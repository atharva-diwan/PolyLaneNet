[2021-08-04 01:03:51,018] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-04 01:03:51,018] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "../data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "../data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-04 01:03:51,018] [INFO] Args:
Namespace(batch_size=None, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-04 01:03:58,496] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 141, in <module>
    test_dataset = cfg.get_dataset("test")
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\config.py", line 23, in get_dataset
    self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\datasets\lane_dataset.py", line 32, in __init__
    self.dataset = TuSimple(split=split, **kwargs)
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\datasets\tusimple.py", line 35, in __init__
    self.load_annotations()
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\datasets\tusimple.py", line 71, in load_annotations
    with open(anno_file, 'r') as anno_obj:
FileNotFoundError: [Errno 2] No such file or directory: '../data_lane-regression/datasets/tusimple\\label_data_0531.json'
[2021-08-04 22:50:08,038] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-04 22:50:08,375] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "../data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "../data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-04 22:50:08,391] [INFO] Args:
Namespace(batch_size=None, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-04 22:50:08,522] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 141, in <module>
    test_dataset = cfg.get_dataset("test")
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\config.py", line 23, in get_dataset
    self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\datasets\lane_dataset.py", line 32, in __init__
    self.dataset = TuSimple(split=split, **kwargs)
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\datasets\tusimple.py", line 35, in __init__
    self.load_annotations()
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\datasets\tusimple.py", line 71, in load_annotations
    with open(anno_file, 'r') as anno_obj:
FileNotFoundError: [Errno 2] No such file or directory: '../data_lane-regression/datasets/tusimple\\label_data_0531.json'
[2021-08-04 23:24:52,429] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-04 23:24:52,529] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "../data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "../data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-04 23:24:52,529] [INFO] Args:
Namespace(batch_size=None, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-04 23:24:52,730] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 141, in <module>
    test_dataset = cfg.get_dataset("test")
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\config.py", line 23, in get_dataset
    self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\datasets\lane_dataset.py", line 32, in __init__
    self.dataset = TuSimple(split=split, **kwargs)
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\datasets\tusimple.py", line 35, in __init__
    self.load_annotations()
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\datasets\tusimple.py", line 71, in load_annotations
    with open(anno_file, 'r') as anno_obj:
FileNotFoundError: [Errno 2] No such file or directory: '../data_lane-regression/datasets/tusimple\\label_data_0531.json'
[2021-08-04 23:34:10,187] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-04 23:34:10,276] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "../data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "../data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-04 23:34:10,291] [INFO] Args:
Namespace(batch_size=None, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-04 23:34:17,014] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 141, in <module>
    test_dataset = cfg.get_dataset("test")
  File "/mnt/e/New folder/umic/Polynomial Regression/PolyLaneNet/lib/config.py", line 23, in get_dataset
    self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
  File "/mnt/e/New folder/umic/Polynomial Regression/PolyLaneNet/lib/datasets/lane_dataset.py", line 32, in __init__
    self.dataset = TuSimple(split=split, **kwargs)
  File "/mnt/e/New folder/umic/Polynomial Regression/PolyLaneNet/lib/datasets/tusimple.py", line 35, in __init__
    self.load_annotations()
  File "/mnt/e/New folder/umic/Polynomial Regression/PolyLaneNet/lib/datasets/tusimple.py", line 71, in load_annotations
    with open(anno_file, 'r') as anno_obj:
FileNotFoundError: [Errno 2] No such file or directory: '../data_lane-regression/datasets/tusimple/label_data_0531.json'
[2021-08-04 23:35:02,744] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-04 23:35:02,745] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "../data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "../data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-04 23:35:02,756] [INFO] Args:
Namespace(batch_size=None, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-04 23:35:02,921] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 141, in <module>
    test_dataset = cfg.get_dataset("test")
  File "/mnt/e/New folder/umic/Polynomial Regression/PolyLaneNet/lib/config.py", line 23, in get_dataset
    self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
  File "/mnt/e/New folder/umic/Polynomial Regression/PolyLaneNet/lib/datasets/lane_dataset.py", line 32, in __init__
    self.dataset = TuSimple(split=split, **kwargs)
  File "/mnt/e/New folder/umic/Polynomial Regression/PolyLaneNet/lib/datasets/tusimple.py", line 35, in __init__
    self.load_annotations()
  File "/mnt/e/New folder/umic/Polynomial Regression/PolyLaneNet/lib/datasets/tusimple.py", line 71, in load_annotations
    with open(anno_file, 'r') as anno_obj:
FileNotFoundError: [Errno 2] No such file or directory: '../data_lane-regression/datasets/tusimple/test_label.json'
[2021-08-04 23:35:42,688] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-04 23:35:42,689] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-04 23:35:42,698] [INFO] Args:
Namespace(batch_size=None, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-04 23:35:47,327] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/.gitignore b/.gitignore
index e4bcbf2..fdf6f3f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,8 +1,8 @@
-__pycache__
-experiments
-.vscode
-venv
-config.yaml
-/datasets/
-lib/nms/build/
-lib/nms/dist/
+__pycache__
+experiments
+.vscode
+venv
+config.yaml
+/datasets/
+lib/nms/build/
+lib/nms/dist/
diff --git a/LICENSE b/LICENSE
index f8fe53d..33d52bc 100644
--- a/LICENSE
+++ b/LICENSE
@@ -1,21 +1,21 @@
-MIT License
-
-Copyright (c) 2020 Lucas Tabelini Torres
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+MIT License
+
+Copyright (c) 2020 Lucas Tabelini Torres
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
diff --git a/README.md b/README.md
index b4af404..d49fcb0 100644
--- a/README.md
+++ b/README.md
@@ -1,165 +1,166 @@
-<div align="center">
-
-# PolyLaneNet
-![Method overview](figures/method-overview.png "Method overview")
-</div>
-
-## Description
-Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
-[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
-
-**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
-
-## Table of Contents
-1. [Installation](#installation)
-2. [Usage](#usage)
-3. [Reproducing the paper results](#reproducing)
-
-<a name="installation"/>
-
-### Installation
-The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
-
-Install dependencies:
-```
-pip install -r requirements.txt
-```
-
-<a name="usage"/>
-
-### Usage
-#### Training
-Every setting for a training is set through a YAML configuration file.
-Thus, in order to train a model you will have to setup the configuration file.
-An example is shown:
-```yaml
-# Training settings
-exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
-iter_log_interval: 1 # Log training iteration every N iterations
-iter_time_window: 100 # Moving average iterations window for the printed loss metric
-model_save_interval: 1 # Save model every N epochs
-seed: 0 # Seed for randomness
-backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
-
-# Dataset settings
-datasets:
-  train:
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: # ImgAug augmentations
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "datasets/tusimple" # Dataset root
-
-  test: &test
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      img_size: [360, 640]
-      root: "datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
-```
-
-With the config file created, run the training script:
-```bash
-python train.py --exp_name tusimple --cfg config.yaml
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the training (.yaml)
-  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
-  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
-  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
-```
-
-#### Testing
-After training, run the `test.py` script to get the metrics:
-```bash
-python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
-  --epoch EPOCH         Epoch to test the model on
-  --batch_size          Number of images per batch
-  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
-```
-
-If you have any issues with either training or testing feel free to open an issue.
-
-<a name="reproducing"/>
-
-### Reproducing the paper results
-
-#### Models
-All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
-
-#### Datasets
-- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
-- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
-- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
-
-#### How to
-To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
-If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
-If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
-1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
-1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
-1. Move the downloaded experiment to your `exps_dir` folder.
-
-Then, run:
-
-```bash
-python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
-```
-Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
-
-
+<div align="center">
+
+# PolyLaneNet
+![Method overview](figures/method-overview.png "Method overview")
+</div>
+
+## Description
+Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
+[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
+
+**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
+
+## Table of Contents
+1. [Installation](#installation)
+2. [Usage](#usage)
+3. [Reproducing the paper results](#reproducing)
+
+<a name="installation"/>
+
+### Installation
+The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
+
+Install dependencies:
+```
+pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
+```
+
+<a name="usage"/>
+
+### Usage
+#### Training
+Every setting for a training is set through a YAML configuration file.
+Thus, in order to train a model you will have to setup the configuration file.
+An example is shown:
+```yaml
+# Training settings
+exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
+iter_log_interval: 1 # Log training iteration every N iterations
+iter_time_window: 100 # Moving average iterations window for the printed loss metric
+model_save_interval: 1 # Save model every N epochs
+seed: 0 # Seed for randomness
+backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
+
+# Dataset settings
+datasets:
+  train:
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: # ImgAug augmentations
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "datasets/tusimple" # Dataset root
+
+  test: &test
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      img_size: [360, 640]
+      root: "datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
+```
+
+With the config file created, run the training script:
+```bash
+python train.py --exp_name tusimple --cfg config.yaml
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the training (.yaml)
+  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
+  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
+  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
+```
+
+#### Testing
+After training, run the `test.py` script to get the metrics:
+```bash
+python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
+  --epoch EPOCH         Epoch to test the model on
+  --batch_size          Number of images per batch
+  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
+```
+
+If you have any issues with either training or testing feel free to open an issue.
+
+<a name="reproducing"/>
+
+### Reproducing the paper results
+
+#### Models
+All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
+
+#### Datasets
+- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
+- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
+- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
+
+#### How to
+To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
+If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
+If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
+1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
+1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
+1. Move the downloaded experiment to your `exps_dir` folder.
+
+Then, run:
+
+```bash
+python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
+```
+Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
+
+
diff --git a/cfgs/elas.yaml b/cfgs/elas.yaml
index 98a03bd..8d9f910 100644
--- a/cfgs/elas.yaml
+++ b/cfgs/elas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 35
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 35
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 35
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 35
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/elas_cls.yaml b/cfgs/elas_cls.yaml
index a251b94..db6d9c8 100644
--- a/cfgs/elas_cls.yaml
+++ b/cfgs/elas_cls.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: true
-    extra_outputs: 40 # 5 lanes * 8 classes
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 1
-  poly_weight: 300
-batch_size: 16
-epochs: 385
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: true
+    extra_outputs: 40 # 5 lanes * 8 classes
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 1
+  poly_weight: 300
+batch_size: 16
+epochs: 385
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/llamas.yaml b/cfgs/llamas.yaml
index 5806168..1af205d 100644
--- a/cfgs/llamas.yaml
+++ b/cfgs/llamas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 75
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 75
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: llamas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/llamas"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: llamas
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/llamas"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 75
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 75
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: llamas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/llamas"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: llamas
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/llamas"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple.yaml b/cfgs/tusimple.yaml
index 01da72b..2a13cb1 100644
--- a/cfgs/tusimple.yaml
+++ b/cfgs/tusimple.yaml
@@ -1,73 +1,73 @@
-# Training settings
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-seed: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+seed: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_1order.yaml b/cfgs/tusimple_1order.yaml
index 66a8607..3e5f617 100644
--- a/cfgs/tusimple_1order.yaml
+++ b/cfgs/tusimple_1order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 1 
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 9000, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression//datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression//datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 1 
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 9000, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression//datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression//datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_2order.yaml b/cfgs/tusimple_2order.yaml
index 9091dcc..2e3cdca 100644
--- a/cfgs/tusimple_2order.yaml
+++ b/cfgs/tusimple_2order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_320x180.yaml b/cfgs/tusimple_320x180.yaml
index fb61010..32b8f5e 100644
--- a/cfgs/tusimple_320x180.yaml
+++ b/cfgs/tusimple_320x180.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [180, 320]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [180, 320]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [180, 320]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [180, 320]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_480x270.yaml b/cfgs/tusimple_480x270.yaml
index e9077d4..3312074 100644
--- a/cfgs/tusimple_480x270.yaml
+++ b/cfgs/tusimple_480x270.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [270, 480]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [270, 480]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [270, 480]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [270, 480]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_efficientnetb1.yaml b/cfgs/tusimple_efficientnetb1.yaml
index f085635..b1a080a 100644
--- a/cfgs/tusimple_efficientnetb1.yaml
+++ b/cfgs/tusimple_efficientnetb1.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b1'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b1'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_fulltrain.yaml b/cfgs/tusimple_fulltrain.yaml
index 0c0f485..69dfe67 100644
--- a/cfgs/tusimple_fulltrain.yaml
+++ b/cfgs/tusimple_fulltrain.yaml
@@ -1,72 +1,72 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train+val
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple-test"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train+val
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple-test"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_no_share_top_y.yaml b/cfgs/tusimple_no_share_top_y.yaml
index ec81eb2..e1081a5 100644
--- a/cfgs/tusimple_no_share_top_y.yaml
+++ b/cfgs/tusimple_no_share_top_y.yaml
@@ -1,74 +1,74 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    share_top_y: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    share_top_y: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_noaug.yaml b/cfgs/tusimple_noaug.yaml
index 8b4b9db..edd5362 100644
--- a/cfgs/tusimple_noaug.yaml
+++ b/cfgs/tusimple_noaug.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: []
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: []
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_nopretrain.yaml b/cfgs/tusimple_nopretrain.yaml
index 0de222f..ccf039f 100644
--- a/cfgs/tusimple_nopretrain.yaml
+++ b/cfgs/tusimple_nopretrain.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: false 
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: false 
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet34.yaml b/cfgs/tusimple_resnet34.yaml
index 6eafef9..753dc12 100644
--- a/cfgs/tusimple_resnet34.yaml
+++ b/cfgs/tusimple_resnet34.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet34'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet34'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet50.yaml b/cfgs/tusimple_resnet50.yaml
index 58784a8..a32ef90 100644
--- a/cfgs/tusimple_resnet50.yaml
+++ b/cfgs/tusimple_resnet50.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet50'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "/dados/tabelini/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "/dados/tabelini/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet50'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "/dados/tabelini/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "/dados/tabelini/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/lib/config.py b/lib/config.py
index d5d6275..e9405c9 100644
--- a/lib/config.py
+++ b/lib/config.py
@@ -1,45 +1,45 @@
-import yaml
-import torch
-
-import lib.models as models
-import lib.datasets as datasets
-
-
-class Config(object):
-    def __init__(self, config_path):
-        self.config = {}
-        self.load(config_path)
-
-    def load(self, path):
-        with open(path, 'r') as file:
-            self.config_str = file.read()
-        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
-
-    def __repr__(self):
-        return self.config_str
-
-    def get_dataset(self, split):
-        return getattr(datasets,
-                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
-
-    def get_model(self):
-        name = self.config['model']['name']
-        parameters = self.config['model']['parameters']
-        return getattr(models, name)(**parameters)
-
-    def get_optimizer(self, model_parameters):
-        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
-                                                                      **self.config['optimizer']['parameters'])
-
-    def get_lr_scheduler(self, optimizer):
-        return getattr(torch.optim.lr_scheduler,
-                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
-
-    def get_loss_parameters(self):
-        return self.config['loss_parameters']
-
-    def get_test_parameters(self):
-        return self.config['test_parameters']
-
-    def __getitem__(self, item):
-        return self.config[item]
+import yaml
+import torch
+
+import lib.models as models
+import lib.datasets as datasets
+
+
+class Config(object):
+    def __init__(self, config_path):
+        self.config = {}
+        self.load(config_path)
+
+    def load(self, path):
+        with open(path, 'r') as file:
+            self.config_str = file.read()
+        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
+
+    def __repr__(self):
+        return self.config_str
+
+    def get_dataset(self, split):
+        return getattr(datasets,
+                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
+
+    def get_model(self):
+        name = self.config['model']['name']
+        parameters = self.config['model']['parameters']
+        return getattr(models, name)(**parameters)
+
+    def get_optimizer(self, model_parameters):
+        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
+                                                                      **self.config['optimizer']['parameters'])
+
+    def get_lr_scheduler(self, optimizer):
+        return getattr(torch.optim.lr_scheduler,
+                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
+
+    def get_loss_parameters(self):
+        return self.config['loss_parameters']
+
+    def get_test_parameters(self):
+        return self.config['test_parameters']
+
+    def __getitem__(self, item):
+        return self.config[item]
diff --git a/lib/datasets/__init__.py b/lib/datasets/__init__.py
index bc2eb7a..a870757 100644
--- a/lib/datasets/__init__.py
+++ b/lib/datasets/__init__.py
@@ -1,3 +1,3 @@
-from .lane_dataset import LaneDataset
-
-__all__ = ["LaneDataset"]
+from .lane_dataset import LaneDataset
+
+__all__ = ["LaneDataset"]
diff --git a/lib/datasets/elas.py b/lib/datasets/elas.py
index 490f37a..c2a0823 100644
--- a/lib/datasets/elas.py
+++ b/lib/datasets/elas.py
@@ -1,137 +1,137 @@
-import os
-import math
-import random
-
-import cv2
-import numpy as np
-import xmljson
-from scipy import interpolate
-from lxml.etree import fromstring
-
-SPLIT_DIRECTORIES = {
-    'train': [
-        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
-        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
-    ],
-    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
-}
-
-CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
-ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
-
-
-class ELAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.root = root
-        self.split = split
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_directories = SPLIT_DIRECTORIES[split]
-
-        self.img_w, self.img_h = 640, 480
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-        self.class_icons = {
-            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
-            for cls_id in ID_TO_CATEGORY
-        }
-
-    def get_class_icon(self, cls_id):
-        return self.class_icons[cls_id]
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def interp_lane(self, lane, ys, step=10):
-        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
-        if len(pts) <= 1:
-            return None
-        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
-        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
-        interp_xs = interpolate.splev(interp_ys, spline)
-
-        return list(zip(interp_xs, interp_ys))
-
-    def load_dir_annotations(self, dataset_dir):
-        annotations = []
-        max_points = 0
-        max_lanes = 0
-
-        # read config.xml
-        config_fname = os.path.join(dataset_dir, 'config.xml')
-        if not os.path.isfile(config_fname):
-            raise Exception('config.xml not found: {}'.format(config_fname))
-        with open(config_fname, 'r') as hf:
-            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
-
-        # read ground truth
-        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
-        if not os.path.isfile(gt_fname):
-            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
-        with open(gt_fname, 'r') as hf:
-            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
-
-        # read frame annotations
-        for frame in gt['frames']['frame']:
-            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
-
-            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
-            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
-            pts = ['p1', 'p2', 'p3', 'p4']
-            lanes = []
-            categories = []
-            for side in ['Left', 'Right']:
-                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
-                lane = self.interp_lane(lane, ys)
-                if lane is None:
-                    continue
-                max_points = max(max_points, len(lane))
-                lanes.append(lane)
-                category = str(frame['@lmt{}'.format(side)])
-                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
-            max_lanes = max(max_lanes, len(lanes))
-            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
-
-        return annotations, max_points, max_lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        for directory in self.anno_directories:
-            dir_path = os.path.join(self.root, directory)
-            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
-
-            self.annotations.extend(dir_annos)
-            self.max_points = max(self.max_points, dir_max_points)
-            self.max_lanes = max(self.max_lanes, dir_max_lanes)
-
-        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
-                                                                            self.max_lanes))
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import math
+import random
+
+import cv2
+import numpy as np
+import xmljson
+from scipy import interpolate
+from lxml.etree import fromstring
+
+SPLIT_DIRECTORIES = {
+    'train': [
+        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
+        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
+    ],
+    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
+}
+
+CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
+ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
+
+
+class ELAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.root = root
+        self.split = split
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_directories = SPLIT_DIRECTORIES[split]
+
+        self.img_w, self.img_h = 640, 480
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+        self.class_icons = {
+            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
+            for cls_id in ID_TO_CATEGORY
+        }
+
+    def get_class_icon(self, cls_id):
+        return self.class_icons[cls_id]
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def interp_lane(self, lane, ys, step=10):
+        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
+        if len(pts) <= 1:
+            return None
+        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
+        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
+        interp_xs = interpolate.splev(interp_ys, spline)
+
+        return list(zip(interp_xs, interp_ys))
+
+    def load_dir_annotations(self, dataset_dir):
+        annotations = []
+        max_points = 0
+        max_lanes = 0
+
+        # read config.xml
+        config_fname = os.path.join(dataset_dir, 'config.xml')
+        if not os.path.isfile(config_fname):
+            raise Exception('config.xml not found: {}'.format(config_fname))
+        with open(config_fname, 'r') as hf:
+            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
+
+        # read ground truth
+        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
+        if not os.path.isfile(gt_fname):
+            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
+        with open(gt_fname, 'r') as hf:
+            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
+
+        # read frame annotations
+        for frame in gt['frames']['frame']:
+            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
+
+            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
+            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
+            pts = ['p1', 'p2', 'p3', 'p4']
+            lanes = []
+            categories = []
+            for side in ['Left', 'Right']:
+                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
+                lane = self.interp_lane(lane, ys)
+                if lane is None:
+                    continue
+                max_points = max(max_points, len(lane))
+                lanes.append(lane)
+                category = str(frame['@lmt{}'.format(side)])
+                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
+            max_lanes = max(max_lanes, len(lanes))
+            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
+
+        return annotations, max_points, max_lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        for directory in self.anno_directories:
+            dir_path = os.path.join(self.root, directory)
+            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
+
+            self.annotations.extend(dir_annos)
+            self.max_points = max(self.max_points, dir_max_points)
+            self.max_lanes = max(self.max_lanes, dir_max_lanes)
+
+        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
+                                                                            self.max_lanes))
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..1f520dc 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -1,239 +1,239 @@
-import cv2
-import numpy as np
-import imgaug.augmenters as iaa
-from imgaug.augmenters import Resize
-from torchvision.transforms import ToTensor
-from torch.utils.data.dataset import Dataset
-from imgaug.augmentables.lines import LineString, LineStringsOnImage
-
-from .elas import ELAS
-from .llamas import LLAMAS
-from .tusimple import TuSimple
-from .nolabel_dataset import NoLabelDataset
-
-GT_COLOR = (255, 0, 0)
-PRED_HIT_COLOR = (0, 255, 0)
-PRED_MISS_COLOR = (0, 0, 255)
-IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
-IMAGENET_STD = np.array([0.229, 0.224, 0.225])
-
-
-class LaneDataset(Dataset):
-    def __init__(self,
-                 dataset='tusimple',
-                 augmentations=None,
-                 normalize=False,
-                 split='train',
-                 img_size=(360, 640),
-                 aug_chance=1.,
-                 **kwargs):
-        super(LaneDataset, self).__init__()
-        if dataset == 'tusimple':
-            self.dataset = TuSimple(split=split, **kwargs)
-        elif dataset == 'llamas':
-            self.dataset = LLAMAS(split=split, **kwargs)
-        elif dataset == 'elas':
-            self.dataset = ELAS(split=split, **kwargs)
-        elif dataset == 'nolabel_dataset':
-            self.dataset = NoLabelDataset(**kwargs)
-        else:
-            raise NotImplementedError()
-
-        self.transform_annotations()
-        self.img_h, self.img_w = img_size
-
-        if augmentations is not None:
-            # add augmentations
-            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
-                             for aug in augmentations]  # add augmentation
-
-        self.normalize = normalize
-        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
-        self.to_tensor = ToTensor()
-        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
-        self.max_lanes = self.dataset.max_lanes
-
-    def transform_annotation(self, anno, img_wh=None):
-        if img_wh is None:
-            img_h = self.dataset.get_img_heigth(anno['path'])
-            img_w = self.dataset.get_img_width(anno['path'])
-        else:
-            img_w, img_h = img_wh
-
-        old_lanes = anno['lanes']
-        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
-        old_lanes = zip(old_lanes, categories)
-        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
-        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
-        lanes[:, 0] = 0
-        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
-        for lane_pos, (lane, category) in enumerate(old_lanes):
-            lower, upper = lane[0][1], lane[-1][1]
-            xs = np.array([p[0] for p in lane]) / img_w
-            ys = np.array([p[1] for p in lane]) / img_h
-            lanes[lane_pos, 0] = category
-            lanes[lane_pos, 1] = lower / img_h
-            lanes[lane_pos, 2] = upper / img_h
-            lanes[lane_pos, 3:3 + len(xs)] = xs
-            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
-
-        new_anno = {
-            'path': anno['path'],
-            'label': lanes,
-            'old_anno': anno,
-            'categories': [cat for _, cat in old_lanes]
-        }
-
-        return new_anno
-
-    @property
-    def annotations(self):
-        return self.dataset.annotations
-
-    def transform_annotations(self):
-        print('Transforming annotations...')
-        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
-        print('Done.')
-
-    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
-        if img is None:
-            img, label, _ = self.__getitem__(idx, transform=True)
-            # Tensor to opencv image
-            img = img.permute(1, 2, 0).numpy()
-            # Unnormalize
-            if self.normalize:
-                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
-            img = (img * 255).astype(np.uint8)
-        else:
-            _, label, _ = self.__getitem__(idx)
-
-        img_h, img_w, _ = img.shape
-
-        # Draw label
-        for i, lane in enumerate(label):
-            if lane[0] == 0:  # Skip invalid lanes
-                continue
-            lane = lane[3:]  # remove conf, upper and lower positions
-            xs = lane[:len(lane) // 2]
-            ys = lane[len(lane) // 2:]
-            ys = ys[xs >= 0]
-            xs = xs[xs >= 0]
-
-            # draw GT points
-            for p in zip(xs, ys):
-                p = (int(p[0] * img_w), int(p[1] * img_h))
-                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
-
-            # draw GT lane ID
-            cv2.putText(img,
-                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
-                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                        fontScale=1,
-                        color=(0, 255, 0))
-
-        if pred is None:
-            return img
-
-        # Draw predictions
-        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
-        matches, accs, _ = self.dataset.get_metrics(pred, idx)
-        overlay = img.copy()
-        for i, lane in enumerate(pred):
-            if matches[i]:
-                color = PRED_HIT_COLOR
-            else:
-                color = PRED_MISS_COLOR
-            lane = lane[1:]  # remove conf
-            lower, upper = lane[0], lane[1]
-            lane = lane[2:]  # remove upper, lower positions
-
-            # generate points from the polynomial
-            ys = np.linspace(lower, upper, num=100)
-            points = np.zeros((len(ys), 2), dtype=np.int32)
-            points[:, 1] = (ys * img_h).astype(int)
-            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
-            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
-
-            # draw lane with a polyline on the overlay
-            for current_point, next_point in zip(points[:-1], points[1:]):
-                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
-
-            # draw class icon
-            if cls_pred is not None and len(points) > 0:
-                class_icon = self.dataset.get_class_icon(cls_pred[i])
-                class_icon = cv2.resize(class_icon, (32, 32))
-                mid = tuple(points[len(points) // 2] - 60)
-                x, y = mid
-
-                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
-
-            # draw lane ID
-            if len(points) > 0:
-                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
-
-            # draw lane accuracy
-            if len(points) > 0:
-                cv2.putText(img,
-                            '{:.2f}'.format(accs[i] * 100),
-                            tuple(points[len(points) // 2] - 30),
-                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                            fontScale=.75,
-                            color=color)
-        # Add lanes overlay
-        w = 0.6
-        img = ((1. - w) * img + w * overlay).astype(np.uint8)
-
-        return img
-
-    def lane_to_linestrings(self, lanes):
-        lines = []
-        for lane in lanes:
-            lines.append(LineString(lane))
-
-        return lines
-
-    def linestrings_to_lanes(self, lines):
-        lanes = []
-        for line in lines:
-            lanes.append(line.coords)
-
-        return lanes
-
-    def __getitem__(self, idx, transform=True):
-        item = self.dataset[idx]
-        img = cv2.imread(item['path'])
-        label = item['label']
-        if transform:
-            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
-            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
-            img, line_strings = self.transform(image=img, line_strings=line_strings)
-            line_strings.clip_out_of_image_()
-            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
-            new_anno['categories'] = item['categories']
-            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
-
-        img = img / 255.
-        if self.normalize:
-            img = (img - IMAGENET_MEAN) / IMAGENET_STD
-        img = self.to_tensor(img.astype(np.float32))
-        return (img, label, idx)
-
-    def __len__(self):
-        return len(self.dataset)
-
-
-def main():
-    import torch
-    from lib.config import Config
-    np.random.seed(0)
-    torch.manual_seed(0)
-    cfg = Config('config.yaml')
-    train_dataset = cfg.get_dataset('train')
-    for idx in range(len(train_dataset)):
-        img = train_dataset.draw_annotation(idx)
-        cv2.imshow('sample', img)
-        cv2.waitKey(0)
-
-
-if __name__ == "__main__":
-    main()
+import cv2
+import numpy as np
+import imgaug.augmenters as iaa
+from imgaug.augmenters import Resize
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+from imgaug.augmentables.lines import LineString, LineStringsOnImage
+
+from .elas import ELAS
+from .llamas import LLAMAS
+from .tusimple import TuSimple
+from .nolabel_dataset import NoLabelDataset
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+
+class LaneDataset(Dataset):
+    def __init__(self,
+                 dataset='tusimple',
+                 augmentations=None,
+                 normalize=False,
+                 split='train',
+                 img_size=(360, 640),
+                 aug_chance=1.,
+                 **kwargs):
+        super(LaneDataset, self).__init__()
+        if dataset == 'tusimple':
+            self.dataset = TuSimple(split=split, **kwargs)
+        elif dataset == 'llamas':
+            self.dataset = LLAMAS(split=split, **kwargs)
+        elif dataset == 'elas':
+            self.dataset = ELAS(split=split, **kwargs)
+        elif dataset == 'nolabel_dataset':
+            self.dataset = NoLabelDataset(**kwargs)
+        else:
+            raise NotImplementedError()
+
+        self.transform_annotations()
+        self.img_h, self.img_w = img_size
+
+        if augmentations is not None:
+            # add augmentations
+            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
+                             for aug in augmentations]  # add augmentation
+
+        self.normalize = normalize
+        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
+        self.to_tensor = ToTensor()
+        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
+        self.max_lanes = self.dataset.max_lanes
+
+    def transform_annotation(self, anno, img_wh=None):
+        if img_wh is None:
+            img_h = self.dataset.get_img_heigth(anno['path'])
+            img_w = self.dataset.get_img_width(anno['path'])
+        else:
+            img_w, img_h = img_wh
+
+        old_lanes = anno['lanes']
+        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
+        old_lanes = zip(old_lanes, categories)
+        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
+        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
+        lanes[:, 0] = 0
+        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
+        for lane_pos, (lane, category) in enumerate(old_lanes):
+            lower, upper = lane[0][1], lane[-1][1]
+            xs = np.array([p[0] for p in lane]) / img_w
+            ys = np.array([p[1] for p in lane]) / img_h
+            lanes[lane_pos, 0] = category
+            lanes[lane_pos, 1] = lower / img_h
+            lanes[lane_pos, 2] = upper / img_h
+            lanes[lane_pos, 3:3 + len(xs)] = xs
+            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
+
+        new_anno = {
+            'path': anno['path'],
+            'label': lanes,
+            'old_anno': anno,
+            'categories': [cat for _, cat in old_lanes]
+        }
+
+        return new_anno
+
+    @property
+    def annotations(self):
+        return self.dataset.annotations
+
+    def transform_annotations(self):
+        print('Transforming annotations...')
+        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
+        print('Done.')
+
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+        if img is None:
+            img, label, _ = self.__getitem__(idx, transform=True)
+            # Tensor to opencv image
+            img = img.permute(1, 2, 0).numpy()
+            # Unnormalize
+            if self.normalize:
+                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+            img = (img * 255).astype(np.uint8)
+        else:
+            _, label, _ = self.__getitem__(idx)
+
+        img_h, img_w, _ = img.shape
+
+        # Draw label
+        for i, lane in enumerate(label):
+            if lane[0] == 0:  # Skip invalid lanes
+                continue
+            lane = lane[3:]  # remove conf, upper and lower positions
+            xs = lane[:len(lane) // 2]
+            ys = lane[len(lane) // 2:]
+            ys = ys[xs >= 0]
+            xs = xs[xs >= 0]
+
+            # draw GT points
+            for p in zip(xs, ys):
+                p = (int(p[0] * img_w), int(p[1] * img_h))
+                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
+
+            # draw GT lane ID
+            cv2.putText(img,
+                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
+                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                        fontScale=1,
+                        color=(0, 255, 0))
+
+        if pred is None:
+            return img
+
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        matches, accs, _ = self.dataset.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+            if matches[i]:
+                color = PRED_HIT_COLOR
+            else:
+                color = PRED_MISS_COLOR
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(accs[i] * 100),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+    def lane_to_linestrings(self, lanes):
+        lines = []
+        for lane in lanes:
+            lines.append(LineString(lane))
+
+        return lines
+
+    def linestrings_to_lanes(self, lines):
+        lanes = []
+        for line in lines:
+            lanes.append(line.coords)
+
+        return lanes
+
+    def __getitem__(self, idx, transform=True):
+        item = self.dataset[idx]
+        img = cv2.imread(item['path'])
+        label = item['label']
+        if transform:
+            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
+            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
+            img, line_strings = self.transform(image=img, line_strings=line_strings)
+            line_strings.clip_out_of_image_()
+            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
+            new_anno['categories'] = item['categories']
+            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
+
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, label, idx)
+
+    def __len__(self):
+        return len(self.dataset)
+
+
+def main():
+    import torch
+    from lib.config import Config
+    np.random.seed(0)
+    torch.manual_seed(0)
+    cfg = Config('config.yaml')
+    train_dataset = cfg.get_dataset('train')
+    for idx in range(len(train_dataset)):
+        img = train_dataset.draw_annotation(idx)
+        cv2.imshow('sample', img)
+        cv2.waitKey(0)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/lib/datasets/llamas.py b/lib/datasets/llamas.py
index 595e17b..aba4654 100644
--- a/lib/datasets/llamas.py
+++ b/lib/datasets/llamas.py
@@ -1,451 +1,451 @@
-import os
-import json
-import pickle as pkl
-
-import numpy as np
-from progressbar import progressbar
-
-TRAIN_LABELS_DIR = 'labels/train'
-TEST_LABELS_DIR = 'labels/valid'
-SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
-
-
-class LLAMAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.split = split
-        self.root = root
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
-
-        self.img_w, self.img_h = 1276, 717
-        self.offset = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def get_img_path(self, json_path):
-        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
-        base_name = '/'.join(json_path.split('/')[-3:])
-        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
-        return image_path
-
-    def get_json_paths(self):
-        json_paths = []
-        for root, dirs, files in os.walk(self.labels_dir):
-            for file in files:
-                if file.endswith(".json"):
-                    json_paths.append(os.path.join(root, file))
-        return json_paths
-
-    def load_annotations(self):
-        # Waiting for the dataset to load is tedious, let's cache it
-        os.makedirs('cache', exist_ok=True)
-        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
-        if os.path.exists(cache_path):
-            with open(cache_path, 'rb') as cache_file:
-                self.annotations = pkl.load(cache_file)
-                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
-                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
-                return
-
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        print("Searching annotation files...")
-        json_paths = self.get_json_paths()
-        print('{} annotations found.'.format(len(json_paths)))
-
-        for json_path in progressbar(json_paths):
-            lanes = get_horizontal_values_for_four_lanes(json_path)
-            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
-            lanes = [lane for lane in lanes if len(lane) > 0]
-            relative_path = self.get_img_path(json_path)
-            img_path = os.path.join(self.root, relative_path)
-            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
-            self.max_lanes = max(self.max_lanes, len(lanes))
-            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
-
-        with open(cache_path, 'wb') as cache_file:
-            pkl.dump(self.annotations, cache_file)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
-
-
-# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
-# Its license is copied here
-
-# ##### Begin License ######
-# MIT License
-
-# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
-
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-
-# The above copyright notice and this permission notice shall be included in all
-# copies or substantial portions of the Software.
-
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# ##### End License ######
-
-# Start code under the previous license
-
-
-def _extend_lane(lane, projection_matrix):
-    """Extends marker closest to the camera
-
-    Adds an extra marker that reaches the end of the image
-
-    Parameters
-    ----------
-    lane : iterable of markers
-    projection_matrix : 3x3 projection matrix
-    """
-    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
-    # z is the orthongal distance to the car. It's good enough
-
-    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
-    # e.g., horizontal markers which need to be filtered
-    filtered_markers = filter(
-        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
-        lane['markers'])
-    # might be the first marker in the list but not guaranteed
-    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
-
-    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
-        return lane
-
-    # World marker extension approximation
-    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-
-    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
-    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
-
-    # Pixel marker extension approximation
-    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
-        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
-    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
-        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
-
-    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
-    if pixel_zero_x < 0:
-        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
-        new_pixel_point = (0, left_y)
-    elif pixel_zero_x > 1276:
-        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
-        new_pixel_point = (1276, right_y)
-    else:
-        new_pixel_point = (pixel_zero_x, 716)
-
-    new_marker = {
-        'lane_marker_id': 'FAKE',
-        'world_end': {
-            'x': closest_marker['world_start']['x'],
-            'y': closest_marker['world_start']['y'],
-            'z': closest_marker['world_start']['z']
-        },
-        'world_start': {
-            'x': zero_x,
-            'y': zero_y,
-            'z': 1
-        },
-        'pixel_end': {
-            'x': closest_marker['pixel_start']['x'],
-            'y': closest_marker['pixel_start']['y']
-        },
-        'pixel_start': {
-            'x': ir(new_pixel_point[0]),
-            'y': ir(new_pixel_point[1])
-        }
-    }
-    lane['markers'].insert(0, new_marker)
-
-    return lane
-
-
-class SplineCreator():
-    """
-    For each lane divder
-      - all lines are projected
-      - linearly interpolated to limit oscillations
-      - interpolated by a spline
-      - subsampled to receive individual pixel values
-
-    The spline creation can be optimized!
-      - Better spline parameters
-      - Extend lowest marker to reach bottom of image would also help
-      - Extending last marker may in some cases be interesting too
-    Any help is welcome.
-
-    Call create_all_points and get the points in self.sampled_points
-    It has an x coordinate for each value for each lane
-
-    """
-    def __init__(self, json_path):
-        self.json_path = json_path
-        self.json_content = read_json(json_path)
-        self.lanes = self.json_content['lanes']
-        self.lane_marker_points = {}
-        self.sampled_points = {}  # <--- the interesting part
-        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
-
-    def _sample_points(self, lane, ypp=5, between_markers=True):
-        """ Markers are given by start and endpoint. This one adds extra points
-        which need to be considered for the interpolation. Otherwise the spline
-        could arbitrarily oscillate between start and end of the individual markers
-
-        Parameters
-        ----------
-        lane: polyline, in theory but there are artifacts which lead to inconsistencies
-              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
-        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
-        between_markers : bool, interpolates inbetween dashes
-
-        Notes
-        -----
-        Especially, adding points in the lower parts of the image (high y-values) because
-        the start and end points are too sparse.
-        Removing upper lane markers that have starting and end points mapped into the same pixel.
-        """
-
-        # Collect all x values from all markers along a given line. There may be multiple
-        # intersecting markers, i.e., multiple entries for some y values
-        x_values = [[] for i in range(717)]
-        for marker in lane['markers']:
-            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
-
-            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
-            if height > 2:
-                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
-                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
-                for i in range(height + 1):
-                    x = marker['pixel_start']['x'] + slope * step_size * i
-                    y = marker['pixel_start']['y'] - step_size * i
-                    x_values[ir(y)].append(ir(x))
-
-        # Calculate average x values for each y value
-        for y, xs in enumerate(x_values):
-            if not xs:
-                x_values[y] = -1
-            else:
-                x_values[y] = sum(xs) / float(len(xs))
-
-        # In the following, we will only interpolate between markers if needed
-        if not between_markers:
-            return x_values  # TODO ypp
-
-        # # interpolate between markers
-        current_y = 0
-        while x_values[current_y] == -1:  # skip missing first entries
-            current_y += 1
-
-        # Also possible using numpy.interp when accounting for beginning and end
-        next_set_y = 0
-        try:
-            while current_y < 717:
-                if x_values[current_y] != -1:  # set. Nothing to be done
-                    current_y += 1
-                    continue
-
-                # Finds target x value for interpolation
-                while next_set_y <= current_y or x_values[next_set_y] == -1:
-                    next_set_y += 1
-                    if next_set_y >= 717:
-                        raise StopIteration
-
-                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
-                    (next_set_y - current_y + 1)
-                current_y += 1
-
-        except StopIteration:
-            pass  # Done with lane
-
-        return x_values
-
-    def _lane_points_fit(self, lane):
-        # TODO name and docstring
-        """ Fits spline in image space for the markers of a single lane (side)
-
-        Parameters
-        ----------
-        lane: dict as specified in label
-
-        Returns
-        -------
-        Pixel level values for curve along the y-axis
-
-        Notes
-        -----
-        This one can be drastically improved. Probably fairly easy as well.
-        """
-        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
-        lane = _extend_lane(lane, self.json_content['projection_matrix'])
-        sampled_points = self._sample_points(lane, ypp=1)
-        self.sampled_points[lane['lane_id']] = sampled_points
-
-        return sampled_points
-
-    def create_all_points(self, ):
-        """ Creates splines for given label """
-        for lane in self.lanes:
-            self._lane_points_fit(lane)
-
-
-def get_horizontal_values_for_four_lanes(json_path):
-    """ Gets an x value for every y coordinate for l1, l0, r0, r1
-
-    This allows to easily train a direct curve approximation. For each value along
-    the y-axis, the respective x-values can be compared, e.g. squared distance.
-    Missing values are filled with -1. Missing values are values missing from the spline.
-    There is no extrapolation to the image start/end (yet).
-    But values are interpolated between markers. Space between dashed markers is not missing.
-
-    Parameters
-    ----------
-    json_path: str
-               path to label-file
-
-    Returns
-    -------
-    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
-    the number of vertical pixels of the image
-
-    Notes
-    -----
-    The points are currently based on the splines. The splines are interpolated based on the
-    segmentation values. The spline interpolation has lots of room for improvement, e.g.
-    the lines could be interpolated in 3D, a better approach to spline interpolation could
-    be used, there is barely any error checking, sometimes the splines oscillate too much.
-    This was used for a quick poly-line regression training only.
-    """
-
-    sc = SplineCreator(json_path)
-    sc.create_all_points()
-
-    l1 = sc.sampled_points.get('l1', [-1] * 717)
-    l0 = sc.sampled_points.get('l0', [-1] * 717)
-    r0 = sc.sampled_points.get('r0', [-1] * 717)
-    r1 = sc.sampled_points.get('r1', [-1] * 717)
-
-    lanes = [l1, l0, r0, r1]
-    return lanes
-
-
-def _filter_lanes_by_size(label, min_height=40):
-    """ May need some tuning """
-    filtered_lanes = []
-    for lane in label['lanes']:
-        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        if (lane_end - lane_start) < min_height:
-            continue
-        filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _filter_few_markers(label, min_markers=2):
-    """Filter lines that consist of only few markers"""
-    filtered_lanes = []
-    for lane in label['lanes']:
-        if len(lane['markers']) >= min_markers:
-            filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _fix_lane_names(label):
-    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
-
-    # Create mapping
-    l_counter = 0
-    r_counter = 0
-    mapping = {}
-    lane_ids = [lane['lane_id'] for lane in label['lanes']]
-    for key in sorted(lane_ids):
-        if key[0] == 'l':
-            mapping[key] = 'l' + str(l_counter)
-            l_counter += 1
-        if key[0] == 'r':
-            mapping[key] = 'r' + str(r_counter)
-            r_counter += 1
-    for lane in label['lanes']:
-        lane['lane_id'] = mapping[lane['lane_id']]
-
-
-def read_json(json_path, min_lane_height=20):
-    """ Reads and cleans label file information by path"""
-    with open(json_path, 'r') as jf:
-        label_content = json.load(jf)
-
-    _filter_lanes_by_size(label_content, min_height=min_lane_height)
-    _filter_few_markers(label_content, min_markers=2)
-    _fix_lane_names(label_content)
-
-    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
-
-    for lane in content['lanes']:
-        for marker in lane['markers']:
-            for pixel_key in marker['pixel_start'].keys():
-                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
-            for pixel_key in marker['pixel_end'].keys():
-                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
-            for pixel_key in marker['world_start'].keys():
-                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
-            for pixel_key in marker['world_end'].keys():
-                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
-    return content
-
-
-def ir(some_value):
-    """ Rounds and casts to int
-    Useful for pixel values that cannot be floats
-    Parameters
-    ----------
-    some_value : float
-                 numeric value
-    Returns
-    --------
-    Rounded integer
-    Raises
-    ------
-    ValueError for non scalar types
-    """
-    return int(round(some_value))
-
-
-# End code under the previous license
+import os
+import json
+import pickle as pkl
+
+import numpy as np
+from progressbar import progressbar
+
+TRAIN_LABELS_DIR = 'labels/train'
+TEST_LABELS_DIR = 'labels/valid'
+SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
+
+
+class LLAMAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.split = split
+        self.root = root
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
+
+        self.img_w, self.img_h = 1276, 717
+        self.offset = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def get_img_path(self, json_path):
+        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
+        base_name = '/'.join(json_path.split('/')[-3:])
+        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
+        return image_path
+
+    def get_json_paths(self):
+        json_paths = []
+        for root, dirs, files in os.walk(self.labels_dir):
+            for file in files:
+                if file.endswith(".json"):
+                    json_paths.append(os.path.join(root, file))
+        return json_paths
+
+    def load_annotations(self):
+        # Waiting for the dataset to load is tedious, let's cache it
+        os.makedirs('cache', exist_ok=True)
+        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
+        if os.path.exists(cache_path):
+            with open(cache_path, 'rb') as cache_file:
+                self.annotations = pkl.load(cache_file)
+                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
+                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
+                return
+
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        print("Searching annotation files...")
+        json_paths = self.get_json_paths()
+        print('{} annotations found.'.format(len(json_paths)))
+
+        for json_path in progressbar(json_paths):
+            lanes = get_horizontal_values_for_four_lanes(json_path)
+            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
+            lanes = [lane for lane in lanes if len(lane) > 0]
+            relative_path = self.get_img_path(json_path)
+            img_path = os.path.join(self.root, relative_path)
+            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
+            self.max_lanes = max(self.max_lanes, len(lanes))
+            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
+
+        with open(cache_path, 'wb') as cache_file:
+            pkl.dump(self.annotations, cache_file)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
+
+
+# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
+# Its license is copied here
+
+# ##### Begin License ######
+# MIT License
+
+# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# ##### End License ######
+
+# Start code under the previous license
+
+
+def _extend_lane(lane, projection_matrix):
+    """Extends marker closest to the camera
+
+    Adds an extra marker that reaches the end of the image
+
+    Parameters
+    ----------
+    lane : iterable of markers
+    projection_matrix : 3x3 projection matrix
+    """
+    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
+    # z is the orthongal distance to the car. It's good enough
+
+    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
+    # e.g., horizontal markers which need to be filtered
+    filtered_markers = filter(
+        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
+        lane['markers'])
+    # might be the first marker in the list but not guaranteed
+    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
+
+    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
+        return lane
+
+    # World marker extension approximation
+    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+
+    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
+    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
+
+    # Pixel marker extension approximation
+    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
+        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
+    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
+        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
+
+    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
+    if pixel_zero_x < 0:
+        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
+        new_pixel_point = (0, left_y)
+    elif pixel_zero_x > 1276:
+        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
+        new_pixel_point = (1276, right_y)
+    else:
+        new_pixel_point = (pixel_zero_x, 716)
+
+    new_marker = {
+        'lane_marker_id': 'FAKE',
+        'world_end': {
+            'x': closest_marker['world_start']['x'],
+            'y': closest_marker['world_start']['y'],
+            'z': closest_marker['world_start']['z']
+        },
+        'world_start': {
+            'x': zero_x,
+            'y': zero_y,
+            'z': 1
+        },
+        'pixel_end': {
+            'x': closest_marker['pixel_start']['x'],
+            'y': closest_marker['pixel_start']['y']
+        },
+        'pixel_start': {
+            'x': ir(new_pixel_point[0]),
+            'y': ir(new_pixel_point[1])
+        }
+    }
+    lane['markers'].insert(0, new_marker)
+
+    return lane
+
+
+class SplineCreator():
+    """
+    For each lane divder
+      - all lines are projected
+      - linearly interpolated to limit oscillations
+      - interpolated by a spline
+      - subsampled to receive individual pixel values
+
+    The spline creation can be optimized!
+      - Better spline parameters
+      - Extend lowest marker to reach bottom of image would also help
+      - Extending last marker may in some cases be interesting too
+    Any help is welcome.
+
+    Call create_all_points and get the points in self.sampled_points
+    It has an x coordinate for each value for each lane
+
+    """
+    def __init__(self, json_path):
+        self.json_path = json_path
+        self.json_content = read_json(json_path)
+        self.lanes = self.json_content['lanes']
+        self.lane_marker_points = {}
+        self.sampled_points = {}  # <--- the interesting part
+        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
+
+    def _sample_points(self, lane, ypp=5, between_markers=True):
+        """ Markers are given by start and endpoint. This one adds extra points
+        which need to be considered for the interpolation. Otherwise the spline
+        could arbitrarily oscillate between start and end of the individual markers
+
+        Parameters
+        ----------
+        lane: polyline, in theory but there are artifacts which lead to inconsistencies
+              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
+        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
+        between_markers : bool, interpolates inbetween dashes
+
+        Notes
+        -----
+        Especially, adding points in the lower parts of the image (high y-values) because
+        the start and end points are too sparse.
+        Removing upper lane markers that have starting and end points mapped into the same pixel.
+        """
+
+        # Collect all x values from all markers along a given line. There may be multiple
+        # intersecting markers, i.e., multiple entries for some y values
+        x_values = [[] for i in range(717)]
+        for marker in lane['markers']:
+            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
+
+            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
+            if height > 2:
+                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
+                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
+                for i in range(height + 1):
+                    x = marker['pixel_start']['x'] + slope * step_size * i
+                    y = marker['pixel_start']['y'] - step_size * i
+                    x_values[ir(y)].append(ir(x))
+
+        # Calculate average x values for each y value
+        for y, xs in enumerate(x_values):
+            if not xs:
+                x_values[y] = -1
+            else:
+                x_values[y] = sum(xs) / float(len(xs))
+
+        # In the following, we will only interpolate between markers if needed
+        if not between_markers:
+            return x_values  # TODO ypp
+
+        # # interpolate between markers
+        current_y = 0
+        while x_values[current_y] == -1:  # skip missing first entries
+            current_y += 1
+
+        # Also possible using numpy.interp when accounting for beginning and end
+        next_set_y = 0
+        try:
+            while current_y < 717:
+                if x_values[current_y] != -1:  # set. Nothing to be done
+                    current_y += 1
+                    continue
+
+                # Finds target x value for interpolation
+                while next_set_y <= current_y or x_values[next_set_y] == -1:
+                    next_set_y += 1
+                    if next_set_y >= 717:
+                        raise StopIteration
+
+                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
+                    (next_set_y - current_y + 1)
+                current_y += 1
+
+        except StopIteration:
+            pass  # Done with lane
+
+        return x_values
+
+    def _lane_points_fit(self, lane):
+        # TODO name and docstring
+        """ Fits spline in image space for the markers of a single lane (side)
+
+        Parameters
+        ----------
+        lane: dict as specified in label
+
+        Returns
+        -------
+        Pixel level values for curve along the y-axis
+
+        Notes
+        -----
+        This one can be drastically improved. Probably fairly easy as well.
+        """
+        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
+        lane = _extend_lane(lane, self.json_content['projection_matrix'])
+        sampled_points = self._sample_points(lane, ypp=1)
+        self.sampled_points[lane['lane_id']] = sampled_points
+
+        return sampled_points
+
+    def create_all_points(self, ):
+        """ Creates splines for given label """
+        for lane in self.lanes:
+            self._lane_points_fit(lane)
+
+
+def get_horizontal_values_for_four_lanes(json_path):
+    """ Gets an x value for every y coordinate for l1, l0, r0, r1
+
+    This allows to easily train a direct curve approximation. For each value along
+    the y-axis, the respective x-values can be compared, e.g. squared distance.
+    Missing values are filled with -1. Missing values are values missing from the spline.
+    There is no extrapolation to the image start/end (yet).
+    But values are interpolated between markers. Space between dashed markers is not missing.
+
+    Parameters
+    ----------
+    json_path: str
+               path to label-file
+
+    Returns
+    -------
+    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
+    the number of vertical pixels of the image
+
+    Notes
+    -----
+    The points are currently based on the splines. The splines are interpolated based on the
+    segmentation values. The spline interpolation has lots of room for improvement, e.g.
+    the lines could be interpolated in 3D, a better approach to spline interpolation could
+    be used, there is barely any error checking, sometimes the splines oscillate too much.
+    This was used for a quick poly-line regression training only.
+    """
+
+    sc = SplineCreator(json_path)
+    sc.create_all_points()
+
+    l1 = sc.sampled_points.get('l1', [-1] * 717)
+    l0 = sc.sampled_points.get('l0', [-1] * 717)
+    r0 = sc.sampled_points.get('r0', [-1] * 717)
+    r1 = sc.sampled_points.get('r1', [-1] * 717)
+
+    lanes = [l1, l0, r0, r1]
+    return lanes
+
+
+def _filter_lanes_by_size(label, min_height=40):
+    """ May need some tuning """
+    filtered_lanes = []
+    for lane in label['lanes']:
+        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        if (lane_end - lane_start) < min_height:
+            continue
+        filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _filter_few_markers(label, min_markers=2):
+    """Filter lines that consist of only few markers"""
+    filtered_lanes = []
+    for lane in label['lanes']:
+        if len(lane['markers']) >= min_markers:
+            filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _fix_lane_names(label):
+    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
+
+    # Create mapping
+    l_counter = 0
+    r_counter = 0
+    mapping = {}
+    lane_ids = [lane['lane_id'] for lane in label['lanes']]
+    for key in sorted(lane_ids):
+        if key[0] == 'l':
+            mapping[key] = 'l' + str(l_counter)
+            l_counter += 1
+        if key[0] == 'r':
+            mapping[key] = 'r' + str(r_counter)
+            r_counter += 1
+    for lane in label['lanes']:
+        lane['lane_id'] = mapping[lane['lane_id']]
+
+
+def read_json(json_path, min_lane_height=20):
+    """ Reads and cleans label file information by path"""
+    with open(json_path, 'r') as jf:
+        label_content = json.load(jf)
+
+    _filter_lanes_by_size(label_content, min_height=min_lane_height)
+    _filter_few_markers(label_content, min_markers=2)
+    _fix_lane_names(label_content)
+
+    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
+
+    for lane in content['lanes']:
+        for marker in lane['markers']:
+            for pixel_key in marker['pixel_start'].keys():
+                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
+            for pixel_key in marker['pixel_end'].keys():
+                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
+            for pixel_key in marker['world_start'].keys():
+                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
+            for pixel_key in marker['world_end'].keys():
+                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
+    return content
+
+
+def ir(some_value):
+    """ Rounds and casts to int
+    Useful for pixel values that cannot be floats
+    Parameters
+    ----------
+    some_value : float
+                 numeric value
+    Returns
+    --------
+    Rounded integer
+    Raises
+    ------
+    ValueError for non scalar types
+    """
+    return int(round(some_value))
+
+
+# End code under the previous license
diff --git a/lib/datasets/nolabel_dataset.py b/lib/datasets/nolabel_dataset.py
index c8af627..1b3705b 100644
--- a/lib/datasets/nolabel_dataset.py
+++ b/lib/datasets/nolabel_dataset.py
@@ -1,44 +1,44 @@
-import glob
-
-import numpy as np
-
-
-class NoLabelDataset(object):
-    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
-        self.root = root
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = img_w, img_h
-        self.img_ext = img_ext
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        # On NoLabelDataset, always force it
-        self.max_lanes = max_lanes
-        self.max_points = 1
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def load_annotations(self):
-        self.annotations = []
-        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
-        print('Looking for image files with the pattern', pattern)
-        for file in glob.glob(pattern, recursive=True):
-            self.annotations.append({'lanes': [], 'path': file})
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import glob
+
+import numpy as np
+
+
+class NoLabelDataset(object):
+    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
+        self.root = root
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = img_w, img_h
+        self.img_ext = img_ext
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        # On NoLabelDataset, always force it
+        self.max_lanes = max_lanes
+        self.max_points = 1
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def load_annotations(self):
+        self.annotations = []
+        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
+        print('Looking for image files with the pattern', pattern)
+        for file in glob.glob(pattern, recursive=True):
+            self.annotations.append({'lanes': [], 'path': file})
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..55690dc 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -1,137 +1,137 @@
-import os
-import json
-import random
-
-import numpy as np
-from tabulate import tabulate
-
-from utils.lane import LaneEval
-from utils.metric import eval_json
-
-SPLIT_FILES = {
-    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
-    'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
-    'test': ['test_label.json'],
-}
-
-
-class TuSimple(object):
-    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
-        self.split = split
-        self.root = root
-        self.metric = metric
-
-        if split not in SPLIT_FILES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
-
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = 1280, 720
-        self.max_points = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return 720
-
-    def get_img_width(self, path):
-        return 1280
-
-    def get_metrics(self, lanes, idx):
-        label = self.annotations[idx]
-        org_anno = label['old_anno']
-        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
-        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
-
-        return matches, accs, dist
-
-    def pred2lanes(self, path, pred, y_samples):
-        ys = np.array(y_samples) / self.img_h
-        lanes = []
-        for lane in pred:
-            if lane[0] == 0:
-                continue
-            lane_pred = np.polyval(lane[3:], ys) * self.img_w
-            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
-            lanes.append(list(lane_pred))
-
-        return lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        max_lanes = 0
-        for anno_file in self.anno_files:
-            with open(anno_file, 'r') as anno_obj:
-                lines = anno_obj.readlines()
-            for line in lines:
-                data = json.loads(line)
-                y_samples = data['h_samples']
-                gt_lanes = data['lanes']
-                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
-                lanes = [lane for lane in lanes if len(lane) > 0]
-                max_lanes = max(max_lanes, len(lanes))
-                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
-                self.annotations.append({
-                    'path': os.path.join(self.root, data['raw_file']),
-                    'org_path': data['raw_file'],
-                    'org_lanes': gt_lanes,
-                    'lanes': lanes,
-                    'aug': False,
-                    'y_samples': y_samples
-                })
-
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-        print('total annos', len(self.annotations))
-        self.max_lanes = max_lanes
-
-    def transform_annotations(self, transform):
-        self.annotations = list(map(transform, self.annotations))
-
-    def pred2tusimpleformat(self, idx, pred, runtime):
-        runtime *= 1000.  # s to ms
-        img_name = self.annotations[idx]['old_anno']['org_path']
-        h_samples = self.annotations[idx]['old_anno']['y_samples']
-        lanes = self.pred2lanes(img_name, pred, h_samples)
-        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
-        return json.dumps(output)
-
-    def save_tusimple_predictions(self, predictions, runtimes, filename):
-        lines = []
-        for idx in range(len(predictions)):
-            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
-            lines.append(line)
-        with open(filename, 'w') as output_file:
-            output_file.write('\n'.join(lines))
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
-        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
-        if self.metric == 'default':
-            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
-        elif self.metric == 'ours':
-            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
-        table = {}
-        for metric in result:
-            table[metric['name']] = [metric['value']]
-        table = tabulate(table, headers='keys')
-
-        if not only_metrics:
-            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
-            with open(os.path.join(exp_dir, filename), 'w') as out_file:
-                json.dump(result, out_file)
-
-        return table, result
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import json
+import random
+
+import numpy as np
+from tabulate import tabulate
+
+from utils.lane import LaneEval
+from utils.metric import eval_json
+
+SPLIT_FILES = {
+    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
+    'train': ['label_data_0313.json', 'label_data_0601.json'],
+    'val': ['test_label.json'],
+    'test': ['test_label.json'],
+}
+
+
+class TuSimple(object):
+    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
+        self.split = split
+        self.root = root
+        self.metric = metric
+
+        if split not in SPLIT_FILES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
+
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = 1280, 720
+        self.max_points = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return 720
+
+    def get_img_width(self, path):
+        return 1280
+
+    def get_metrics(self, lanes, idx):
+        label = self.annotations[idx]
+        org_anno = label['old_anno']
+        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
+        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
+
+        return matches, accs, dist
+
+    def pred2lanes(self, path, pred, y_samples):
+        ys = np.array(y_samples) / self.img_h
+        lanes = []
+        for lane in pred:
+            if lane[0] == 0:
+                continue
+            lane_pred = np.polyval(lane[3:], ys) * self.img_w
+            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
+            lanes.append(list(lane_pred))
+
+        return lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        max_lanes = 0
+        for anno_file in self.anno_files:
+            with open(anno_file, 'r') as anno_obj:
+                lines = anno_obj.readlines()
+            for line in lines:
+                data = json.loads(line)
+                y_samples = data['h_samples']
+                gt_lanes = data['lanes']
+                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
+                lanes = [lane for lane in lanes if len(lane) > 0]
+                max_lanes = max(max_lanes, len(lanes))
+                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
+                self.annotations.append({
+                    'path': os.path.join(self.root, data['raw_file']),
+                    'org_path': data['raw_file'],
+                    'org_lanes': gt_lanes,
+                    'lanes': lanes,
+                    'aug': False,
+                    'y_samples': y_samples
+                })
+
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+        print('total annos', len(self.annotations))
+        self.max_lanes = max_lanes
+
+    def transform_annotations(self, transform):
+        self.annotations = list(map(transform, self.annotations))
+
+    def pred2tusimpleformat(self, idx, pred, runtime):
+        runtime *= 1000.  # s to ms
+        img_name = self.annotations[idx]['old_anno']['org_path']
+        h_samples = self.annotations[idx]['old_anno']['y_samples']
+        lanes = self.pred2lanes(img_name, pred, h_samples)
+        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
+        return json.dumps(output)
+
+    def save_tusimple_predictions(self, predictions, runtimes, filename):
+        lines = []
+        for idx in range(len(predictions)):
+            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
+            lines.append(line)
+        with open(filename, 'w') as output_file:
+            output_file.write('\n'.join(lines))
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
+        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
+        if self.metric == 'default':
+            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
+        elif self.metric == 'ours':
+            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
+        table = {}
+        for metric in result:
+            table[metric['name']] = [metric['value']]
+        table = tabulate(table, headers='keys')
+
+        if not only_metrics:
+            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
+            with open(os.path.join(exp_dir, filename), 'w') as out_file:
+                json.dump(result, out_file)
+
+        return table, result
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/models.py b/lib/models.py
index 15eb117..ad6e599 100644
--- a/lib/models.py
+++ b/lib/models.py
@@ -1,160 +1,160 @@
-import torch
-import torch.nn as nn
-from torchvision.models import resnet34, resnet50, resnet101
-from efficientnet_pytorch import EfficientNet
-
-
-class OutputLayer(nn.Module):
-    def __init__(self, fc, num_extra):
-        super(OutputLayer, self).__init__()
-        self.regular_outputs_layer = fc
-        self.num_extra = num_extra
-        if num_extra > 0:
-            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
-
-    def forward(self, x):
-        regular_outputs = self.regular_outputs_layer(x)
-        if self.num_extra > 0:
-            extra_outputs = self.extra_outputs_layer(x)
-        else:
-            extra_outputs = None
-
-        return regular_outputs, extra_outputs
-
-
-class PolyRegression(nn.Module):
-    def __init__(self,
-                 num_outputs,
-                 backbone,
-                 pretrained,
-                 curriculum_steps=None,
-                 extra_outputs=0,
-                 share_top_y=True,
-                 pred_category=False):
-        super(PolyRegression, self).__init__()
-        if 'efficientnet' in backbone:
-            if pretrained:
-                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
-            else:
-                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
-            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
-        elif backbone == 'resnet34':
-            self.model = resnet34(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet50':
-            self.model = resnet50(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet101':
-            self.model = resnet101(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        else:
-            raise NotImplementedError()
-
-        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
-        self.share_top_y = share_top_y
-        self.extra_outputs = extra_outputs
-        self.pred_category = pred_category
-        self.sigmoid = nn.Sigmoid()
-
-    def forward(self, x, epoch=None, **kwargs):
-        output, extra_outputs = self.model(x, **kwargs)
-        for i in range(len(self.curriculum_steps)):
-            if epoch is not None and epoch < self.curriculum_steps[i]:
-                output[:, -len(self.curriculum_steps) + i] = 0
-        return output, extra_outputs
-
-    def decode(self, all_outputs, labels, conf_threshold=0.5):
-        outputs, extra_outputs = all_outputs
-        if extra_outputs is not None:
-            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
-            extra_outputs = extra_outputs.argmax(dim=2)
-        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
-        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
-        outputs[outputs[:, :, 0] < conf_threshold] = 0
-
-        if False and self.share_top_y:
-            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
-
-        return outputs, extra_outputs
-
-    def loss(self,
-             outputs,
-             target,
-             conf_weight=1,
-             lower_weight=1,
-             upper_weight=1,
-             cls_weight=1,
-             poly_weight=300,
-             threshold=15 / 720.):
-        pred, extra_outputs = outputs
-        bce = nn.BCELoss()
-        mse = nn.MSELoss()
-        s = nn.Sigmoid()
-        threshold = nn.Threshold(threshold**2, 0.)
-        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
-        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
-        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
-        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
-        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
-
-        if self.share_top_y:
-            # inexistent lanes have -1e-5 as lower
-            # i'm just setting it to a high value here so that the .min below works fine
-            target_lowers[target_lowers < 0] = 1
-            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
-            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
-
-        target_lowers = target_lowers.reshape((-1, 1))
-        pred_lowers = pred_lowers.reshape((-1, 1))
-
-        target_confs = (target_categories > 0).float()
-        valid_lanes_idx = target_confs == 1
-        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
-        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
-        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
-
-        # classification loss
-        if self.pred_category and self.extra_outputs > 0:
-            ce = nn.CrossEntropyLoss()
-            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
-            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
-            pred_categories = pred_categories[target_categories > 0]
-            target_categories = target_categories[target_categories > 0]
-            cls_loss = ce(pred_categories, target_categories - 1)
-        else:
-            cls_loss = 0
-
-        # poly loss calc
-        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
-        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
-        valid_xs = target_xs >= 0
-        pred_polys = pred_polys[valid_lanes_idx_flat]
-        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
-        pred_xs.t_()
-        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
-        pred_xs = (pred_xs.t_() *
-                   weights).t()  # without this, lanes with more points would have more weight on the cost function
-        target_xs = (target_xs.t_() * weights).t()
-        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
-        poly_loss = threshold(
-            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
-
-        # applying weights to partial losses
-        poly_loss = poly_loss * poly_weight
-        lower_loss = lower_loss * lower_weight
-        upper_loss = upper_loss * upper_weight
-        cls_loss = cls_loss * cls_weight
-        conf_loss = bce(pred_confs, target_confs) * conf_weight
-
-        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
-
-        return loss, {
-            'conf': conf_loss,
-            'lower': lower_loss,
-            'upper': upper_loss,
-            'poly': poly_loss,
-            'cls_loss': cls_loss
-        }
+import torch
+import torch.nn as nn
+from torchvision.models import resnet34, resnet50, resnet101
+from efficientnet_pytorch import EfficientNet
+
+
+class OutputLayer(nn.Module):
+    def __init__(self, fc, num_extra):
+        super(OutputLayer, self).__init__()
+        self.regular_outputs_layer = fc
+        self.num_extra = num_extra
+        if num_extra > 0:
+            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
+
+    def forward(self, x):
+        regular_outputs = self.regular_outputs_layer(x)
+        if self.num_extra > 0:
+            extra_outputs = self.extra_outputs_layer(x)
+        else:
+            extra_outputs = None
+
+        return regular_outputs, extra_outputs
+
+
+class PolyRegression(nn.Module):
+    def __init__(self,
+                 num_outputs,
+                 backbone,
+                 pretrained,
+                 curriculum_steps=None,
+                 extra_outputs=0,
+                 share_top_y=True,
+                 pred_category=False):
+        super(PolyRegression, self).__init__()
+        if 'efficientnet' in backbone:
+            if pretrained:
+                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
+            else:
+                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
+            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
+        elif backbone == 'resnet34':
+            self.model = resnet34(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet50':
+            self.model = resnet50(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet101':
+            self.model = resnet101(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        else:
+            raise NotImplementedError()
+
+        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
+        self.share_top_y = share_top_y
+        self.extra_outputs = extra_outputs
+        self.pred_category = pred_category
+        self.sigmoid = nn.Sigmoid()
+
+    def forward(self, x, epoch=None, **kwargs):
+        output, extra_outputs = self.model(x, **kwargs)
+        for i in range(len(self.curriculum_steps)):
+            if epoch is not None and epoch < self.curriculum_steps[i]:
+                output[:, -len(self.curriculum_steps) + i] = 0
+        return output, extra_outputs
+
+    def decode(self, all_outputs, labels, conf_threshold=0.5):
+        outputs, extra_outputs = all_outputs
+        if extra_outputs is not None:
+            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
+            extra_outputs = extra_outputs.argmax(dim=2)
+        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
+        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
+        outputs[outputs[:, :, 0] < conf_threshold] = 0
+
+        if False and self.share_top_y:
+            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
+
+        return outputs, extra_outputs
+
+    def loss(self,
+             outputs,
+             target,
+             conf_weight=1,
+             lower_weight=1,
+             upper_weight=1,
+             cls_weight=1,
+             poly_weight=300,
+             threshold=15 / 720.):
+        pred, extra_outputs = outputs
+        bce = nn.BCELoss()
+        mse = nn.MSELoss()
+        s = nn.Sigmoid()
+        threshold = nn.Threshold(threshold**2, 0.)
+        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
+        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
+        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
+        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
+        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
+
+        if self.share_top_y:
+            # inexistent lanes have -1e-5 as lower
+            # i'm just setting it to a high value here so that the .min below works fine
+            target_lowers[target_lowers < 0] = 1
+            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
+            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
+
+        target_lowers = target_lowers.reshape((-1, 1))
+        pred_lowers = pred_lowers.reshape((-1, 1))
+
+        target_confs = (target_categories > 0).float()
+        valid_lanes_idx = target_confs == 1
+        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
+        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
+        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
+
+        # classification loss
+        if self.pred_category and self.extra_outputs > 0:
+            ce = nn.CrossEntropyLoss()
+            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
+            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
+            pred_categories = pred_categories[target_categories > 0]
+            target_categories = target_categories[target_categories > 0]
+            cls_loss = ce(pred_categories, target_categories - 1)
+        else:
+            cls_loss = 0
+
+        # poly loss calc
+        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
+        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
+        valid_xs = target_xs >= 0
+        pred_polys = pred_polys[valid_lanes_idx_flat]
+        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
+        pred_xs.t_()
+        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
+        pred_xs = (pred_xs.t_() *
+                   weights).t()  # without this, lanes with more points would have more weight on the cost function
+        target_xs = (target_xs.t_() * weights).t()
+        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
+        poly_loss = threshold(
+            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
+
+        # applying weights to partial losses
+        poly_loss = poly_loss * poly_weight
+        lower_loss = lower_loss * lower_weight
+        upper_loss = upper_loss * upper_weight
+        cls_loss = cls_loss * cls_weight
+        conf_loss = bce(pred_confs, target_confs) * conf_weight
+
+        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
+
+        return loss, {
+            'conf': conf_loss,
+            'lower': lower_loss,
+            'upper': upper_loss,
+            'poly': poly_loss,
+            'cls_loss': cls_loss
+        }
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..3ba5b3a 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,16 +1,15 @@
-lxml==4.6.2
-torchvision==0.5.0
-xmljson==0.2.0
-scipy==1.4.1
-tabulate==0.8.6
-numpy==1.18.1
-ujson==1.35
-matplotlib==3.1.3
-imgaug==0.4.0
-tqdm==4.43.0
-opencv_python==4.2.0.32
-efficientnet_pytorch==0.6.3
-torch==1.4.0
-progressbar33==2.4
-PyYAML==5.3.1
-scikit-learn==0.21.3
+lxml==4.6.2
+torchvision==0.5.0
+xmljson==0.2.0
+scipy==1.4.1
+tabulate==0.8.6
+numpy==1.18.1
+ujson==1.35
+matplotlib==3.1.3
+imgaug==0.4.0
+tqdm==4.43.0
+opencv_python==4.2.0.32
+efficientnet_pytorch==0.6.3
+progressbar33==2.4
+PyYAML==5.3.1
+scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..94b5e58 100644
--- a/test.py
+++ b/test.py
@@ -1,166 +1,166 @@
-import os
-import sys
-import random
-import logging
-import argparse
-import subprocess
-from time import time
-
-import cv2
-import numpy as np
-import torch
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
-    if verbose:
-        logging.info("Starting testing.")
-
-    # Test the model
-    if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
-
-    model.eval()
-    criterion_parameters = cfg.get_loss_parameters()
-    test_parameters = cfg.get_test_parameters()
-    criterion = model.loss
-    loss = 0
-    total_iters = 0
-    test_t0 = time()
-    loss_dict = {}
-    with torch.no_grad():
-        for idx, (images, labels, img_idxs) in enumerate(test_loader):
-            if max_batches is not None and idx >= max_batches:
-                break
-            if idx % 1 == 0 and verbose:
-                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
-            images = images.to(device)
-            labels = labels.to(device)
-
-            t0 = time()
-            outputs = model(images)
-            t = time() - t0
-            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            loss += loss_i.item()
-            total_iters += 1
-            for key in loss_dict_i:
-                if key not in loss_dict:
-                    loss_dict[key] = 0
-                loss_dict[key] += loss_dict_i[key]
-
-            outputs = model.decode(outputs, labels, **test_parameters)
-
-            if evaluator is not None:
-                lane_outputs, _ = outputs
-                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
-            if view:
-                outputs, extra_outputs = outputs
-                preds = test_loader.dataset.draw_annotation(
-                    idx,
-                    pred=outputs[0].cpu().numpy(),
-                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
-                cv2.imshow('pred', preds)
-                cv2.waitKey(0)
-
-    if verbose:
-        logging.info("Testing time: {:.4f}".format(time() - test_t0))
-    out_line = []
-    for key in loss_dict:
-        loss_dict[key] /= total_iters
-        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
-    if verbose:
-        logging.info(', '.join(out_line))
-
-    return evaluator, loss / total_iters
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Lane regression")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
-    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
-    parser.add_argument("--view", action="store_true", help="Show predictions")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    # Set up logging
-    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
-
-    # Model
-    model = cfg.get_model().to(device)
-    test_epoch = args.epoch
-
-    # Get data set
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size if args.view is False else 1,
-                                              shuffle=False,
-                                              num_workers=8)
-    # Eval results
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import logging
+import argparse
+import subprocess
+from time import time
+
+import cv2
+import numpy as np
+import torch
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
+    if verbose:
+        logging.info("Starting testing.")
+
+    # Test the model
+    if epoch > 0:
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+
+    model.eval()
+    criterion_parameters = cfg.get_loss_parameters()
+    test_parameters = cfg.get_test_parameters()
+    criterion = model.loss
+    loss = 0
+    total_iters = 0
+    test_t0 = time()
+    loss_dict = {}
+    with torch.no_grad():
+        for idx, (images, labels, img_idxs) in enumerate(test_loader):
+            if max_batches is not None and idx >= max_batches:
+                break
+            if idx % 1 == 0 and verbose:
+                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
+            images = images.to(device)
+            labels = labels.to(device)
+
+            t0 = time()
+            outputs = model(images)
+            t = time() - t0
+            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            loss += loss_i.item()
+            total_iters += 1
+            for key in loss_dict_i:
+                if key not in loss_dict:
+                    loss_dict[key] = 0
+                loss_dict[key] += loss_dict_i[key]
+
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            if evaluator is not None:
+                lane_outputs, _ = outputs
+                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
+            if view:
+                outputs, extra_outputs = outputs
+                preds = test_loader.dataset.draw_annotation(
+                    idx,
+                    pred=outputs[0].cpu().numpy(),
+                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+                cv2.imshow('pred', preds)
+                cv2.waitKey(0)
+
+    if verbose:
+        logging.info("Testing time: {:.4f}".format(time() - test_t0))
+    out_line = []
+    for key in loss_dict:
+        loss_dict[key] /= total_iters
+        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
+    if verbose:
+        logging.info(', '.join(out_line))
+
+    return evaluator, loss / total_iters
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
+    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
+    parser.add_argument("--view", action="store_true", help="Show predictions")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    # Set up logging
+    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
+
+    # Model
+    model = cfg.get_model().to(device)
+    test_epoch = args.epoch
+
+    # Get data set
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size if args.view is False else 1,
+                                              shuffle=False,
+                                              num_workers=8)
+    # Eval results
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/train.py b/train.py
index 3753aed..d066d7e 100644
--- a/train.py
+++ b/train.py
@@ -1,271 +1,271 @@
-import os
-import sys
-import random
-import shutil
-import logging
-import argparse
-import subprocess
-from time import time
-
-import numpy as np
-import torch
-
-from test import test
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
-    # Get initial train state
-    optimizer = cfg.get_optimizer(model.parameters())
-    scheduler = cfg.get_lr_scheduler(optimizer)
-    starting_epoch = 1
-
-    if train_state is not None:
-        model.load_state_dict(train_state['model'])
-        optimizer.load_state_dict(train_state['optimizer'])
-        scheduler.load_state_dict(train_state['lr_scheduler'])
-        starting_epoch = train_state['epoch'] + 1
-        scheduler.step(starting_epoch)
-
-    # Train the model
-    criterion_parameters = cfg.get_loss_parameters()
-    criterion = model.loss
-    total_step = len(train_loader)
-    ITER_LOG_INTERVAL = cfg['iter_log_interval']
-    ITER_TIME_WINDOW = cfg['iter_time_window']
-    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
-    t0 = time()
-    total_iter = 0
-    iter_times = []
-    logging.info("Starting training.")
-    for epoch in range(starting_epoch, num_epochs + 1):
-        epoch_t0 = time()
-        logging.info("Beginning epoch {}".format(epoch))
-        accum_loss = 0
-        for i, (images, labels, img_idxs) in enumerate(train_loader):
-            total_iter += 1
-            iter_t0 = time()
-            images = images.to(device)
-            labels = labels.to(device)
-
-            # Forward pass
-            outputs = model(images, epoch=epoch)
-            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            accum_loss += loss.item()
-
-            # Backward and optimize
-            optimizer.zero_grad()
-            loss.backward()
-            optimizer.step()
-
-            iter_times.append(time() - iter_t0)
-            if len(iter_times) > 100:
-                iter_times = iter_times[-ITER_TIME_WINDOW:]
-            if (i + 1) % ITER_LOG_INTERVAL == 0:
-                loss_str = ', '.join(
-                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
-                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
-                    epoch,
-                    num_epochs,
-                    i + 1,
-                    total_step,
-                    accum_loss / (i + 1),
-                    loss_str,
-                    np.mean(iter_times),
-                    optimizer.param_groups[0]["lr"],
-                ))
-        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
-        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
-            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
-            save_train_state(model_path, model, optimizer, scheduler, epoch)
-        if val_loader is not None:
-            evaluator = Evaluator(val_loader.dataset, exp_root)
-            evaluator, val_loss = test(
-                model,
-                val_loader,
-                evaluator,
-                None,
-                cfg,
-                view=False,
-                epoch=-1,
-                verbose=False,
-            )
-            _, results = evaluator.eval(label=None, only_metrics=True)
-            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
-            model.train()
-        scheduler.step()
-    logging.info("Training time: {:.4f}".format(time() - t0))
-
-    return model
-
-
-def save_train_state(path, model, optimizer, lr_scheduler, epoch):
-    train_state = {
-        'model': model.state_dict(),
-        'optimizer': optimizer.state_dict(),
-        'lr_scheduler': lr_scheduler.state_dict(),
-        'epoch': epoch
-    }
-
-    torch.save(train_state, path)
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--resume", action="store_true", help="Resume training")
-    parser.add_argument("--validate", action="store_true", help="Validate model during training")
-    parser.add_argument("--deterministic",
-                        action="store_true",
-                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def setup_exp_dir(exps_dir, exp_name, cfg_path):
-    dirs = ["models"]
-    exp_root = os.path.join(exps_dir, exp_name)
-
-    for dirname in dirs:
-        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
-
-    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
-    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
-        file.write(get_code_state())
-
-    return exp_root
-
-
-def get_exp_train_state(exp_root):
-    models_dir = os.path.join(exp_root, "models")
-    models = os.listdir(models_dir)
-    last_epoch, last_modelname = sorted(
-        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
-        key=lambda x: x[0],
-    )[-1]
-    train_state = torch.load(os.path.join(models_dir, last_modelname))
-
-    return train_state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    if args.deterministic:
-        torch.backends.cudnn.deterministic = True
-        torch.backends.cudnn.benchmark = False
-
-    # Set up experiment
-    if not args.resume:
-        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
-    else:
-        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Get data sets
-    train_dataset = cfg.get_dataset("train")
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"]
-
-    # Model
-    model = cfg.get_model().to(device)
-
-    train_state = None
-    if args.resume:
-        train_state = get_exp_train_state(exp_root)
-
-    # Data loader
-    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
-                                               batch_size=batch_size,
-                                               shuffle=True,
-                                               num_workers=8)
-
-    if args.validate:
-        val_dataset = cfg.get_dataset("val")
-        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
-                                                 batch_size=batch_size,
-                                                 shuffle=False,
-                                                 num_workers=8)
-    # Train regressor
-    try:
-        model = train(
-            model,
-            train_loader,
-            exp_root,
-            cfg,
-            val_loader=val_loader if args.validate else None,
-            train_state=train_state,
-        )
-    except KeyboardInterrupt:
-        logging.info("Training session terminated.")
-    test_epoch = -1
-    if cfg['backup'] is not None:
-        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
-
-    # Eval model after training
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size,
-                                              shuffle=False,
-                                              num_workers=8)
-
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import shutil
+import logging
+import argparse
+import subprocess
+from time import time
+
+import numpy as np
+import torch
+
+from test import test
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
+    # Get initial train state
+    optimizer = cfg.get_optimizer(model.parameters())
+    scheduler = cfg.get_lr_scheduler(optimizer)
+    starting_epoch = 1
+
+    if train_state is not None:
+        model.load_state_dict(train_state['model'])
+        optimizer.load_state_dict(train_state['optimizer'])
+        scheduler.load_state_dict(train_state['lr_scheduler'])
+        starting_epoch = train_state['epoch'] + 1
+        scheduler.step(starting_epoch)
+
+    # Train the model
+    criterion_parameters = cfg.get_loss_parameters()
+    criterion = model.loss
+    total_step = len(train_loader)
+    ITER_LOG_INTERVAL = cfg['iter_log_interval']
+    ITER_TIME_WINDOW = cfg['iter_time_window']
+    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
+    t0 = time()
+    total_iter = 0
+    iter_times = []
+    logging.info("Starting training.")
+    for epoch in range(starting_epoch, num_epochs + 1):
+        epoch_t0 = time()
+        logging.info("Beginning epoch {}".format(epoch))
+        accum_loss = 0
+        for i, (images, labels, img_idxs) in enumerate(train_loader):
+            total_iter += 1
+            iter_t0 = time()
+            images = images.to(device)
+            labels = labels.to(device)
+
+            # Forward pass
+            outputs = model(images, epoch=epoch)
+            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            accum_loss += loss.item()
+
+            # Backward and optimize
+            optimizer.zero_grad()
+            loss.backward()
+            optimizer.step()
+
+            iter_times.append(time() - iter_t0)
+            if len(iter_times) > 100:
+                iter_times = iter_times[-ITER_TIME_WINDOW:]
+            if (i + 1) % ITER_LOG_INTERVAL == 0:
+                loss_str = ', '.join(
+                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
+                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
+                    epoch,
+                    num_epochs,
+                    i + 1,
+                    total_step,
+                    accum_loss / (i + 1),
+                    loss_str,
+                    np.mean(iter_times),
+                    optimizer.param_groups[0]["lr"],
+                ))
+        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
+        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
+            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
+            save_train_state(model_path, model, optimizer, scheduler, epoch)
+        if val_loader is not None:
+            evaluator = Evaluator(val_loader.dataset, exp_root)
+            evaluator, val_loss = test(
+                model,
+                val_loader,
+                evaluator,
+                None,
+                cfg,
+                view=False,
+                epoch=-1,
+                verbose=False,
+            )
+            _, results = evaluator.eval(label=None, only_metrics=True)
+            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
+            model.train()
+        scheduler.step()
+    logging.info("Training time: {:.4f}".format(time() - t0))
+
+    return model
+
+
+def save_train_state(path, model, optimizer, lr_scheduler, epoch):
+    train_state = {
+        'model': model.state_dict(),
+        'optimizer': optimizer.state_dict(),
+        'lr_scheduler': lr_scheduler.state_dict(),
+        'epoch': epoch
+    }
+
+    torch.save(train_state, path)
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--resume", action="store_true", help="Resume training")
+    parser.add_argument("--validate", action="store_true", help="Validate model during training")
+    parser.add_argument("--deterministic",
+                        action="store_true",
+                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def setup_exp_dir(exps_dir, exp_name, cfg_path):
+    dirs = ["models"]
+    exp_root = os.path.join(exps_dir, exp_name)
+
+    for dirname in dirs:
+        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
+
+    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
+    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
+        file.write(get_code_state())
+
+    return exp_root
+
+
+def get_exp_train_state(exp_root):
+    models_dir = os.path.join(exp_root, "models")
+    models = os.listdir(models_dir)
+    last_epoch, last_modelname = sorted(
+        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
+        key=lambda x: x[0],
+    )[-1]
+    train_state = torch.load(os.path.join(models_dir, last_modelname))
+
+    return train_state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    if args.deterministic:
+        torch.backends.cudnn.deterministic = True
+        torch.backends.cudnn.benchmark = False
+
+    # Set up experiment
+    if not args.resume:
+        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
+    else:
+        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Get data sets
+    train_dataset = cfg.get_dataset("train")
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    # Model
+    model = cfg.get_model().to(device)
+
+    train_state = None
+    if args.resume:
+        train_state = get_exp_train_state(exp_root)
+
+    # Data loader
+    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
+                                               batch_size=batch_size,
+                                               shuffle=True,
+                                               num_workers=8)
+
+    if args.validate:
+        val_dataset = cfg.get_dataset("val")
+        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
+                                                 batch_size=batch_size,
+                                                 shuffle=False,
+                                                 num_workers=8)
+    # Train regressor
+    try:
+        model = train(
+            model,
+            train_loader,
+            exp_root,
+            cfg,
+            val_loader=val_loader if args.validate else None,
+            train_state=train_state,
+        )
+    except KeyboardInterrupt:
+        logging.info("Training session terminated.")
+    test_epoch = -1
+    if cfg['backup'] is not None:
+        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
+
+    # Eval model after training
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size,
+                                              shuffle=False,
+                                              num_workers=8)
+
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/utils/evaluator.py b/utils/evaluator.py
index b4d51a1..9793857 100644
--- a/utils/evaluator.py
+++ b/utils/evaluator.py
@@ -1,33 +1,33 @@
-import sys
-
-import numpy as np
-
-from lib.datasets.lane_dataset import LaneDataset
-
-EXPS_DIR = 'experiments'
-
-
-class Evaluator(object):
-    def __init__(self, dataset, exp_dir, poly_degree=3):
-        self.dataset = dataset
-        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
-        self.predictions = None
-        self.runtimes = np.zeros(len(dataset))
-        self.loss = np.zeros(len(dataset))
-        self.exp_dir = exp_dir
-        self.new_preds = False
-
-    def add_prediction(self, idx, pred, runtime):
-        if self.predictions is None:
-            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
-        self.predictions[idx, :pred.shape[1], :] = pred
-        self.runtimes[idx] = runtime
-        self.new_preds = True
-
-    def eval(self, **kwargs):
-        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
-
-
-if __name__ == "__main__":
-    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
-    evaluator.tusimple_eval()
+import sys
+
+import numpy as np
+
+from lib.datasets.lane_dataset import LaneDataset
+
+EXPS_DIR = 'experiments'
+
+
+class Evaluator(object):
+    def __init__(self, dataset, exp_dir, poly_degree=3):
+        self.dataset = dataset
+        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
+        self.predictions = None
+        self.runtimes = np.zeros(len(dataset))
+        self.loss = np.zeros(len(dataset))
+        self.exp_dir = exp_dir
+        self.new_preds = False
+
+    def add_prediction(self, idx, pred, runtime):
+        if self.predictions is None:
+            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
+        self.predictions[idx, :pred.shape[1], :] = pred
+        self.runtimes[idx] = runtime
+        self.new_preds = True
+
+    def eval(self, **kwargs):
+        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
+
+
+if __name__ == "__main__":
+    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
+    evaluator.tusimple_eval()
diff --git a/utils/gen_video.py b/utils/gen_video.py
index b4a3b4d..8dff9a8 100644
--- a/utils/gen_video.py
+++ b/utils/gen_video.py
@@ -1,67 +1,67 @@
-import pickle
-import argparse
-
-import cv2
-from tqdm import tqdm
-
-from lib.config import Config
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
-    parser.add_argument("--pred", help=".pkl file to load predictions from")
-    parser.add_argument("--cfg", default="config.yaml", help="Config file")
-    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
-    parser.add_argument("--out", default="video.avi", help="Output filename")
-    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
-
-    return parser.parse_args()
-
-
-def add_cover_img(video, cover_path, frames=90):
-    cover = cv2.imread(cover_path)
-    for _ in range(frames):
-        video.write(cover)
-
-
-def create_video(filename, width, height, fps=30):
-    fourcc = cv2.VideoWriter_fourcc(*'MP42')
-    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
-
-    return video
-
-
-def main():
-    args = parse_args()
-    cfg = Config(args.cfg)
-    dataset = cfg.get_dataset('test')
-    height, width = cfg['datasets']['test']['parameters']['img_size']
-    print('Using resolution {}x{}'.format(width, height))
-    if not args.view:
-        video = create_video(args.out, width, height)
-    # add_cover_img(video, args.cover)
-    with open(args.pred, "rb") as pred_file:
-        predictions = pickle.load(pred_file)
-
-    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
-        if idx < 2200: continue
-        if idx > 3000: break
-        det_pred, cls_pred = pred
-        assert det_pred.shape[0] == 1  # batch size == 1
-        frame = dataset.draw_annotation(idx,
-                                        pred=det_pred[0].cpu().numpy(),
-                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
-        assert frame.shape[:2] == (height, width)
-        if args.view:
-            cv2.imshow('frame', frame)
-            cv2.waitKey(0)
-        else:
-            video.write(frame)
-
-    if not args.view:
-        video.release()
-        print('Video saved as {}'.format(args.out))
-
-
-if __name__ == '__main__':
-    main()
+import pickle
+import argparse
+
+import cv2
+from tqdm import tqdm
+
+from lib.config import Config
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
+    parser.add_argument("--pred", help=".pkl file to load predictions from")
+    parser.add_argument("--cfg", default="config.yaml", help="Config file")
+    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
+    parser.add_argument("--out", default="video.avi", help="Output filename")
+    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
+
+    return parser.parse_args()
+
+
+def add_cover_img(video, cover_path, frames=90):
+    cover = cv2.imread(cover_path)
+    for _ in range(frames):
+        video.write(cover)
+
+
+def create_video(filename, width, height, fps=30):
+    fourcc = cv2.VideoWriter_fourcc(*'MP42')
+    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
+
+    return video
+
+
+def main():
+    args = parse_args()
+    cfg = Config(args.cfg)
+    dataset = cfg.get_dataset('test')
+    height, width = cfg['datasets']['test']['parameters']['img_size']
+    print('Using resolution {}x{}'.format(width, height))
+    if not args.view:
+        video = create_video(args.out, width, height)
+    # add_cover_img(video, args.cover)
+    with open(args.pred, "rb") as pred_file:
+        predictions = pickle.load(pred_file)
+
+    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
+        if idx < 2200: continue
+        if idx > 3000: break
+        det_pred, cls_pred = pred
+        assert det_pred.shape[0] == 1  # batch size == 1
+        frame = dataset.draw_annotation(idx,
+                                        pred=det_pred[0].cpu().numpy(),
+                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
+        assert frame.shape[:2] == (height, width)
+        if args.view:
+            cv2.imshow('frame', frame)
+            cv2.waitKey(0)
+        else:
+            video.write(frame)
+
+    if not args.view:
+        video.release()
+        print('Video saved as {}'.format(args.out))
+
+
+if __name__ == '__main__':
+    main()
diff --git a/utils/lane.py b/utils/lane.py
index 863a92a..6fd2a7d 100644
--- a/utils/lane.py
+++ b/utils/lane.py
@@ -1,133 +1,133 @@
-import numpy as np
-import ujson as json
-from sklearn.linear_model import LinearRegression
-
-
-class LaneEval(object):
-    lr = LinearRegression()
-    pixel_thresh = 20
-    pt_thresh = 0.85
-
-    @staticmethod
-    def get_angle(xs, y_samples):
-        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
-        if len(xs) > 1:
-            LaneEval.lr.fit(ys[:, None], xs)
-            k = LaneEval.lr.coef_[0]
-            theta = np.arctan(k)
-        else:
-            theta = 0
-        return theta
-
-    @staticmethod
-    def line_accuracy(pred, gt, thresh):
-        pred = np.array([p if p >= 0 else -100 for p in pred])
-        gt = np.array([g if g >= 0 else -100 for g in gt])
-        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
-
-    @staticmethod
-    def distances(pred, gt):
-        return np.abs(pred - gt)
-
-    @staticmethod
-    def bench(pred, gt, y_samples, running_time, get_matches=False):
-        if any(len(p) != len(y_samples) for p in pred):
-            raise Exception('Format of lanes error.')
-        if running_time > 20000 or len(gt) + 2 < len(pred):
-            return 0., 0., 1.
-        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
-        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
-        line_accs = []
-        fp, fn = 0., 0.
-        matched = 0.
-        my_matches = [False] * len(pred)
-        my_accs = [0] * len(pred)
-        my_dists = [None] * len(pred)
-        for x_gts, thresh in zip(gt, threshs):
-            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
-            my_accs = np.maximum(my_accs, accs)
-            max_acc = np.max(accs) if len(accs) > 0 else 0.
-            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
-            if len(accs) > 0:
-                my_dists[np.argmax(accs)] = {
-                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
-                    'dists': list(my_dist[np.argmax(accs)])
-                }
-
-            if max_acc < LaneEval.pt_thresh:
-                fn += 1
-            else:
-                my_matches[np.argmax(accs)] = True
-                matched += 1
-            line_accs.append(max_acc)
-        fp = len(pred) - matched
-        if len(gt) > 4 and fn > 0:
-            fn -= 1
-        s = sum(line_accs)
-        if len(gt) > 4:
-            s -= min(line_accs)
-        if get_matches:
-            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
-                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
-        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
-
-    @staticmethod
-    def bench_one_submit(pred_file, gt_file):
-        try:
-            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-        except BaseException as e:
-            raise Exception('Fail to load json file of the prediction.')
-        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-        if len(json_gt) != len(json_pred):
-            raise Exception('We do not get the predictions of all the test tasks')
-        gts = {l['raw_file']: l for l in json_gt}
-        accuracy, fp, fn = 0., 0., 0.
-        run_times = []
-        for pred in json_pred:
-            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
-                raise Exception('raw_file or lanes or run_time not in some predictions.')
-            raw_file = pred['raw_file']
-            pred_lanes = pred['lanes']
-            run_time = pred['run_time']
-            run_times.append(run_time)
-            if raw_file not in gts:
-                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-            gt = gts[raw_file]
-            gt_lanes = gt['lanes']
-            y_samples = gt['h_samples']
-            try:
-                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
-            except BaseException as e:
-                raise Exception('Format of lanes error.')
-            accuracy += a
-            fp += p
-            fn += n
-        num = len(gts)
-        # the first return parameter is the default ranking parameter
-        return json.dumps([{
-            'name': 'Accuracy',
-            'value': accuracy / num,
-            'order': 'desc'
-        }, {
-            'name': 'FP',
-            'value': fp / num,
-            'order': 'asc'
-        }, {
-            'name': 'FN',
-            'value': fn / num,
-            'order': 'asc'
-        }, {
-            'name': 'FPS',
-            'value': 1000. / np.mean(run_times)
-        }])
-
-
-if __name__ == '__main__':
-    import sys
-    try:
-        if len(sys.argv) != 3:
-            raise Exception('Invalid input arguments')
-        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
-    except Exception as e:
-        print(e)
-        # sys.exit(e.message)
+import numpy as np
+import ujson as json
+from sklearn.linear_model import LinearRegression
+
+
+class LaneEval(object):
+    lr = LinearRegression()
+    pixel_thresh = 20
+    pt_thresh = 0.85
+
+    @staticmethod
+    def get_angle(xs, y_samples):
+        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
+        if len(xs) > 1:
+            LaneEval.lr.fit(ys[:, None], xs)
+            k = LaneEval.lr.coef_[0]
+            theta = np.arctan(k)
+        else:
+            theta = 0
+        return theta
+
+    @staticmethod
+    def line_accuracy(pred, gt, thresh):
+        pred = np.array([p if p >= 0 else -100 for p in pred])
+        gt = np.array([g if g >= 0 else -100 for g in gt])
+        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
+
+    @staticmethod
+    def distances(pred, gt):
+        return np.abs(pred - gt)
+
+    @staticmethod
+    def bench(pred, gt, y_samples, running_time, get_matches=False):
+        if any(len(p) != len(y_samples) for p in pred):
+            raise Exception('Format of lanes error.')
+        if running_time > 20000 or len(gt) + 2 < len(pred):
+            return 0., 0., 1.
+        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
+        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
+        line_accs = []
+        fp, fn = 0., 0.
+        matched = 0.
+        my_matches = [False] * len(pred)
+        my_accs = [0] * len(pred)
+        my_dists = [None] * len(pred)
+        for x_gts, thresh in zip(gt, threshs):
+            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
+            my_accs = np.maximum(my_accs, accs)
+            max_acc = np.max(accs) if len(accs) > 0 else 0.
+            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
+            if len(accs) > 0:
+                my_dists[np.argmax(accs)] = {
+                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
+                    'dists': list(my_dist[np.argmax(accs)])
+                }
+
+            if max_acc < LaneEval.pt_thresh:
+                fn += 1
+            else:
+                my_matches[np.argmax(accs)] = True
+                matched += 1
+            line_accs.append(max_acc)
+        fp = len(pred) - matched
+        if len(gt) > 4 and fn > 0:
+            fn -= 1
+        s = sum(line_accs)
+        if len(gt) > 4:
+            s -= min(line_accs)
+        if get_matches:
+            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
+                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
+        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
+
+    @staticmethod
+    def bench_one_submit(pred_file, gt_file):
+        try:
+            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+        except BaseException as e:
+            raise Exception('Fail to load json file of the prediction.')
+        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+        if len(json_gt) != len(json_pred):
+            raise Exception('We do not get the predictions of all the test tasks')
+        gts = {l['raw_file']: l for l in json_gt}
+        accuracy, fp, fn = 0., 0., 0.
+        run_times = []
+        for pred in json_pred:
+            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
+                raise Exception('raw_file or lanes or run_time not in some predictions.')
+            raw_file = pred['raw_file']
+            pred_lanes = pred['lanes']
+            run_time = pred['run_time']
+            run_times.append(run_time)
+            if raw_file not in gts:
+                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+            gt = gts[raw_file]
+            gt_lanes = gt['lanes']
+            y_samples = gt['h_samples']
+            try:
+                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
+            except BaseException as e:
+                raise Exception('Format of lanes error.')
+            accuracy += a
+            fp += p
+            fn += n
+        num = len(gts)
+        # the first return parameter is the default ranking parameter
+        return json.dumps([{
+            'name': 'Accuracy',
+            'value': accuracy / num,
+            'order': 'desc'
+        }, {
+            'name': 'FP',
+            'value': fp / num,
+            'order': 'asc'
+        }, {
+            'name': 'FN',
+            'value': fn / num,
+            'order': 'asc'
+        }, {
+            'name': 'FPS',
+            'value': 1000. / np.mean(run_times)
+        }])
+
+
+if __name__ == '__main__':
+    import sys
+    try:
+        if len(sys.argv) != 3:
+            raise Exception('Invalid input arguments')
+        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
+    except Exception as e:
+        print(e)
+        # sys.exit(e.message)
diff --git a/utils/metric.py b/utils/metric.py
index f2c066d..9fe866e 100644
--- a/utils/metric.py
+++ b/utils/metric.py
@@ -1,177 +1,177 @@
-import argparse
-from pprint import pprint
-
-import cv2
-import numpy as np
-import ujson as json
-from tqdm import tqdm
-from tabulate import tabulate
-from scipy.spatial import distance
-
-
-def show_preds(pred, gt):
-    img = np.zeros((720, 1280, 3), dtype=np.uint8)
-    print(len(gt), 'gts and', len(pred), 'preds')
-    for lane in gt:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
-    for lane in pred:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
-    cv2.imshow('img', img)
-    cv2.waitKey(0)
-
-
-def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
-    pred = np.vstack([pred_x, pred_y]).T
-    gt = np.vstack([gt_x, gt_y]).T
-
-    # pred = pred[pred[:, 0] > 0][:3, :]
-    # gt = gt[gt[:, 0] > 0][:5, :]
-
-    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
-
-    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
-    dist /= np.max(gt_y) - np.min(gt_y)
-    return dist
-
-
-def area_metric(pred, gt, debug=None):
-    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    if len(pred) == 0:
-        return 0., 0., len(gt)
-    line_dists = []
-    fp = 0.
-    matched = 0.
-    gt_matches = [False] * len(gt)
-    pred_matches = [False] * len(pred)
-    pred_dists = [None] * len(pred)
-
-    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
-    for i_gt, gt_points in enumerate(gt):
-        x_gts = [x for x, _ in gt_points]
-        y_gts = [y for _, y in gt_points]
-        for i_pred, pred_points in enumerate(pred):
-            x_preds = [x for x, _ in pred_points]
-            y_preds = [y for _, y in pred_points]
-            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
-
-    best_preds = np.argmin(distances, axis=1)
-    best_gts = np.argmin(distances, axis=0)
-    fp = 0.
-    fn = 0.
-    dist = 0.
-    is_fp = []
-    is_fn = []
-    for i_pred, best_gt in enumerate(best_gts):
-        if best_preds[best_gt] == i_pred:
-            dist += distances[best_gt, i_pred]
-            is_fp.append(False)
-        else:
-            fp += 1
-            is_fp.append(True)
-    for i_gt, best_pred in enumerate(best_preds):
-        if best_gts[best_pred] != i_gt:
-            fn += 1
-            is_fn.append(True)
-        else:
-            is_fn.append(False)
-    if debug:
-        print('is fp')
-        print(is_fp)
-        print('is fn')
-        print(is_fn)
-        print('distances')
-        dists = np.min(distances, axis=0)
-        dists[np.array(is_fp)] = 0
-        print(dists)
-        show_preds(pred, gt)
-
-    return dist, fp, fn
-
-
-def convert_tusimple_format(json_gt):
-    output = []
-    for data in json_gt:
-        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
-                 if any(x > 0 for x in lane)]
-        output.append({
-            'raw_file': data['raw_file'],
-            'run_time': data['run_time'] if 'run_time' in data else None,
-            'lanes': lanes
-        })
-    return output
-
-
-def eval_json(pred_file, gt_file, json_type=None, debug=False):
-    try:
-        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-    except BaseException as e:
-        raise Exception('Fail to load json file of the prediction.')
-    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-    if len(json_gt) != len(json_pred):
-        raise Exception('We do not get the predictions of all the test tasks')
-
-    if json_type == 'tusimple':
-        for gt, pred in zip(json_gt, json_pred):
-            pred['h_samples'] = gt['h_samples']
-        json_gt = convert_tusimple_format(json_gt)
-        json_pred = convert_tusimple_format(json_pred)
-    gts = {l['raw_file']: l for l in json_gt}
-
-    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
-    for pred in tqdm(json_pred):
-        if 'raw_file' not in pred or 'lanes' not in pred:
-            raise Exception('raw_file or lanes not in some predictions.')
-        raw_file = pred['raw_file']
-        pred_lanes = pred['lanes']
-        run_time += pred['run_time'] if 'run_time' in pred else 1.
-
-        if raw_file not in gts:
-            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-        gt = gts[raw_file]
-        gt_lanes = gt['lanes']
-
-        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
-
-        total_distance += distance
-        total_fp += fp
-        total_fn += fn
-
-    num = len(gts)
-    return json.dumps([{
-        'name': 'Distance',
-        'value': total_distance / num,
-        'order': 'desc'
-    }, {
-        'name': 'FP',
-        'value': total_fp,
-        'order': 'asc'
-    }, {
-        'name': 'FN',
-        'value': total_fn,
-        'order': 'asc'
-    }, {
-        'name': 'FPS',
-        'value': 1000. * num / run_time
-    }])
-
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(description="Compute the metrics")
-    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
-    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
-    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
-    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
-    argv = vars(parser.parse_args())
-
-    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
-
-    # pretty-print
-    table = {}
-    for metric in result:
-        if metric['name'] not in table.keys():
-            table[metric['name']] = []
-        table[metric['name']].append(metric['value'])
-    print(tabulate(table, headers='keys'))
+import argparse
+from pprint import pprint
+
+import cv2
+import numpy as np
+import ujson as json
+from tqdm import tqdm
+from tabulate import tabulate
+from scipy.spatial import distance
+
+
+def show_preds(pred, gt):
+    img = np.zeros((720, 1280, 3), dtype=np.uint8)
+    print(len(gt), 'gts and', len(pred), 'preds')
+    for lane in gt:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
+    for lane in pred:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
+    cv2.imshow('img', img)
+    cv2.waitKey(0)
+
+
+def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
+    pred = np.vstack([pred_x, pred_y]).T
+    gt = np.vstack([gt_x, gt_y]).T
+
+    # pred = pred[pred[:, 0] > 0][:3, :]
+    # gt = gt[gt[:, 0] > 0][:5, :]
+
+    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
+
+    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
+    dist /= np.max(gt_y) - np.min(gt_y)
+    return dist
+
+
+def area_metric(pred, gt, debug=None):
+    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    if len(pred) == 0:
+        return 0., 0., len(gt)
+    line_dists = []
+    fp = 0.
+    matched = 0.
+    gt_matches = [False] * len(gt)
+    pred_matches = [False] * len(pred)
+    pred_dists = [None] * len(pred)
+
+    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
+    for i_gt, gt_points in enumerate(gt):
+        x_gts = [x for x, _ in gt_points]
+        y_gts = [y for _, y in gt_points]
+        for i_pred, pred_points in enumerate(pred):
+            x_preds = [x for x, _ in pred_points]
+            y_preds = [y for _, y in pred_points]
+            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
+
+    best_preds = np.argmin(distances, axis=1)
+    best_gts = np.argmin(distances, axis=0)
+    fp = 0.
+    fn = 0.
+    dist = 0.
+    is_fp = []
+    is_fn = []
+    for i_pred, best_gt in enumerate(best_gts):
+        if best_preds[best_gt] == i_pred:
+            dist += distances[best_gt, i_pred]
+            is_fp.append(False)
+        else:
+            fp += 1
+            is_fp.append(True)
+    for i_gt, best_pred in enumerate(best_preds):
+        if best_gts[best_pred] != i_gt:
+            fn += 1
+            is_fn.append(True)
+        else:
+            is_fn.append(False)
+    if debug:
+        print('is fp')
+        print(is_fp)
+        print('is fn')
+        print(is_fn)
+        print('distances')
+        dists = np.min(distances, axis=0)
+        dists[np.array(is_fp)] = 0
+        print(dists)
+        show_preds(pred, gt)
+
+    return dist, fp, fn
+
+
+def convert_tusimple_format(json_gt):
+    output = []
+    for data in json_gt:
+        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
+                 if any(x > 0 for x in lane)]
+        output.append({
+            'raw_file': data['raw_file'],
+            'run_time': data['run_time'] if 'run_time' in data else None,
+            'lanes': lanes
+        })
+    return output
+
+
+def eval_json(pred_file, gt_file, json_type=None, debug=False):
+    try:
+        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+    except BaseException as e:
+        raise Exception('Fail to load json file of the prediction.')
+    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+    if len(json_gt) != len(json_pred):
+        raise Exception('We do not get the predictions of all the test tasks')
+
+    if json_type == 'tusimple':
+        for gt, pred in zip(json_gt, json_pred):
+            pred['h_samples'] = gt['h_samples']
+        json_gt = convert_tusimple_format(json_gt)
+        json_pred = convert_tusimple_format(json_pred)
+    gts = {l['raw_file']: l for l in json_gt}
+
+    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
+    for pred in tqdm(json_pred):
+        if 'raw_file' not in pred or 'lanes' not in pred:
+            raise Exception('raw_file or lanes not in some predictions.')
+        raw_file = pred['raw_file']
+        pred_lanes = pred['lanes']
+        run_time += pred['run_time'] if 'run_time' in pred else 1.
+
+        if raw_file not in gts:
+            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+        gt = gts[raw_file]
+        gt_lanes = gt['lanes']
+
+        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
+
+        total_distance += distance
+        total_fp += fp
+        total_fn += fn
+
+    num = len(gts)
+    return json.dumps([{
+        'name': 'Distance',
+        'value': total_distance / num,
+        'order': 'desc'
+    }, {
+        'name': 'FP',
+        'value': total_fp,
+        'order': 'asc'
+    }, {
+        'name': 'FN',
+        'value': total_fn,
+        'order': 'asc'
+    }, {
+        'name': 'FPS',
+        'value': 1000. * num / run_time
+    }])
+
+
+if __name__ == '__main__':
+    parser = argparse.ArgumentParser(description="Compute the metrics")
+    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
+    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
+    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
+    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
+    argv = vars(parser.parse_args())
+
+    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
+
+    # pretty-print
+    table = {}
+    for metric in result:
+        if metric['name'] not in table.keys():
+            table[metric['name']] = []
+        table[metric['name']].append(metric['value'])
+    print(tabulate(table, headers='keys'))
diff --git a/utils/plot_log.py b/utils/plot_log.py
index ee18cf1..aaba69a 100644
--- a/utils/plot_log.py
+++ b/utils/plot_log.py
@@ -1,161 +1,161 @@
-import os
-import re
-import argparse
-import datetime
-
-import numpy as np
-import matplotlib.dates as mdates
-import matplotlib.colors as colors
-import matplotlib.pyplot as plt
-
-ITER_PATTERN = re.compile(
-    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
-)
-LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
-EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
-EXPS_DIR = '../data_lane-regression/experiments'
-
-# TODO: refactor this file
-
-
-def smooth_curve(xs, factor):
-    smoothed = [None] * len(xs)
-    smoothed[0] = xs[0]
-    for i in range(1, len(xs)):
-        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
-
-    return smoothed
-
-
-def plot_loss(data,
-              fig,
-              ax,
-              label,
-              plot_lr=True,
-              smoothing=0,
-              xaxis='time',
-              only_epoch_end=False,
-              plot_val=False,
-              plot_loss_comps=False):
-    iter_data = data['iter_update']
-    epoch_data = data['epoch_update']
-    now = datetime.datetime.today()
-    if xaxis == 'epoch':
-        if only_epoch_end:
-            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
-        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
-    elif xaxis == 'time':
-        d0 = iter_data[0]['date']
-        x = [now + (d['date'] - d0) for d in iter_data]
-    elif xaxis == 'iter':
-        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
-    loss = [d['loss'] for d in iter_data]
-    if plot_loss_comps:
-        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
-    if plot_val:
-        val_loss = [d['val_loss'] for d in epoch_data]
-        if xaxis == 'epoch':
-            val_loss_x = [d['epoch'] for d in epoch_data]
-        else:
-            val_loss_d0 = epoch_data[0]['date']
-            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
-    loss_smooth = smooth_curve(loss, factor=smoothing)
-    if plot_lr:
-        lr = [d['lr'] for d in iter_data]
-        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
-                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
-        if len(lr_decays) < 10:
-            for epoch, old, new in lr_decays:
-                ax.axvline(x=epoch, linestyle='--')
-        ax.plot(x, lr, label='LR: {}'.format(label))
-    ax.set_yscale('log')
-    ax.set_title('Loss')
-    ax.set_xlabel('Epoch')
-    ax.set_ylabel('Loss')
-    loss_line = ax.plot(x, loss_smooth)[0]
-    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
-    loss_line_color[-1] = 0.5
-    if plot_loss_comps:
-        for loss_comp in loss_comps:
-            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
-            line_color = np.array(colors.to_rgba(line.get_color()))
-            line_color[-1] = 0.5
-            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
-    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
-    if plot_val:
-        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
-    if xaxis == 'time':
-        fig.autofmt_xdate()
-        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
-
-
-def parse_line(line):
-    iter_match = re.match(ITER_PATTERN, line)
-    epoch_match = re.match(EPOCH_PATTERN, line)
-    data = {}
-    if iter_match is not None:
-        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
-        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
-            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
-                loss), float(speed), float(lr)
-        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
-        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
-        data['iter_update'] = {
-            'date': date,
-            'epoch': epoch,
-            'total_epochs': total_epochs,
-            'iter_nb': iter_nb,
-            'total_iters': total_iters,
-            'loss': loss,
-            'speed': date,
-            'loss_comps': loss_comps,
-            'lr': lr,
-        }
-    if epoch_match is not None:
-        date, epoch, _, val_loss = epoch_match.groups()
-        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
-        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
-
-    return data
-
-
-def parse_log(log_path):
-    with open(log_path, 'r') as log_file:
-        lines = [line.rstrip() for line in log_file.readlines()]
-    data = {'iter_update': [], 'epoch_update': []}
-    for line in lines:
-        line_data = parse_line(line)
-        for key in line_data:
-            data[key].append(line_data[key])
-    return data
-
-
-def get_logfilepath(exp_name):
-    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description='Visualization')
-    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
-    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
-    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
-
-    return parser.parse_args()
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    fig, ax = plt.subplots(nrows=1, ncols=1)
-    for exp_name in args.exp_name:
-        log_filepath = get_logfilepath(exp_name)
-        data = parse_log(log_filepath)
-        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
-
-    # Show the major grid lines with dark grey lines
-    plt.grid(b=True, which='major', color='#666666', linestyle='-')
-
-    # Show the minor grid lines with very faint and almost transparent grey lines
-    plt.minorticks_on()
-    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
-    plt.legend()
-    plt.show()
+import os
+import re
+import argparse
+import datetime
+
+import numpy as np
+import matplotlib.dates as mdates
+import matplotlib.colors as colors
+import matplotlib.pyplot as plt
+
+ITER_PATTERN = re.compile(
+    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
+)
+LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
+EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
+EXPS_DIR = '../data_lane-regression/experiments'
+
+# TODO: refactor this file
+
+
+def smooth_curve(xs, factor):
+    smoothed = [None] * len(xs)
+    smoothed[0] = xs[0]
+    for i in range(1, len(xs)):
+        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
+
+    return smoothed
+
+
+def plot_loss(data,
+              fig,
+              ax,
+              label,
+              plot_lr=True,
+              smoothing=0,
+              xaxis='time',
+              only_epoch_end=False,
+              plot_val=False,
+              plot_loss_comps=False):
+    iter_data = data['iter_update']
+    epoch_data = data['epoch_update']
+    now = datetime.datetime.today()
+    if xaxis == 'epoch':
+        if only_epoch_end:
+            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
+        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
+    elif xaxis == 'time':
+        d0 = iter_data[0]['date']
+        x = [now + (d['date'] - d0) for d in iter_data]
+    elif xaxis == 'iter':
+        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
+    loss = [d['loss'] for d in iter_data]
+    if plot_loss_comps:
+        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
+    if plot_val:
+        val_loss = [d['val_loss'] for d in epoch_data]
+        if xaxis == 'epoch':
+            val_loss_x = [d['epoch'] for d in epoch_data]
+        else:
+            val_loss_d0 = epoch_data[0]['date']
+            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
+    loss_smooth = smooth_curve(loss, factor=smoothing)
+    if plot_lr:
+        lr = [d['lr'] for d in iter_data]
+        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
+                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
+        if len(lr_decays) < 10:
+            for epoch, old, new in lr_decays:
+                ax.axvline(x=epoch, linestyle='--')
+        ax.plot(x, lr, label='LR: {}'.format(label))
+    ax.set_yscale('log')
+    ax.set_title('Loss')
+    ax.set_xlabel('Epoch')
+    ax.set_ylabel('Loss')
+    loss_line = ax.plot(x, loss_smooth)[0]
+    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
+    loss_line_color[-1] = 0.5
+    if plot_loss_comps:
+        for loss_comp in loss_comps:
+            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
+            line_color = np.array(colors.to_rgba(line.get_color()))
+            line_color[-1] = 0.5
+            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
+    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
+    if plot_val:
+        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
+    if xaxis == 'time':
+        fig.autofmt_xdate()
+        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
+
+
+def parse_line(line):
+    iter_match = re.match(ITER_PATTERN, line)
+    epoch_match = re.match(EPOCH_PATTERN, line)
+    data = {}
+    if iter_match is not None:
+        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
+        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
+            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
+                loss), float(speed), float(lr)
+        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
+        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
+        data['iter_update'] = {
+            'date': date,
+            'epoch': epoch,
+            'total_epochs': total_epochs,
+            'iter_nb': iter_nb,
+            'total_iters': total_iters,
+            'loss': loss,
+            'speed': date,
+            'loss_comps': loss_comps,
+            'lr': lr,
+        }
+    if epoch_match is not None:
+        date, epoch, _, val_loss = epoch_match.groups()
+        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
+        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
+
+    return data
+
+
+def parse_log(log_path):
+    with open(log_path, 'r') as log_file:
+        lines = [line.rstrip() for line in log_file.readlines()]
+    data = {'iter_update': [], 'epoch_update': []}
+    for line in lines:
+        line_data = parse_line(line)
+        for key in line_data:
+            data[key].append(line_data[key])
+    return data
+
+
+def get_logfilepath(exp_name):
+    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description='Visualization')
+    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
+    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
+    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
+
+    return parser.parse_args()
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    fig, ax = plt.subplots(nrows=1, ncols=1)
+    for exp_name in args.exp_name:
+        log_filepath = get_logfilepath(exp_name)
+        data = parse_log(log_filepath)
+        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
+
+    # Show the major grid lines with dark grey lines
+    plt.grid(b=True, which='major', color='#666666', linestyle='-')
+
+    # Show the minor grid lines with very faint and almost transparent grey lines
+    plt.minorticks_on()
+    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
+    plt.legend()
+    plt.show()
diff --git a/utils/upperbound.py b/utils/upperbound.py
index 78af9b3..1fbce9e 100644
--- a/utils/upperbound.py
+++ b/utils/upperbound.py
@@ -1,44 +1,44 @@
-import sys
-import warnings
-
-import numpy as np
-from progressbar import progressbar
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-warnings.simplefilter('ignore', np.RankWarning)
-
-
-def polyfit_upperbound(dataset, degree):
-    evaluator = Evaluator(dataset, '/tmp', degree)
-    print('Predicting with upperbound...')
-    for i, anno in enumerate(progressbar(dataset.annotations)):
-        label = anno['label']
-        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
-        pred[:, :3] = label[:, :3]
-        for j, lane in enumerate(label):
-            if lane[0] == 0:
-                continue
-            xy = lane[3:]
-            x = xy[:(len(xy) // 2)]
-            y = xy[(len(xy) // 2):]
-            ind = x > 0
-            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
-        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
-    _, result = evaluator.eval(label='upperbound', only_metrics=True)
-
-    return result
-
-
-if __name__ == "__main__":
-    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
-    dataset = cfg.get_dataset('test')
-    for n in range(1, 5 + 1):
-        result = polyfit_upperbound(dataset, n)
-        print('Degree {} upperbound:'.format(n))
-        for metric in result:
-            if metric['name'] == 'Accuracy':
-                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
-            else:
-                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))
+import sys
+import warnings
+
+import numpy as np
+from progressbar import progressbar
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+warnings.simplefilter('ignore', np.RankWarning)
+
+
+def polyfit_upperbound(dataset, degree):
+    evaluator = Evaluator(dataset, '/tmp', degree)
+    print('Predicting with upperbound...')
+    for i, anno in enumerate(progressbar(dataset.annotations)):
+        label = anno['label']
+        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
+        pred[:, :3] = label[:, :3]
+        for j, lane in enumerate(label):
+            if lane[0] == 0:
+                continue
+            xy = lane[3:]
+            x = xy[:(len(xy) // 2)]
+            y = xy[(len(xy) // 2):]
+            ind = x > 0
+            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
+        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
+    _, result = evaluator.eval(label='upperbound', only_metrics=True)
+
+    return result
+
+
+if __name__ == "__main__":
+    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
+    dataset = cfg.get_dataset('test')
+    for n in range(1, 5 + 1):
+        result = polyfit_upperbound(dataset, n)
+        print('Degree {} upperbound:'.format(n))
+        for metric in result:
+            if metric['name'] == 'Accuracy':
+                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
+            else:
+                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))

[2021-08-04 23:35:47,972] [INFO] Starting testing.
[2021-08-04 23:35:48,197] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 159, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 23, in test
    model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
  File "/mnt/d/linux/miniconda3/envs/PolyLaneNet/lib/python3.6/site-packages/torch/serialization.py", line 529, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/mnt/d/linux/miniconda3/envs/PolyLaneNet/lib/python3.6/site-packages/torch/serialization.py", line 702, in _legacy_load
    result = unpickler.load()
  File "/mnt/d/linux/miniconda3/envs/PolyLaneNet/lib/python3.6/site-packages/torch/serialization.py", line 665, in persistent_load
    deserialized_objects[root_key] = restore_location(obj, location)
  File "/mnt/d/linux/miniconda3/envs/PolyLaneNet/lib/python3.6/site-packages/torch/serialization.py", line 156, in default_restore_location
    result = fn(storage, location)
  File "/mnt/d/linux/miniconda3/envs/PolyLaneNet/lib/python3.6/site-packages/torch/serialization.py", line 132, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/mnt/d/linux/miniconda3/envs/PolyLaneNet/lib/python3.6/site-packages/torch/serialization.py", line 116, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2021-08-04 23:37:53,260] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-04 23:37:53,260] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-04 23:37:53,263] [INFO] Args:
Namespace(batch_size=None, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-04 23:37:54,232] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/.gitignore b/.gitignore
index e4bcbf2..fdf6f3f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,8 +1,8 @@
-__pycache__
-experiments
-.vscode
-venv
-config.yaml
-/datasets/
-lib/nms/build/
-lib/nms/dist/
+__pycache__
+experiments
+.vscode
+venv
+config.yaml
+/datasets/
+lib/nms/build/
+lib/nms/dist/
diff --git a/LICENSE b/LICENSE
index f8fe53d..33d52bc 100644
--- a/LICENSE
+++ b/LICENSE
@@ -1,21 +1,21 @@
-MIT License
-
-Copyright (c) 2020 Lucas Tabelini Torres
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+MIT License
+
+Copyright (c) 2020 Lucas Tabelini Torres
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
diff --git a/README.md b/README.md
index b4af404..d49fcb0 100644
--- a/README.md
+++ b/README.md
@@ -1,165 +1,166 @@
-<div align="center">
-
-# PolyLaneNet
-![Method overview](figures/method-overview.png "Method overview")
-</div>
-
-## Description
-Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
-[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
-
-**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
-
-## Table of Contents
-1. [Installation](#installation)
-2. [Usage](#usage)
-3. [Reproducing the paper results](#reproducing)
-
-<a name="installation"/>
-
-### Installation
-The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
-
-Install dependencies:
-```
-pip install -r requirements.txt
-```
-
-<a name="usage"/>
-
-### Usage
-#### Training
-Every setting for a training is set through a YAML configuration file.
-Thus, in order to train a model you will have to setup the configuration file.
-An example is shown:
-```yaml
-# Training settings
-exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
-iter_log_interval: 1 # Log training iteration every N iterations
-iter_time_window: 100 # Moving average iterations window for the printed loss metric
-model_save_interval: 1 # Save model every N epochs
-seed: 0 # Seed for randomness
-backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
-
-# Dataset settings
-datasets:
-  train:
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: # ImgAug augmentations
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "datasets/tusimple" # Dataset root
-
-  test: &test
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      img_size: [360, 640]
-      root: "datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
-```
-
-With the config file created, run the training script:
-```bash
-python train.py --exp_name tusimple --cfg config.yaml
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the training (.yaml)
-  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
-  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
-  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
-```
-
-#### Testing
-After training, run the `test.py` script to get the metrics:
-```bash
-python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
-  --epoch EPOCH         Epoch to test the model on
-  --batch_size          Number of images per batch
-  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
-```
-
-If you have any issues with either training or testing feel free to open an issue.
-
-<a name="reproducing"/>
-
-### Reproducing the paper results
-
-#### Models
-All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
-
-#### Datasets
-- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
-- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
-- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
-
-#### How to
-To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
-If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
-If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
-1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
-1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
-1. Move the downloaded experiment to your `exps_dir` folder.
-
-Then, run:
-
-```bash
-python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
-```
-Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
-
-
+<div align="center">
+
+# PolyLaneNet
+![Method overview](figures/method-overview.png "Method overview")
+</div>
+
+## Description
+Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
+[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
+
+**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
+
+## Table of Contents
+1. [Installation](#installation)
+2. [Usage](#usage)
+3. [Reproducing the paper results](#reproducing)
+
+<a name="installation"/>
+
+### Installation
+The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
+
+Install dependencies:
+```
+pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
+```
+
+<a name="usage"/>
+
+### Usage
+#### Training
+Every setting for a training is set through a YAML configuration file.
+Thus, in order to train a model you will have to setup the configuration file.
+An example is shown:
+```yaml
+# Training settings
+exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
+iter_log_interval: 1 # Log training iteration every N iterations
+iter_time_window: 100 # Moving average iterations window for the printed loss metric
+model_save_interval: 1 # Save model every N epochs
+seed: 0 # Seed for randomness
+backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
+
+# Dataset settings
+datasets:
+  train:
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: # ImgAug augmentations
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "datasets/tusimple" # Dataset root
+
+  test: &test
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      img_size: [360, 640]
+      root: "datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
+```
+
+With the config file created, run the training script:
+```bash
+python train.py --exp_name tusimple --cfg config.yaml
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the training (.yaml)
+  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
+  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
+  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
+```
+
+#### Testing
+After training, run the `test.py` script to get the metrics:
+```bash
+python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
+  --epoch EPOCH         Epoch to test the model on
+  --batch_size          Number of images per batch
+  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
+```
+
+If you have any issues with either training or testing feel free to open an issue.
+
+<a name="reproducing"/>
+
+### Reproducing the paper results
+
+#### Models
+All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
+
+#### Datasets
+- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
+- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
+- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
+
+#### How to
+To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
+If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
+If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
+1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
+1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
+1. Move the downloaded experiment to your `exps_dir` folder.
+
+Then, run:
+
+```bash
+python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
+```
+Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
+
+
diff --git a/cfgs/elas.yaml b/cfgs/elas.yaml
index 98a03bd..8d9f910 100644
--- a/cfgs/elas.yaml
+++ b/cfgs/elas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 35
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 35
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 35
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 35
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/elas_cls.yaml b/cfgs/elas_cls.yaml
index a251b94..db6d9c8 100644
--- a/cfgs/elas_cls.yaml
+++ b/cfgs/elas_cls.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: true
-    extra_outputs: 40 # 5 lanes * 8 classes
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 1
-  poly_weight: 300
-batch_size: 16
-epochs: 385
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: true
+    extra_outputs: 40 # 5 lanes * 8 classes
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 1
+  poly_weight: 300
+batch_size: 16
+epochs: 385
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/llamas.yaml b/cfgs/llamas.yaml
index 5806168..1af205d 100644
--- a/cfgs/llamas.yaml
+++ b/cfgs/llamas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 75
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 75
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: llamas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/llamas"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: llamas
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/llamas"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 75
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 75
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: llamas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/llamas"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: llamas
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/llamas"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple.yaml b/cfgs/tusimple.yaml
index 01da72b..2a13cb1 100644
--- a/cfgs/tusimple.yaml
+++ b/cfgs/tusimple.yaml
@@ -1,73 +1,73 @@
-# Training settings
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-seed: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+seed: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_1order.yaml b/cfgs/tusimple_1order.yaml
index 66a8607..3e5f617 100644
--- a/cfgs/tusimple_1order.yaml
+++ b/cfgs/tusimple_1order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 1 
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 9000, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression//datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression//datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 1 
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 9000, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression//datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression//datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_2order.yaml b/cfgs/tusimple_2order.yaml
index 9091dcc..2e3cdca 100644
--- a/cfgs/tusimple_2order.yaml
+++ b/cfgs/tusimple_2order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_320x180.yaml b/cfgs/tusimple_320x180.yaml
index fb61010..32b8f5e 100644
--- a/cfgs/tusimple_320x180.yaml
+++ b/cfgs/tusimple_320x180.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [180, 320]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [180, 320]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [180, 320]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [180, 320]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_480x270.yaml b/cfgs/tusimple_480x270.yaml
index e9077d4..3312074 100644
--- a/cfgs/tusimple_480x270.yaml
+++ b/cfgs/tusimple_480x270.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [270, 480]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [270, 480]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [270, 480]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [270, 480]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_efficientnetb1.yaml b/cfgs/tusimple_efficientnetb1.yaml
index f085635..b1a080a 100644
--- a/cfgs/tusimple_efficientnetb1.yaml
+++ b/cfgs/tusimple_efficientnetb1.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b1'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b1'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_fulltrain.yaml b/cfgs/tusimple_fulltrain.yaml
index 0c0f485..69dfe67 100644
--- a/cfgs/tusimple_fulltrain.yaml
+++ b/cfgs/tusimple_fulltrain.yaml
@@ -1,72 +1,72 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train+val
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple-test"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train+val
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple-test"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_no_share_top_y.yaml b/cfgs/tusimple_no_share_top_y.yaml
index ec81eb2..e1081a5 100644
--- a/cfgs/tusimple_no_share_top_y.yaml
+++ b/cfgs/tusimple_no_share_top_y.yaml
@@ -1,74 +1,74 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    share_top_y: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    share_top_y: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_noaug.yaml b/cfgs/tusimple_noaug.yaml
index 8b4b9db..edd5362 100644
--- a/cfgs/tusimple_noaug.yaml
+++ b/cfgs/tusimple_noaug.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: []
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: []
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_nopretrain.yaml b/cfgs/tusimple_nopretrain.yaml
index 0de222f..ccf039f 100644
--- a/cfgs/tusimple_nopretrain.yaml
+++ b/cfgs/tusimple_nopretrain.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: false 
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: false 
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet34.yaml b/cfgs/tusimple_resnet34.yaml
index 6eafef9..753dc12 100644
--- a/cfgs/tusimple_resnet34.yaml
+++ b/cfgs/tusimple_resnet34.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet34'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet34'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet50.yaml b/cfgs/tusimple_resnet50.yaml
index 58784a8..a32ef90 100644
--- a/cfgs/tusimple_resnet50.yaml
+++ b/cfgs/tusimple_resnet50.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet50'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "/dados/tabelini/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "/dados/tabelini/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet50'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "/dados/tabelini/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "/dados/tabelini/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/lib/config.py b/lib/config.py
index d5d6275..e9405c9 100644
--- a/lib/config.py
+++ b/lib/config.py
@@ -1,45 +1,45 @@
-import yaml
-import torch
-
-import lib.models as models
-import lib.datasets as datasets
-
-
-class Config(object):
-    def __init__(self, config_path):
-        self.config = {}
-        self.load(config_path)
-
-    def load(self, path):
-        with open(path, 'r') as file:
-            self.config_str = file.read()
-        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
-
-    def __repr__(self):
-        return self.config_str
-
-    def get_dataset(self, split):
-        return getattr(datasets,
-                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
-
-    def get_model(self):
-        name = self.config['model']['name']
-        parameters = self.config['model']['parameters']
-        return getattr(models, name)(**parameters)
-
-    def get_optimizer(self, model_parameters):
-        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
-                                                                      **self.config['optimizer']['parameters'])
-
-    def get_lr_scheduler(self, optimizer):
-        return getattr(torch.optim.lr_scheduler,
-                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
-
-    def get_loss_parameters(self):
-        return self.config['loss_parameters']
-
-    def get_test_parameters(self):
-        return self.config['test_parameters']
-
-    def __getitem__(self, item):
-        return self.config[item]
+import yaml
+import torch
+
+import lib.models as models
+import lib.datasets as datasets
+
+
+class Config(object):
+    def __init__(self, config_path):
+        self.config = {}
+        self.load(config_path)
+
+    def load(self, path):
+        with open(path, 'r') as file:
+            self.config_str = file.read()
+        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
+
+    def __repr__(self):
+        return self.config_str
+
+    def get_dataset(self, split):
+        return getattr(datasets,
+                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
+
+    def get_model(self):
+        name = self.config['model']['name']
+        parameters = self.config['model']['parameters']
+        return getattr(models, name)(**parameters)
+
+    def get_optimizer(self, model_parameters):
+        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
+                                                                      **self.config['optimizer']['parameters'])
+
+    def get_lr_scheduler(self, optimizer):
+        return getattr(torch.optim.lr_scheduler,
+                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
+
+    def get_loss_parameters(self):
+        return self.config['loss_parameters']
+
+    def get_test_parameters(self):
+        return self.config['test_parameters']
+
+    def __getitem__(self, item):
+        return self.config[item]
diff --git a/lib/datasets/__init__.py b/lib/datasets/__init__.py
index bc2eb7a..a870757 100644
--- a/lib/datasets/__init__.py
+++ b/lib/datasets/__init__.py
@@ -1,3 +1,3 @@
-from .lane_dataset import LaneDataset
-
-__all__ = ["LaneDataset"]
+from .lane_dataset import LaneDataset
+
+__all__ = ["LaneDataset"]
diff --git a/lib/datasets/elas.py b/lib/datasets/elas.py
index 490f37a..c2a0823 100644
--- a/lib/datasets/elas.py
+++ b/lib/datasets/elas.py
@@ -1,137 +1,137 @@
-import os
-import math
-import random
-
-import cv2
-import numpy as np
-import xmljson
-from scipy import interpolate
-from lxml.etree import fromstring
-
-SPLIT_DIRECTORIES = {
-    'train': [
-        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
-        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
-    ],
-    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
-}
-
-CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
-ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
-
-
-class ELAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.root = root
-        self.split = split
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_directories = SPLIT_DIRECTORIES[split]
-
-        self.img_w, self.img_h = 640, 480
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-        self.class_icons = {
-            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
-            for cls_id in ID_TO_CATEGORY
-        }
-
-    def get_class_icon(self, cls_id):
-        return self.class_icons[cls_id]
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def interp_lane(self, lane, ys, step=10):
-        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
-        if len(pts) <= 1:
-            return None
-        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
-        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
-        interp_xs = interpolate.splev(interp_ys, spline)
-
-        return list(zip(interp_xs, interp_ys))
-
-    def load_dir_annotations(self, dataset_dir):
-        annotations = []
-        max_points = 0
-        max_lanes = 0
-
-        # read config.xml
-        config_fname = os.path.join(dataset_dir, 'config.xml')
-        if not os.path.isfile(config_fname):
-            raise Exception('config.xml not found: {}'.format(config_fname))
-        with open(config_fname, 'r') as hf:
-            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
-
-        # read ground truth
-        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
-        if not os.path.isfile(gt_fname):
-            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
-        with open(gt_fname, 'r') as hf:
-            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
-
-        # read frame annotations
-        for frame in gt['frames']['frame']:
-            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
-
-            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
-            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
-            pts = ['p1', 'p2', 'p3', 'p4']
-            lanes = []
-            categories = []
-            for side in ['Left', 'Right']:
-                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
-                lane = self.interp_lane(lane, ys)
-                if lane is None:
-                    continue
-                max_points = max(max_points, len(lane))
-                lanes.append(lane)
-                category = str(frame['@lmt{}'.format(side)])
-                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
-            max_lanes = max(max_lanes, len(lanes))
-            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
-
-        return annotations, max_points, max_lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        for directory in self.anno_directories:
-            dir_path = os.path.join(self.root, directory)
-            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
-
-            self.annotations.extend(dir_annos)
-            self.max_points = max(self.max_points, dir_max_points)
-            self.max_lanes = max(self.max_lanes, dir_max_lanes)
-
-        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
-                                                                            self.max_lanes))
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import math
+import random
+
+import cv2
+import numpy as np
+import xmljson
+from scipy import interpolate
+from lxml.etree import fromstring
+
+SPLIT_DIRECTORIES = {
+    'train': [
+        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
+        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
+    ],
+    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
+}
+
+CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
+ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
+
+
+class ELAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.root = root
+        self.split = split
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_directories = SPLIT_DIRECTORIES[split]
+
+        self.img_w, self.img_h = 640, 480
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+        self.class_icons = {
+            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
+            for cls_id in ID_TO_CATEGORY
+        }
+
+    def get_class_icon(self, cls_id):
+        return self.class_icons[cls_id]
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def interp_lane(self, lane, ys, step=10):
+        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
+        if len(pts) <= 1:
+            return None
+        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
+        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
+        interp_xs = interpolate.splev(interp_ys, spline)
+
+        return list(zip(interp_xs, interp_ys))
+
+    def load_dir_annotations(self, dataset_dir):
+        annotations = []
+        max_points = 0
+        max_lanes = 0
+
+        # read config.xml
+        config_fname = os.path.join(dataset_dir, 'config.xml')
+        if not os.path.isfile(config_fname):
+            raise Exception('config.xml not found: {}'.format(config_fname))
+        with open(config_fname, 'r') as hf:
+            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
+
+        # read ground truth
+        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
+        if not os.path.isfile(gt_fname):
+            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
+        with open(gt_fname, 'r') as hf:
+            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
+
+        # read frame annotations
+        for frame in gt['frames']['frame']:
+            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
+
+            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
+            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
+            pts = ['p1', 'p2', 'p3', 'p4']
+            lanes = []
+            categories = []
+            for side in ['Left', 'Right']:
+                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
+                lane = self.interp_lane(lane, ys)
+                if lane is None:
+                    continue
+                max_points = max(max_points, len(lane))
+                lanes.append(lane)
+                category = str(frame['@lmt{}'.format(side)])
+                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
+            max_lanes = max(max_lanes, len(lanes))
+            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
+
+        return annotations, max_points, max_lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        for directory in self.anno_directories:
+            dir_path = os.path.join(self.root, directory)
+            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
+
+            self.annotations.extend(dir_annos)
+            self.max_points = max(self.max_points, dir_max_points)
+            self.max_lanes = max(self.max_lanes, dir_max_lanes)
+
+        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
+                                                                            self.max_lanes))
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..1f520dc 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -1,239 +1,239 @@
-import cv2
-import numpy as np
-import imgaug.augmenters as iaa
-from imgaug.augmenters import Resize
-from torchvision.transforms import ToTensor
-from torch.utils.data.dataset import Dataset
-from imgaug.augmentables.lines import LineString, LineStringsOnImage
-
-from .elas import ELAS
-from .llamas import LLAMAS
-from .tusimple import TuSimple
-from .nolabel_dataset import NoLabelDataset
-
-GT_COLOR = (255, 0, 0)
-PRED_HIT_COLOR = (0, 255, 0)
-PRED_MISS_COLOR = (0, 0, 255)
-IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
-IMAGENET_STD = np.array([0.229, 0.224, 0.225])
-
-
-class LaneDataset(Dataset):
-    def __init__(self,
-                 dataset='tusimple',
-                 augmentations=None,
-                 normalize=False,
-                 split='train',
-                 img_size=(360, 640),
-                 aug_chance=1.,
-                 **kwargs):
-        super(LaneDataset, self).__init__()
-        if dataset == 'tusimple':
-            self.dataset = TuSimple(split=split, **kwargs)
-        elif dataset == 'llamas':
-            self.dataset = LLAMAS(split=split, **kwargs)
-        elif dataset == 'elas':
-            self.dataset = ELAS(split=split, **kwargs)
-        elif dataset == 'nolabel_dataset':
-            self.dataset = NoLabelDataset(**kwargs)
-        else:
-            raise NotImplementedError()
-
-        self.transform_annotations()
-        self.img_h, self.img_w = img_size
-
-        if augmentations is not None:
-            # add augmentations
-            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
-                             for aug in augmentations]  # add augmentation
-
-        self.normalize = normalize
-        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
-        self.to_tensor = ToTensor()
-        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
-        self.max_lanes = self.dataset.max_lanes
-
-    def transform_annotation(self, anno, img_wh=None):
-        if img_wh is None:
-            img_h = self.dataset.get_img_heigth(anno['path'])
-            img_w = self.dataset.get_img_width(anno['path'])
-        else:
-            img_w, img_h = img_wh
-
-        old_lanes = anno['lanes']
-        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
-        old_lanes = zip(old_lanes, categories)
-        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
-        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
-        lanes[:, 0] = 0
-        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
-        for lane_pos, (lane, category) in enumerate(old_lanes):
-            lower, upper = lane[0][1], lane[-1][1]
-            xs = np.array([p[0] for p in lane]) / img_w
-            ys = np.array([p[1] for p in lane]) / img_h
-            lanes[lane_pos, 0] = category
-            lanes[lane_pos, 1] = lower / img_h
-            lanes[lane_pos, 2] = upper / img_h
-            lanes[lane_pos, 3:3 + len(xs)] = xs
-            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
-
-        new_anno = {
-            'path': anno['path'],
-            'label': lanes,
-            'old_anno': anno,
-            'categories': [cat for _, cat in old_lanes]
-        }
-
-        return new_anno
-
-    @property
-    def annotations(self):
-        return self.dataset.annotations
-
-    def transform_annotations(self):
-        print('Transforming annotations...')
-        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
-        print('Done.')
-
-    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
-        if img is None:
-            img, label, _ = self.__getitem__(idx, transform=True)
-            # Tensor to opencv image
-            img = img.permute(1, 2, 0).numpy()
-            # Unnormalize
-            if self.normalize:
-                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
-            img = (img * 255).astype(np.uint8)
-        else:
-            _, label, _ = self.__getitem__(idx)
-
-        img_h, img_w, _ = img.shape
-
-        # Draw label
-        for i, lane in enumerate(label):
-            if lane[0] == 0:  # Skip invalid lanes
-                continue
-            lane = lane[3:]  # remove conf, upper and lower positions
-            xs = lane[:len(lane) // 2]
-            ys = lane[len(lane) // 2:]
-            ys = ys[xs >= 0]
-            xs = xs[xs >= 0]
-
-            # draw GT points
-            for p in zip(xs, ys):
-                p = (int(p[0] * img_w), int(p[1] * img_h))
-                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
-
-            # draw GT lane ID
-            cv2.putText(img,
-                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
-                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                        fontScale=1,
-                        color=(0, 255, 0))
-
-        if pred is None:
-            return img
-
-        # Draw predictions
-        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
-        matches, accs, _ = self.dataset.get_metrics(pred, idx)
-        overlay = img.copy()
-        for i, lane in enumerate(pred):
-            if matches[i]:
-                color = PRED_HIT_COLOR
-            else:
-                color = PRED_MISS_COLOR
-            lane = lane[1:]  # remove conf
-            lower, upper = lane[0], lane[1]
-            lane = lane[2:]  # remove upper, lower positions
-
-            # generate points from the polynomial
-            ys = np.linspace(lower, upper, num=100)
-            points = np.zeros((len(ys), 2), dtype=np.int32)
-            points[:, 1] = (ys * img_h).astype(int)
-            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
-            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
-
-            # draw lane with a polyline on the overlay
-            for current_point, next_point in zip(points[:-1], points[1:]):
-                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
-
-            # draw class icon
-            if cls_pred is not None and len(points) > 0:
-                class_icon = self.dataset.get_class_icon(cls_pred[i])
-                class_icon = cv2.resize(class_icon, (32, 32))
-                mid = tuple(points[len(points) // 2] - 60)
-                x, y = mid
-
-                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
-
-            # draw lane ID
-            if len(points) > 0:
-                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
-
-            # draw lane accuracy
-            if len(points) > 0:
-                cv2.putText(img,
-                            '{:.2f}'.format(accs[i] * 100),
-                            tuple(points[len(points) // 2] - 30),
-                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                            fontScale=.75,
-                            color=color)
-        # Add lanes overlay
-        w = 0.6
-        img = ((1. - w) * img + w * overlay).astype(np.uint8)
-
-        return img
-
-    def lane_to_linestrings(self, lanes):
-        lines = []
-        for lane in lanes:
-            lines.append(LineString(lane))
-
-        return lines
-
-    def linestrings_to_lanes(self, lines):
-        lanes = []
-        for line in lines:
-            lanes.append(line.coords)
-
-        return lanes
-
-    def __getitem__(self, idx, transform=True):
-        item = self.dataset[idx]
-        img = cv2.imread(item['path'])
-        label = item['label']
-        if transform:
-            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
-            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
-            img, line_strings = self.transform(image=img, line_strings=line_strings)
-            line_strings.clip_out_of_image_()
-            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
-            new_anno['categories'] = item['categories']
-            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
-
-        img = img / 255.
-        if self.normalize:
-            img = (img - IMAGENET_MEAN) / IMAGENET_STD
-        img = self.to_tensor(img.astype(np.float32))
-        return (img, label, idx)
-
-    def __len__(self):
-        return len(self.dataset)
-
-
-def main():
-    import torch
-    from lib.config import Config
-    np.random.seed(0)
-    torch.manual_seed(0)
-    cfg = Config('config.yaml')
-    train_dataset = cfg.get_dataset('train')
-    for idx in range(len(train_dataset)):
-        img = train_dataset.draw_annotation(idx)
-        cv2.imshow('sample', img)
-        cv2.waitKey(0)
-
-
-if __name__ == "__main__":
-    main()
+import cv2
+import numpy as np
+import imgaug.augmenters as iaa
+from imgaug.augmenters import Resize
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+from imgaug.augmentables.lines import LineString, LineStringsOnImage
+
+from .elas import ELAS
+from .llamas import LLAMAS
+from .tusimple import TuSimple
+from .nolabel_dataset import NoLabelDataset
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+
+class LaneDataset(Dataset):
+    def __init__(self,
+                 dataset='tusimple',
+                 augmentations=None,
+                 normalize=False,
+                 split='train',
+                 img_size=(360, 640),
+                 aug_chance=1.,
+                 **kwargs):
+        super(LaneDataset, self).__init__()
+        if dataset == 'tusimple':
+            self.dataset = TuSimple(split=split, **kwargs)
+        elif dataset == 'llamas':
+            self.dataset = LLAMAS(split=split, **kwargs)
+        elif dataset == 'elas':
+            self.dataset = ELAS(split=split, **kwargs)
+        elif dataset == 'nolabel_dataset':
+            self.dataset = NoLabelDataset(**kwargs)
+        else:
+            raise NotImplementedError()
+
+        self.transform_annotations()
+        self.img_h, self.img_w = img_size
+
+        if augmentations is not None:
+            # add augmentations
+            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
+                             for aug in augmentations]  # add augmentation
+
+        self.normalize = normalize
+        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
+        self.to_tensor = ToTensor()
+        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
+        self.max_lanes = self.dataset.max_lanes
+
+    def transform_annotation(self, anno, img_wh=None):
+        if img_wh is None:
+            img_h = self.dataset.get_img_heigth(anno['path'])
+            img_w = self.dataset.get_img_width(anno['path'])
+        else:
+            img_w, img_h = img_wh
+
+        old_lanes = anno['lanes']
+        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
+        old_lanes = zip(old_lanes, categories)
+        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
+        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
+        lanes[:, 0] = 0
+        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
+        for lane_pos, (lane, category) in enumerate(old_lanes):
+            lower, upper = lane[0][1], lane[-1][1]
+            xs = np.array([p[0] for p in lane]) / img_w
+            ys = np.array([p[1] for p in lane]) / img_h
+            lanes[lane_pos, 0] = category
+            lanes[lane_pos, 1] = lower / img_h
+            lanes[lane_pos, 2] = upper / img_h
+            lanes[lane_pos, 3:3 + len(xs)] = xs
+            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
+
+        new_anno = {
+            'path': anno['path'],
+            'label': lanes,
+            'old_anno': anno,
+            'categories': [cat for _, cat in old_lanes]
+        }
+
+        return new_anno
+
+    @property
+    def annotations(self):
+        return self.dataset.annotations
+
+    def transform_annotations(self):
+        print('Transforming annotations...')
+        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
+        print('Done.')
+
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+        if img is None:
+            img, label, _ = self.__getitem__(idx, transform=True)
+            # Tensor to opencv image
+            img = img.permute(1, 2, 0).numpy()
+            # Unnormalize
+            if self.normalize:
+                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+            img = (img * 255).astype(np.uint8)
+        else:
+            _, label, _ = self.__getitem__(idx)
+
+        img_h, img_w, _ = img.shape
+
+        # Draw label
+        for i, lane in enumerate(label):
+            if lane[0] == 0:  # Skip invalid lanes
+                continue
+            lane = lane[3:]  # remove conf, upper and lower positions
+            xs = lane[:len(lane) // 2]
+            ys = lane[len(lane) // 2:]
+            ys = ys[xs >= 0]
+            xs = xs[xs >= 0]
+
+            # draw GT points
+            for p in zip(xs, ys):
+                p = (int(p[0] * img_w), int(p[1] * img_h))
+                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
+
+            # draw GT lane ID
+            cv2.putText(img,
+                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
+                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                        fontScale=1,
+                        color=(0, 255, 0))
+
+        if pred is None:
+            return img
+
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        matches, accs, _ = self.dataset.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+            if matches[i]:
+                color = PRED_HIT_COLOR
+            else:
+                color = PRED_MISS_COLOR
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(accs[i] * 100),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+    def lane_to_linestrings(self, lanes):
+        lines = []
+        for lane in lanes:
+            lines.append(LineString(lane))
+
+        return lines
+
+    def linestrings_to_lanes(self, lines):
+        lanes = []
+        for line in lines:
+            lanes.append(line.coords)
+
+        return lanes
+
+    def __getitem__(self, idx, transform=True):
+        item = self.dataset[idx]
+        img = cv2.imread(item['path'])
+        label = item['label']
+        if transform:
+            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
+            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
+            img, line_strings = self.transform(image=img, line_strings=line_strings)
+            line_strings.clip_out_of_image_()
+            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
+            new_anno['categories'] = item['categories']
+            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
+
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, label, idx)
+
+    def __len__(self):
+        return len(self.dataset)
+
+
+def main():
+    import torch
+    from lib.config import Config
+    np.random.seed(0)
+    torch.manual_seed(0)
+    cfg = Config('config.yaml')
+    train_dataset = cfg.get_dataset('train')
+    for idx in range(len(train_dataset)):
+        img = train_dataset.draw_annotation(idx)
+        cv2.imshow('sample', img)
+        cv2.waitKey(0)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/lib/datasets/llamas.py b/lib/datasets/llamas.py
index 595e17b..aba4654 100644
--- a/lib/datasets/llamas.py
+++ b/lib/datasets/llamas.py
@@ -1,451 +1,451 @@
-import os
-import json
-import pickle as pkl
-
-import numpy as np
-from progressbar import progressbar
-
-TRAIN_LABELS_DIR = 'labels/train'
-TEST_LABELS_DIR = 'labels/valid'
-SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
-
-
-class LLAMAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.split = split
-        self.root = root
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
-
-        self.img_w, self.img_h = 1276, 717
-        self.offset = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def get_img_path(self, json_path):
-        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
-        base_name = '/'.join(json_path.split('/')[-3:])
-        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
-        return image_path
-
-    def get_json_paths(self):
-        json_paths = []
-        for root, dirs, files in os.walk(self.labels_dir):
-            for file in files:
-                if file.endswith(".json"):
-                    json_paths.append(os.path.join(root, file))
-        return json_paths
-
-    def load_annotations(self):
-        # Waiting for the dataset to load is tedious, let's cache it
-        os.makedirs('cache', exist_ok=True)
-        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
-        if os.path.exists(cache_path):
-            with open(cache_path, 'rb') as cache_file:
-                self.annotations = pkl.load(cache_file)
-                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
-                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
-                return
-
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        print("Searching annotation files...")
-        json_paths = self.get_json_paths()
-        print('{} annotations found.'.format(len(json_paths)))
-
-        for json_path in progressbar(json_paths):
-            lanes = get_horizontal_values_for_four_lanes(json_path)
-            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
-            lanes = [lane for lane in lanes if len(lane) > 0]
-            relative_path = self.get_img_path(json_path)
-            img_path = os.path.join(self.root, relative_path)
-            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
-            self.max_lanes = max(self.max_lanes, len(lanes))
-            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
-
-        with open(cache_path, 'wb') as cache_file:
-            pkl.dump(self.annotations, cache_file)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
-
-
-# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
-# Its license is copied here
-
-# ##### Begin License ######
-# MIT License
-
-# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
-
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-
-# The above copyright notice and this permission notice shall be included in all
-# copies or substantial portions of the Software.
-
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# ##### End License ######
-
-# Start code under the previous license
-
-
-def _extend_lane(lane, projection_matrix):
-    """Extends marker closest to the camera
-
-    Adds an extra marker that reaches the end of the image
-
-    Parameters
-    ----------
-    lane : iterable of markers
-    projection_matrix : 3x3 projection matrix
-    """
-    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
-    # z is the orthongal distance to the car. It's good enough
-
-    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
-    # e.g., horizontal markers which need to be filtered
-    filtered_markers = filter(
-        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
-        lane['markers'])
-    # might be the first marker in the list but not guaranteed
-    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
-
-    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
-        return lane
-
-    # World marker extension approximation
-    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-
-    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
-    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
-
-    # Pixel marker extension approximation
-    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
-        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
-    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
-        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
-
-    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
-    if pixel_zero_x < 0:
-        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
-        new_pixel_point = (0, left_y)
-    elif pixel_zero_x > 1276:
-        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
-        new_pixel_point = (1276, right_y)
-    else:
-        new_pixel_point = (pixel_zero_x, 716)
-
-    new_marker = {
-        'lane_marker_id': 'FAKE',
-        'world_end': {
-            'x': closest_marker['world_start']['x'],
-            'y': closest_marker['world_start']['y'],
-            'z': closest_marker['world_start']['z']
-        },
-        'world_start': {
-            'x': zero_x,
-            'y': zero_y,
-            'z': 1
-        },
-        'pixel_end': {
-            'x': closest_marker['pixel_start']['x'],
-            'y': closest_marker['pixel_start']['y']
-        },
-        'pixel_start': {
-            'x': ir(new_pixel_point[0]),
-            'y': ir(new_pixel_point[1])
-        }
-    }
-    lane['markers'].insert(0, new_marker)
-
-    return lane
-
-
-class SplineCreator():
-    """
-    For each lane divder
-      - all lines are projected
-      - linearly interpolated to limit oscillations
-      - interpolated by a spline
-      - subsampled to receive individual pixel values
-
-    The spline creation can be optimized!
-      - Better spline parameters
-      - Extend lowest marker to reach bottom of image would also help
-      - Extending last marker may in some cases be interesting too
-    Any help is welcome.
-
-    Call create_all_points and get the points in self.sampled_points
-    It has an x coordinate for each value for each lane
-
-    """
-    def __init__(self, json_path):
-        self.json_path = json_path
-        self.json_content = read_json(json_path)
-        self.lanes = self.json_content['lanes']
-        self.lane_marker_points = {}
-        self.sampled_points = {}  # <--- the interesting part
-        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
-
-    def _sample_points(self, lane, ypp=5, between_markers=True):
-        """ Markers are given by start and endpoint. This one adds extra points
-        which need to be considered for the interpolation. Otherwise the spline
-        could arbitrarily oscillate between start and end of the individual markers
-
-        Parameters
-        ----------
-        lane: polyline, in theory but there are artifacts which lead to inconsistencies
-              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
-        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
-        between_markers : bool, interpolates inbetween dashes
-
-        Notes
-        -----
-        Especially, adding points in the lower parts of the image (high y-values) because
-        the start and end points are too sparse.
-        Removing upper lane markers that have starting and end points mapped into the same pixel.
-        """
-
-        # Collect all x values from all markers along a given line. There may be multiple
-        # intersecting markers, i.e., multiple entries for some y values
-        x_values = [[] for i in range(717)]
-        for marker in lane['markers']:
-            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
-
-            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
-            if height > 2:
-                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
-                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
-                for i in range(height + 1):
-                    x = marker['pixel_start']['x'] + slope * step_size * i
-                    y = marker['pixel_start']['y'] - step_size * i
-                    x_values[ir(y)].append(ir(x))
-
-        # Calculate average x values for each y value
-        for y, xs in enumerate(x_values):
-            if not xs:
-                x_values[y] = -1
-            else:
-                x_values[y] = sum(xs) / float(len(xs))
-
-        # In the following, we will only interpolate between markers if needed
-        if not between_markers:
-            return x_values  # TODO ypp
-
-        # # interpolate between markers
-        current_y = 0
-        while x_values[current_y] == -1:  # skip missing first entries
-            current_y += 1
-
-        # Also possible using numpy.interp when accounting for beginning and end
-        next_set_y = 0
-        try:
-            while current_y < 717:
-                if x_values[current_y] != -1:  # set. Nothing to be done
-                    current_y += 1
-                    continue
-
-                # Finds target x value for interpolation
-                while next_set_y <= current_y or x_values[next_set_y] == -1:
-                    next_set_y += 1
-                    if next_set_y >= 717:
-                        raise StopIteration
-
-                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
-                    (next_set_y - current_y + 1)
-                current_y += 1
-
-        except StopIteration:
-            pass  # Done with lane
-
-        return x_values
-
-    def _lane_points_fit(self, lane):
-        # TODO name and docstring
-        """ Fits spline in image space for the markers of a single lane (side)
-
-        Parameters
-        ----------
-        lane: dict as specified in label
-
-        Returns
-        -------
-        Pixel level values for curve along the y-axis
-
-        Notes
-        -----
-        This one can be drastically improved. Probably fairly easy as well.
-        """
-        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
-        lane = _extend_lane(lane, self.json_content['projection_matrix'])
-        sampled_points = self._sample_points(lane, ypp=1)
-        self.sampled_points[lane['lane_id']] = sampled_points
-
-        return sampled_points
-
-    def create_all_points(self, ):
-        """ Creates splines for given label """
-        for lane in self.lanes:
-            self._lane_points_fit(lane)
-
-
-def get_horizontal_values_for_four_lanes(json_path):
-    """ Gets an x value for every y coordinate for l1, l0, r0, r1
-
-    This allows to easily train a direct curve approximation. For each value along
-    the y-axis, the respective x-values can be compared, e.g. squared distance.
-    Missing values are filled with -1. Missing values are values missing from the spline.
-    There is no extrapolation to the image start/end (yet).
-    But values are interpolated between markers. Space between dashed markers is not missing.
-
-    Parameters
-    ----------
-    json_path: str
-               path to label-file
-
-    Returns
-    -------
-    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
-    the number of vertical pixels of the image
-
-    Notes
-    -----
-    The points are currently based on the splines. The splines are interpolated based on the
-    segmentation values. The spline interpolation has lots of room for improvement, e.g.
-    the lines could be interpolated in 3D, a better approach to spline interpolation could
-    be used, there is barely any error checking, sometimes the splines oscillate too much.
-    This was used for a quick poly-line regression training only.
-    """
-
-    sc = SplineCreator(json_path)
-    sc.create_all_points()
-
-    l1 = sc.sampled_points.get('l1', [-1] * 717)
-    l0 = sc.sampled_points.get('l0', [-1] * 717)
-    r0 = sc.sampled_points.get('r0', [-1] * 717)
-    r1 = sc.sampled_points.get('r1', [-1] * 717)
-
-    lanes = [l1, l0, r0, r1]
-    return lanes
-
-
-def _filter_lanes_by_size(label, min_height=40):
-    """ May need some tuning """
-    filtered_lanes = []
-    for lane in label['lanes']:
-        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        if (lane_end - lane_start) < min_height:
-            continue
-        filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _filter_few_markers(label, min_markers=2):
-    """Filter lines that consist of only few markers"""
-    filtered_lanes = []
-    for lane in label['lanes']:
-        if len(lane['markers']) >= min_markers:
-            filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _fix_lane_names(label):
-    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
-
-    # Create mapping
-    l_counter = 0
-    r_counter = 0
-    mapping = {}
-    lane_ids = [lane['lane_id'] for lane in label['lanes']]
-    for key in sorted(lane_ids):
-        if key[0] == 'l':
-            mapping[key] = 'l' + str(l_counter)
-            l_counter += 1
-        if key[0] == 'r':
-            mapping[key] = 'r' + str(r_counter)
-            r_counter += 1
-    for lane in label['lanes']:
-        lane['lane_id'] = mapping[lane['lane_id']]
-
-
-def read_json(json_path, min_lane_height=20):
-    """ Reads and cleans label file information by path"""
-    with open(json_path, 'r') as jf:
-        label_content = json.load(jf)
-
-    _filter_lanes_by_size(label_content, min_height=min_lane_height)
-    _filter_few_markers(label_content, min_markers=2)
-    _fix_lane_names(label_content)
-
-    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
-
-    for lane in content['lanes']:
-        for marker in lane['markers']:
-            for pixel_key in marker['pixel_start'].keys():
-                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
-            for pixel_key in marker['pixel_end'].keys():
-                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
-            for pixel_key in marker['world_start'].keys():
-                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
-            for pixel_key in marker['world_end'].keys():
-                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
-    return content
-
-
-def ir(some_value):
-    """ Rounds and casts to int
-    Useful for pixel values that cannot be floats
-    Parameters
-    ----------
-    some_value : float
-                 numeric value
-    Returns
-    --------
-    Rounded integer
-    Raises
-    ------
-    ValueError for non scalar types
-    """
-    return int(round(some_value))
-
-
-# End code under the previous license
+import os
+import json
+import pickle as pkl
+
+import numpy as np
+from progressbar import progressbar
+
+TRAIN_LABELS_DIR = 'labels/train'
+TEST_LABELS_DIR = 'labels/valid'
+SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
+
+
+class LLAMAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.split = split
+        self.root = root
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
+
+        self.img_w, self.img_h = 1276, 717
+        self.offset = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def get_img_path(self, json_path):
+        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
+        base_name = '/'.join(json_path.split('/')[-3:])
+        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
+        return image_path
+
+    def get_json_paths(self):
+        json_paths = []
+        for root, dirs, files in os.walk(self.labels_dir):
+            for file in files:
+                if file.endswith(".json"):
+                    json_paths.append(os.path.join(root, file))
+        return json_paths
+
+    def load_annotations(self):
+        # Waiting for the dataset to load is tedious, let's cache it
+        os.makedirs('cache', exist_ok=True)
+        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
+        if os.path.exists(cache_path):
+            with open(cache_path, 'rb') as cache_file:
+                self.annotations = pkl.load(cache_file)
+                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
+                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
+                return
+
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        print("Searching annotation files...")
+        json_paths = self.get_json_paths()
+        print('{} annotations found.'.format(len(json_paths)))
+
+        for json_path in progressbar(json_paths):
+            lanes = get_horizontal_values_for_four_lanes(json_path)
+            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
+            lanes = [lane for lane in lanes if len(lane) > 0]
+            relative_path = self.get_img_path(json_path)
+            img_path = os.path.join(self.root, relative_path)
+            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
+            self.max_lanes = max(self.max_lanes, len(lanes))
+            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
+
+        with open(cache_path, 'wb') as cache_file:
+            pkl.dump(self.annotations, cache_file)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
+
+
+# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
+# Its license is copied here
+
+# ##### Begin License ######
+# MIT License
+
+# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# ##### End License ######
+
+# Start code under the previous license
+
+
+def _extend_lane(lane, projection_matrix):
+    """Extends marker closest to the camera
+
+    Adds an extra marker that reaches the end of the image
+
+    Parameters
+    ----------
+    lane : iterable of markers
+    projection_matrix : 3x3 projection matrix
+    """
+    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
+    # z is the orthongal distance to the car. It's good enough
+
+    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
+    # e.g., horizontal markers which need to be filtered
+    filtered_markers = filter(
+        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
+        lane['markers'])
+    # might be the first marker in the list but not guaranteed
+    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
+
+    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
+        return lane
+
+    # World marker extension approximation
+    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+
+    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
+    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
+
+    # Pixel marker extension approximation
+    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
+        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
+    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
+        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
+
+    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
+    if pixel_zero_x < 0:
+        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
+        new_pixel_point = (0, left_y)
+    elif pixel_zero_x > 1276:
+        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
+        new_pixel_point = (1276, right_y)
+    else:
+        new_pixel_point = (pixel_zero_x, 716)
+
+    new_marker = {
+        'lane_marker_id': 'FAKE',
+        'world_end': {
+            'x': closest_marker['world_start']['x'],
+            'y': closest_marker['world_start']['y'],
+            'z': closest_marker['world_start']['z']
+        },
+        'world_start': {
+            'x': zero_x,
+            'y': zero_y,
+            'z': 1
+        },
+        'pixel_end': {
+            'x': closest_marker['pixel_start']['x'],
+            'y': closest_marker['pixel_start']['y']
+        },
+        'pixel_start': {
+            'x': ir(new_pixel_point[0]),
+            'y': ir(new_pixel_point[1])
+        }
+    }
+    lane['markers'].insert(0, new_marker)
+
+    return lane
+
+
+class SplineCreator():
+    """
+    For each lane divder
+      - all lines are projected
+      - linearly interpolated to limit oscillations
+      - interpolated by a spline
+      - subsampled to receive individual pixel values
+
+    The spline creation can be optimized!
+      - Better spline parameters
+      - Extend lowest marker to reach bottom of image would also help
+      - Extending last marker may in some cases be interesting too
+    Any help is welcome.
+
+    Call create_all_points and get the points in self.sampled_points
+    It has an x coordinate for each value for each lane
+
+    """
+    def __init__(self, json_path):
+        self.json_path = json_path
+        self.json_content = read_json(json_path)
+        self.lanes = self.json_content['lanes']
+        self.lane_marker_points = {}
+        self.sampled_points = {}  # <--- the interesting part
+        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
+
+    def _sample_points(self, lane, ypp=5, between_markers=True):
+        """ Markers are given by start and endpoint. This one adds extra points
+        which need to be considered for the interpolation. Otherwise the spline
+        could arbitrarily oscillate between start and end of the individual markers
+
+        Parameters
+        ----------
+        lane: polyline, in theory but there are artifacts which lead to inconsistencies
+              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
+        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
+        between_markers : bool, interpolates inbetween dashes
+
+        Notes
+        -----
+        Especially, adding points in the lower parts of the image (high y-values) because
+        the start and end points are too sparse.
+        Removing upper lane markers that have starting and end points mapped into the same pixel.
+        """
+
+        # Collect all x values from all markers along a given line. There may be multiple
+        # intersecting markers, i.e., multiple entries for some y values
+        x_values = [[] for i in range(717)]
+        for marker in lane['markers']:
+            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
+
+            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
+            if height > 2:
+                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
+                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
+                for i in range(height + 1):
+                    x = marker['pixel_start']['x'] + slope * step_size * i
+                    y = marker['pixel_start']['y'] - step_size * i
+                    x_values[ir(y)].append(ir(x))
+
+        # Calculate average x values for each y value
+        for y, xs in enumerate(x_values):
+            if not xs:
+                x_values[y] = -1
+            else:
+                x_values[y] = sum(xs) / float(len(xs))
+
+        # In the following, we will only interpolate between markers if needed
+        if not between_markers:
+            return x_values  # TODO ypp
+
+        # # interpolate between markers
+        current_y = 0
+        while x_values[current_y] == -1:  # skip missing first entries
+            current_y += 1
+
+        # Also possible using numpy.interp when accounting for beginning and end
+        next_set_y = 0
+        try:
+            while current_y < 717:
+                if x_values[current_y] != -1:  # set. Nothing to be done
+                    current_y += 1
+                    continue
+
+                # Finds target x value for interpolation
+                while next_set_y <= current_y or x_values[next_set_y] == -1:
+                    next_set_y += 1
+                    if next_set_y >= 717:
+                        raise StopIteration
+
+                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
+                    (next_set_y - current_y + 1)
+                current_y += 1
+
+        except StopIteration:
+            pass  # Done with lane
+
+        return x_values
+
+    def _lane_points_fit(self, lane):
+        # TODO name and docstring
+        """ Fits spline in image space for the markers of a single lane (side)
+
+        Parameters
+        ----------
+        lane: dict as specified in label
+
+        Returns
+        -------
+        Pixel level values for curve along the y-axis
+
+        Notes
+        -----
+        This one can be drastically improved. Probably fairly easy as well.
+        """
+        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
+        lane = _extend_lane(lane, self.json_content['projection_matrix'])
+        sampled_points = self._sample_points(lane, ypp=1)
+        self.sampled_points[lane['lane_id']] = sampled_points
+
+        return sampled_points
+
+    def create_all_points(self, ):
+        """ Creates splines for given label """
+        for lane in self.lanes:
+            self._lane_points_fit(lane)
+
+
+def get_horizontal_values_for_four_lanes(json_path):
+    """ Gets an x value for every y coordinate for l1, l0, r0, r1
+
+    This allows to easily train a direct curve approximation. For each value along
+    the y-axis, the respective x-values can be compared, e.g. squared distance.
+    Missing values are filled with -1. Missing values are values missing from the spline.
+    There is no extrapolation to the image start/end (yet).
+    But values are interpolated between markers. Space between dashed markers is not missing.
+
+    Parameters
+    ----------
+    json_path: str
+               path to label-file
+
+    Returns
+    -------
+    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
+    the number of vertical pixels of the image
+
+    Notes
+    -----
+    The points are currently based on the splines. The splines are interpolated based on the
+    segmentation values. The spline interpolation has lots of room for improvement, e.g.
+    the lines could be interpolated in 3D, a better approach to spline interpolation could
+    be used, there is barely any error checking, sometimes the splines oscillate too much.
+    This was used for a quick poly-line regression training only.
+    """
+
+    sc = SplineCreator(json_path)
+    sc.create_all_points()
+
+    l1 = sc.sampled_points.get('l1', [-1] * 717)
+    l0 = sc.sampled_points.get('l0', [-1] * 717)
+    r0 = sc.sampled_points.get('r0', [-1] * 717)
+    r1 = sc.sampled_points.get('r1', [-1] * 717)
+
+    lanes = [l1, l0, r0, r1]
+    return lanes
+
+
+def _filter_lanes_by_size(label, min_height=40):
+    """ May need some tuning """
+    filtered_lanes = []
+    for lane in label['lanes']:
+        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        if (lane_end - lane_start) < min_height:
+            continue
+        filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _filter_few_markers(label, min_markers=2):
+    """Filter lines that consist of only few markers"""
+    filtered_lanes = []
+    for lane in label['lanes']:
+        if len(lane['markers']) >= min_markers:
+            filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _fix_lane_names(label):
+    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
+
+    # Create mapping
+    l_counter = 0
+    r_counter = 0
+    mapping = {}
+    lane_ids = [lane['lane_id'] for lane in label['lanes']]
+    for key in sorted(lane_ids):
+        if key[0] == 'l':
+            mapping[key] = 'l' + str(l_counter)
+            l_counter += 1
+        if key[0] == 'r':
+            mapping[key] = 'r' + str(r_counter)
+            r_counter += 1
+    for lane in label['lanes']:
+        lane['lane_id'] = mapping[lane['lane_id']]
+
+
+def read_json(json_path, min_lane_height=20):
+    """ Reads and cleans label file information by path"""
+    with open(json_path, 'r') as jf:
+        label_content = json.load(jf)
+
+    _filter_lanes_by_size(label_content, min_height=min_lane_height)
+    _filter_few_markers(label_content, min_markers=2)
+    _fix_lane_names(label_content)
+
+    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
+
+    for lane in content['lanes']:
+        for marker in lane['markers']:
+            for pixel_key in marker['pixel_start'].keys():
+                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
+            for pixel_key in marker['pixel_end'].keys():
+                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
+            for pixel_key in marker['world_start'].keys():
+                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
+            for pixel_key in marker['world_end'].keys():
+                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
+    return content
+
+
+def ir(some_value):
+    """ Rounds and casts to int
+    Useful for pixel values that cannot be floats
+    Parameters
+    ----------
+    some_value : float
+                 numeric value
+    Returns
+    --------
+    Rounded integer
+    Raises
+    ------
+    ValueError for non scalar types
+    """
+    return int(round(some_value))
+
+
+# End code under the previous license
diff --git a/lib/datasets/nolabel_dataset.py b/lib/datasets/nolabel_dataset.py
index c8af627..1b3705b 100644
--- a/lib/datasets/nolabel_dataset.py
+++ b/lib/datasets/nolabel_dataset.py
@@ -1,44 +1,44 @@
-import glob
-
-import numpy as np
-
-
-class NoLabelDataset(object):
-    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
-        self.root = root
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = img_w, img_h
-        self.img_ext = img_ext
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        # On NoLabelDataset, always force it
-        self.max_lanes = max_lanes
-        self.max_points = 1
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def load_annotations(self):
-        self.annotations = []
-        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
-        print('Looking for image files with the pattern', pattern)
-        for file in glob.glob(pattern, recursive=True):
-            self.annotations.append({'lanes': [], 'path': file})
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import glob
+
+import numpy as np
+
+
+class NoLabelDataset(object):
+    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
+        self.root = root
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = img_w, img_h
+        self.img_ext = img_ext
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        # On NoLabelDataset, always force it
+        self.max_lanes = max_lanes
+        self.max_points = 1
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def load_annotations(self):
+        self.annotations = []
+        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
+        print('Looking for image files with the pattern', pattern)
+        for file in glob.glob(pattern, recursive=True):
+            self.annotations.append({'lanes': [], 'path': file})
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..55690dc 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -1,137 +1,137 @@
-import os
-import json
-import random
-
-import numpy as np
-from tabulate import tabulate
-
-from utils.lane import LaneEval
-from utils.metric import eval_json
-
-SPLIT_FILES = {
-    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
-    'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
-    'test': ['test_label.json'],
-}
-
-
-class TuSimple(object):
-    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
-        self.split = split
-        self.root = root
-        self.metric = metric
-
-        if split not in SPLIT_FILES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
-
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = 1280, 720
-        self.max_points = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return 720
-
-    def get_img_width(self, path):
-        return 1280
-
-    def get_metrics(self, lanes, idx):
-        label = self.annotations[idx]
-        org_anno = label['old_anno']
-        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
-        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
-
-        return matches, accs, dist
-
-    def pred2lanes(self, path, pred, y_samples):
-        ys = np.array(y_samples) / self.img_h
-        lanes = []
-        for lane in pred:
-            if lane[0] == 0:
-                continue
-            lane_pred = np.polyval(lane[3:], ys) * self.img_w
-            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
-            lanes.append(list(lane_pred))
-
-        return lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        max_lanes = 0
-        for anno_file in self.anno_files:
-            with open(anno_file, 'r') as anno_obj:
-                lines = anno_obj.readlines()
-            for line in lines:
-                data = json.loads(line)
-                y_samples = data['h_samples']
-                gt_lanes = data['lanes']
-                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
-                lanes = [lane for lane in lanes if len(lane) > 0]
-                max_lanes = max(max_lanes, len(lanes))
-                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
-                self.annotations.append({
-                    'path': os.path.join(self.root, data['raw_file']),
-                    'org_path': data['raw_file'],
-                    'org_lanes': gt_lanes,
-                    'lanes': lanes,
-                    'aug': False,
-                    'y_samples': y_samples
-                })
-
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-        print('total annos', len(self.annotations))
-        self.max_lanes = max_lanes
-
-    def transform_annotations(self, transform):
-        self.annotations = list(map(transform, self.annotations))
-
-    def pred2tusimpleformat(self, idx, pred, runtime):
-        runtime *= 1000.  # s to ms
-        img_name = self.annotations[idx]['old_anno']['org_path']
-        h_samples = self.annotations[idx]['old_anno']['y_samples']
-        lanes = self.pred2lanes(img_name, pred, h_samples)
-        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
-        return json.dumps(output)
-
-    def save_tusimple_predictions(self, predictions, runtimes, filename):
-        lines = []
-        for idx in range(len(predictions)):
-            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
-            lines.append(line)
-        with open(filename, 'w') as output_file:
-            output_file.write('\n'.join(lines))
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
-        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
-        if self.metric == 'default':
-            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
-        elif self.metric == 'ours':
-            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
-        table = {}
-        for metric in result:
-            table[metric['name']] = [metric['value']]
-        table = tabulate(table, headers='keys')
-
-        if not only_metrics:
-            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
-            with open(os.path.join(exp_dir, filename), 'w') as out_file:
-                json.dump(result, out_file)
-
-        return table, result
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import json
+import random
+
+import numpy as np
+from tabulate import tabulate
+
+from utils.lane import LaneEval
+from utils.metric import eval_json
+
+SPLIT_FILES = {
+    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
+    'train': ['label_data_0313.json', 'label_data_0601.json'],
+    'val': ['test_label.json'],
+    'test': ['test_label.json'],
+}
+
+
+class TuSimple(object):
+    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
+        self.split = split
+        self.root = root
+        self.metric = metric
+
+        if split not in SPLIT_FILES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
+
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = 1280, 720
+        self.max_points = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return 720
+
+    def get_img_width(self, path):
+        return 1280
+
+    def get_metrics(self, lanes, idx):
+        label = self.annotations[idx]
+        org_anno = label['old_anno']
+        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
+        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
+
+        return matches, accs, dist
+
+    def pred2lanes(self, path, pred, y_samples):
+        ys = np.array(y_samples) / self.img_h
+        lanes = []
+        for lane in pred:
+            if lane[0] == 0:
+                continue
+            lane_pred = np.polyval(lane[3:], ys) * self.img_w
+            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
+            lanes.append(list(lane_pred))
+
+        return lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        max_lanes = 0
+        for anno_file in self.anno_files:
+            with open(anno_file, 'r') as anno_obj:
+                lines = anno_obj.readlines()
+            for line in lines:
+                data = json.loads(line)
+                y_samples = data['h_samples']
+                gt_lanes = data['lanes']
+                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
+                lanes = [lane for lane in lanes if len(lane) > 0]
+                max_lanes = max(max_lanes, len(lanes))
+                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
+                self.annotations.append({
+                    'path': os.path.join(self.root, data['raw_file']),
+                    'org_path': data['raw_file'],
+                    'org_lanes': gt_lanes,
+                    'lanes': lanes,
+                    'aug': False,
+                    'y_samples': y_samples
+                })
+
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+        print('total annos', len(self.annotations))
+        self.max_lanes = max_lanes
+
+    def transform_annotations(self, transform):
+        self.annotations = list(map(transform, self.annotations))
+
+    def pred2tusimpleformat(self, idx, pred, runtime):
+        runtime *= 1000.  # s to ms
+        img_name = self.annotations[idx]['old_anno']['org_path']
+        h_samples = self.annotations[idx]['old_anno']['y_samples']
+        lanes = self.pred2lanes(img_name, pred, h_samples)
+        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
+        return json.dumps(output)
+
+    def save_tusimple_predictions(self, predictions, runtimes, filename):
+        lines = []
+        for idx in range(len(predictions)):
+            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
+            lines.append(line)
+        with open(filename, 'w') as output_file:
+            output_file.write('\n'.join(lines))
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
+        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
+        if self.metric == 'default':
+            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
+        elif self.metric == 'ours':
+            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
+        table = {}
+        for metric in result:
+            table[metric['name']] = [metric['value']]
+        table = tabulate(table, headers='keys')
+
+        if not only_metrics:
+            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
+            with open(os.path.join(exp_dir, filename), 'w') as out_file:
+                json.dump(result, out_file)
+
+        return table, result
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/models.py b/lib/models.py
index 15eb117..ad6e599 100644
--- a/lib/models.py
+++ b/lib/models.py
@@ -1,160 +1,160 @@
-import torch
-import torch.nn as nn
-from torchvision.models import resnet34, resnet50, resnet101
-from efficientnet_pytorch import EfficientNet
-
-
-class OutputLayer(nn.Module):
-    def __init__(self, fc, num_extra):
-        super(OutputLayer, self).__init__()
-        self.regular_outputs_layer = fc
-        self.num_extra = num_extra
-        if num_extra > 0:
-            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
-
-    def forward(self, x):
-        regular_outputs = self.regular_outputs_layer(x)
-        if self.num_extra > 0:
-            extra_outputs = self.extra_outputs_layer(x)
-        else:
-            extra_outputs = None
-
-        return regular_outputs, extra_outputs
-
-
-class PolyRegression(nn.Module):
-    def __init__(self,
-                 num_outputs,
-                 backbone,
-                 pretrained,
-                 curriculum_steps=None,
-                 extra_outputs=0,
-                 share_top_y=True,
-                 pred_category=False):
-        super(PolyRegression, self).__init__()
-        if 'efficientnet' in backbone:
-            if pretrained:
-                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
-            else:
-                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
-            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
-        elif backbone == 'resnet34':
-            self.model = resnet34(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet50':
-            self.model = resnet50(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet101':
-            self.model = resnet101(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        else:
-            raise NotImplementedError()
-
-        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
-        self.share_top_y = share_top_y
-        self.extra_outputs = extra_outputs
-        self.pred_category = pred_category
-        self.sigmoid = nn.Sigmoid()
-
-    def forward(self, x, epoch=None, **kwargs):
-        output, extra_outputs = self.model(x, **kwargs)
-        for i in range(len(self.curriculum_steps)):
-            if epoch is not None and epoch < self.curriculum_steps[i]:
-                output[:, -len(self.curriculum_steps) + i] = 0
-        return output, extra_outputs
-
-    def decode(self, all_outputs, labels, conf_threshold=0.5):
-        outputs, extra_outputs = all_outputs
-        if extra_outputs is not None:
-            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
-            extra_outputs = extra_outputs.argmax(dim=2)
-        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
-        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
-        outputs[outputs[:, :, 0] < conf_threshold] = 0
-
-        if False and self.share_top_y:
-            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
-
-        return outputs, extra_outputs
-
-    def loss(self,
-             outputs,
-             target,
-             conf_weight=1,
-             lower_weight=1,
-             upper_weight=1,
-             cls_weight=1,
-             poly_weight=300,
-             threshold=15 / 720.):
-        pred, extra_outputs = outputs
-        bce = nn.BCELoss()
-        mse = nn.MSELoss()
-        s = nn.Sigmoid()
-        threshold = nn.Threshold(threshold**2, 0.)
-        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
-        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
-        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
-        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
-        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
-
-        if self.share_top_y:
-            # inexistent lanes have -1e-5 as lower
-            # i'm just setting it to a high value here so that the .min below works fine
-            target_lowers[target_lowers < 0] = 1
-            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
-            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
-
-        target_lowers = target_lowers.reshape((-1, 1))
-        pred_lowers = pred_lowers.reshape((-1, 1))
-
-        target_confs = (target_categories > 0).float()
-        valid_lanes_idx = target_confs == 1
-        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
-        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
-        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
-
-        # classification loss
-        if self.pred_category and self.extra_outputs > 0:
-            ce = nn.CrossEntropyLoss()
-            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
-            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
-            pred_categories = pred_categories[target_categories > 0]
-            target_categories = target_categories[target_categories > 0]
-            cls_loss = ce(pred_categories, target_categories - 1)
-        else:
-            cls_loss = 0
-
-        # poly loss calc
-        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
-        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
-        valid_xs = target_xs >= 0
-        pred_polys = pred_polys[valid_lanes_idx_flat]
-        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
-        pred_xs.t_()
-        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
-        pred_xs = (pred_xs.t_() *
-                   weights).t()  # without this, lanes with more points would have more weight on the cost function
-        target_xs = (target_xs.t_() * weights).t()
-        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
-        poly_loss = threshold(
-            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
-
-        # applying weights to partial losses
-        poly_loss = poly_loss * poly_weight
-        lower_loss = lower_loss * lower_weight
-        upper_loss = upper_loss * upper_weight
-        cls_loss = cls_loss * cls_weight
-        conf_loss = bce(pred_confs, target_confs) * conf_weight
-
-        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
-
-        return loss, {
-            'conf': conf_loss,
-            'lower': lower_loss,
-            'upper': upper_loss,
-            'poly': poly_loss,
-            'cls_loss': cls_loss
-        }
+import torch
+import torch.nn as nn
+from torchvision.models import resnet34, resnet50, resnet101
+from efficientnet_pytorch import EfficientNet
+
+
+class OutputLayer(nn.Module):
+    def __init__(self, fc, num_extra):
+        super(OutputLayer, self).__init__()
+        self.regular_outputs_layer = fc
+        self.num_extra = num_extra
+        if num_extra > 0:
+            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
+
+    def forward(self, x):
+        regular_outputs = self.regular_outputs_layer(x)
+        if self.num_extra > 0:
+            extra_outputs = self.extra_outputs_layer(x)
+        else:
+            extra_outputs = None
+
+        return regular_outputs, extra_outputs
+
+
+class PolyRegression(nn.Module):
+    def __init__(self,
+                 num_outputs,
+                 backbone,
+                 pretrained,
+                 curriculum_steps=None,
+                 extra_outputs=0,
+                 share_top_y=True,
+                 pred_category=False):
+        super(PolyRegression, self).__init__()
+        if 'efficientnet' in backbone:
+            if pretrained:
+                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
+            else:
+                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
+            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
+        elif backbone == 'resnet34':
+            self.model = resnet34(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet50':
+            self.model = resnet50(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet101':
+            self.model = resnet101(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        else:
+            raise NotImplementedError()
+
+        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
+        self.share_top_y = share_top_y
+        self.extra_outputs = extra_outputs
+        self.pred_category = pred_category
+        self.sigmoid = nn.Sigmoid()
+
+    def forward(self, x, epoch=None, **kwargs):
+        output, extra_outputs = self.model(x, **kwargs)
+        for i in range(len(self.curriculum_steps)):
+            if epoch is not None and epoch < self.curriculum_steps[i]:
+                output[:, -len(self.curriculum_steps) + i] = 0
+        return output, extra_outputs
+
+    def decode(self, all_outputs, labels, conf_threshold=0.5):
+        outputs, extra_outputs = all_outputs
+        if extra_outputs is not None:
+            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
+            extra_outputs = extra_outputs.argmax(dim=2)
+        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
+        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
+        outputs[outputs[:, :, 0] < conf_threshold] = 0
+
+        if False and self.share_top_y:
+            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
+
+        return outputs, extra_outputs
+
+    def loss(self,
+             outputs,
+             target,
+             conf_weight=1,
+             lower_weight=1,
+             upper_weight=1,
+             cls_weight=1,
+             poly_weight=300,
+             threshold=15 / 720.):
+        pred, extra_outputs = outputs
+        bce = nn.BCELoss()
+        mse = nn.MSELoss()
+        s = nn.Sigmoid()
+        threshold = nn.Threshold(threshold**2, 0.)
+        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
+        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
+        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
+        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
+        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
+
+        if self.share_top_y:
+            # inexistent lanes have -1e-5 as lower
+            # i'm just setting it to a high value here so that the .min below works fine
+            target_lowers[target_lowers < 0] = 1
+            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
+            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
+
+        target_lowers = target_lowers.reshape((-1, 1))
+        pred_lowers = pred_lowers.reshape((-1, 1))
+
+        target_confs = (target_categories > 0).float()
+        valid_lanes_idx = target_confs == 1
+        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
+        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
+        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
+
+        # classification loss
+        if self.pred_category and self.extra_outputs > 0:
+            ce = nn.CrossEntropyLoss()
+            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
+            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
+            pred_categories = pred_categories[target_categories > 0]
+            target_categories = target_categories[target_categories > 0]
+            cls_loss = ce(pred_categories, target_categories - 1)
+        else:
+            cls_loss = 0
+
+        # poly loss calc
+        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
+        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
+        valid_xs = target_xs >= 0
+        pred_polys = pred_polys[valid_lanes_idx_flat]
+        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
+        pred_xs.t_()
+        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
+        pred_xs = (pred_xs.t_() *
+                   weights).t()  # without this, lanes with more points would have more weight on the cost function
+        target_xs = (target_xs.t_() * weights).t()
+        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
+        poly_loss = threshold(
+            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
+
+        # applying weights to partial losses
+        poly_loss = poly_loss * poly_weight
+        lower_loss = lower_loss * lower_weight
+        upper_loss = upper_loss * upper_weight
+        cls_loss = cls_loss * cls_weight
+        conf_loss = bce(pred_confs, target_confs) * conf_weight
+
+        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
+
+        return loss, {
+            'conf': conf_loss,
+            'lower': lower_loss,
+            'upper': upper_loss,
+            'poly': poly_loss,
+            'cls_loss': cls_loss
+        }
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..3ba5b3a 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,16 +1,15 @@
-lxml==4.6.2
-torchvision==0.5.0
-xmljson==0.2.0
-scipy==1.4.1
-tabulate==0.8.6
-numpy==1.18.1
-ujson==1.35
-matplotlib==3.1.3
-imgaug==0.4.0
-tqdm==4.43.0
-opencv_python==4.2.0.32
-efficientnet_pytorch==0.6.3
-torch==1.4.0
-progressbar33==2.4
-PyYAML==5.3.1
-scikit-learn==0.21.3
+lxml==4.6.2
+torchvision==0.5.0
+xmljson==0.2.0
+scipy==1.4.1
+tabulate==0.8.6
+numpy==1.18.1
+ujson==1.35
+matplotlib==3.1.3
+imgaug==0.4.0
+tqdm==4.43.0
+opencv_python==4.2.0.32
+efficientnet_pytorch==0.6.3
+progressbar33==2.4
+PyYAML==5.3.1
+scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..ed3e216 100644
--- a/test.py
+++ b/test.py
@@ -1,166 +1,166 @@
-import os
-import sys
-import random
-import logging
-import argparse
-import subprocess
-from time import time
-
-import cv2
-import numpy as np
-import torch
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
-    if verbose:
-        logging.info("Starting testing.")
-
-    # Test the model
-    if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
-
-    model.eval()
-    criterion_parameters = cfg.get_loss_parameters()
-    test_parameters = cfg.get_test_parameters()
-    criterion = model.loss
-    loss = 0
-    total_iters = 0
-    test_t0 = time()
-    loss_dict = {}
-    with torch.no_grad():
-        for idx, (images, labels, img_idxs) in enumerate(test_loader):
-            if max_batches is not None and idx >= max_batches:
-                break
-            if idx % 1 == 0 and verbose:
-                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
-            images = images.to(device)
-            labels = labels.to(device)
-
-            t0 = time()
-            outputs = model(images)
-            t = time() - t0
-            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            loss += loss_i.item()
-            total_iters += 1
-            for key in loss_dict_i:
-                if key not in loss_dict:
-                    loss_dict[key] = 0
-                loss_dict[key] += loss_dict_i[key]
-
-            outputs = model.decode(outputs, labels, **test_parameters)
-
-            if evaluator is not None:
-                lane_outputs, _ = outputs
-                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
-            if view:
-                outputs, extra_outputs = outputs
-                preds = test_loader.dataset.draw_annotation(
-                    idx,
-                    pred=outputs[0].cpu().numpy(),
-                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
-                cv2.imshow('pred', preds)
-                cv2.waitKey(0)
-
-    if verbose:
-        logging.info("Testing time: {:.4f}".format(time() - test_t0))
-    out_line = []
-    for key in loss_dict:
-        loss_dict[key] /= total_iters
-        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
-    if verbose:
-        logging.info(', '.join(out_line))
-
-    return evaluator, loss / total_iters
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Lane regression")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
-    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
-    parser.add_argument("--view", action="store_true", help="Show predictions")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    # Set up logging
-    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
-
-    # Model
-    model = cfg.get_model().to(device)
-    test_epoch = args.epoch
-
-    # Get data set
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size if args.view is False else 1,
-                                              shuffle=False,
-                                              num_workers=8)
-    # Eval results
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import logging
+import argparse
+import subprocess
+from time import time
+
+import cv2
+import numpy as np
+import torch
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
+    if verbose:
+        logging.info("Starting testing.")
+
+    # Test the model
+    if epoch > 0:
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
+
+    model.eval()
+    criterion_parameters = cfg.get_loss_parameters()
+    test_parameters = cfg.get_test_parameters()
+    criterion = model.loss
+    loss = 0
+    total_iters = 0
+    test_t0 = time()
+    loss_dict = {}
+    with torch.no_grad():
+        for idx, (images, labels, img_idxs) in enumerate(test_loader):
+            if max_batches is not None and idx >= max_batches:
+                break
+            if idx % 1 == 0 and verbose:
+                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
+            images = images.to(device)
+            labels = labels.to(device)
+
+            t0 = time()
+            outputs = model(images)
+            t = time() - t0
+            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            loss += loss_i.item()
+            total_iters += 1
+            for key in loss_dict_i:
+                if key not in loss_dict:
+                    loss_dict[key] = 0
+                loss_dict[key] += loss_dict_i[key]
+
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            if evaluator is not None:
+                lane_outputs, _ = outputs
+                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
+            if view:
+                outputs, extra_outputs = outputs
+                preds = test_loader.dataset.draw_annotation(
+                    idx,
+                    pred=outputs[0].cpu().numpy(),
+                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+                cv2.imshow('pred', preds)
+                cv2.waitKey(0)
+
+    if verbose:
+        logging.info("Testing time: {:.4f}".format(time() - test_t0))
+    out_line = []
+    for key in loss_dict:
+        loss_dict[key] /= total_iters
+        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
+    if verbose:
+        logging.info(', '.join(out_line))
+
+    return evaluator, loss / total_iters
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
+    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
+    parser.add_argument("--view", action="store_true", help="Show predictions")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    # Set up logging
+    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
+
+    # Model
+    model = cfg.get_model().to(device)
+    test_epoch = args.epoch
+
+    # Get data set
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size if args.view is False else 1,
+                                              shuffle=False,
+                                              num_workers=8)
+    # Eval results
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/train.py b/train.py
index 3753aed..d066d7e 100644
--- a/train.py
+++ b/train.py
@@ -1,271 +1,271 @@
-import os
-import sys
-import random
-import shutil
-import logging
-import argparse
-import subprocess
-from time import time
-
-import numpy as np
-import torch
-
-from test import test
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
-    # Get initial train state
-    optimizer = cfg.get_optimizer(model.parameters())
-    scheduler = cfg.get_lr_scheduler(optimizer)
-    starting_epoch = 1
-
-    if train_state is not None:
-        model.load_state_dict(train_state['model'])
-        optimizer.load_state_dict(train_state['optimizer'])
-        scheduler.load_state_dict(train_state['lr_scheduler'])
-        starting_epoch = train_state['epoch'] + 1
-        scheduler.step(starting_epoch)
-
-    # Train the model
-    criterion_parameters = cfg.get_loss_parameters()
-    criterion = model.loss
-    total_step = len(train_loader)
-    ITER_LOG_INTERVAL = cfg['iter_log_interval']
-    ITER_TIME_WINDOW = cfg['iter_time_window']
-    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
-    t0 = time()
-    total_iter = 0
-    iter_times = []
-    logging.info("Starting training.")
-    for epoch in range(starting_epoch, num_epochs + 1):
-        epoch_t0 = time()
-        logging.info("Beginning epoch {}".format(epoch))
-        accum_loss = 0
-        for i, (images, labels, img_idxs) in enumerate(train_loader):
-            total_iter += 1
-            iter_t0 = time()
-            images = images.to(device)
-            labels = labels.to(device)
-
-            # Forward pass
-            outputs = model(images, epoch=epoch)
-            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            accum_loss += loss.item()
-
-            # Backward and optimize
-            optimizer.zero_grad()
-            loss.backward()
-            optimizer.step()
-
-            iter_times.append(time() - iter_t0)
-            if len(iter_times) > 100:
-                iter_times = iter_times[-ITER_TIME_WINDOW:]
-            if (i + 1) % ITER_LOG_INTERVAL == 0:
-                loss_str = ', '.join(
-                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
-                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
-                    epoch,
-                    num_epochs,
-                    i + 1,
-                    total_step,
-                    accum_loss / (i + 1),
-                    loss_str,
-                    np.mean(iter_times),
-                    optimizer.param_groups[0]["lr"],
-                ))
-        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
-        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
-            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
-            save_train_state(model_path, model, optimizer, scheduler, epoch)
-        if val_loader is not None:
-            evaluator = Evaluator(val_loader.dataset, exp_root)
-            evaluator, val_loss = test(
-                model,
-                val_loader,
-                evaluator,
-                None,
-                cfg,
-                view=False,
-                epoch=-1,
-                verbose=False,
-            )
-            _, results = evaluator.eval(label=None, only_metrics=True)
-            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
-            model.train()
-        scheduler.step()
-    logging.info("Training time: {:.4f}".format(time() - t0))
-
-    return model
-
-
-def save_train_state(path, model, optimizer, lr_scheduler, epoch):
-    train_state = {
-        'model': model.state_dict(),
-        'optimizer': optimizer.state_dict(),
-        'lr_scheduler': lr_scheduler.state_dict(),
-        'epoch': epoch
-    }
-
-    torch.save(train_state, path)
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--resume", action="store_true", help="Resume training")
-    parser.add_argument("--validate", action="store_true", help="Validate model during training")
-    parser.add_argument("--deterministic",
-                        action="store_true",
-                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def setup_exp_dir(exps_dir, exp_name, cfg_path):
-    dirs = ["models"]
-    exp_root = os.path.join(exps_dir, exp_name)
-
-    for dirname in dirs:
-        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
-
-    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
-    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
-        file.write(get_code_state())
-
-    return exp_root
-
-
-def get_exp_train_state(exp_root):
-    models_dir = os.path.join(exp_root, "models")
-    models = os.listdir(models_dir)
-    last_epoch, last_modelname = sorted(
-        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
-        key=lambda x: x[0],
-    )[-1]
-    train_state = torch.load(os.path.join(models_dir, last_modelname))
-
-    return train_state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    if args.deterministic:
-        torch.backends.cudnn.deterministic = True
-        torch.backends.cudnn.benchmark = False
-
-    # Set up experiment
-    if not args.resume:
-        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
-    else:
-        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Get data sets
-    train_dataset = cfg.get_dataset("train")
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"]
-
-    # Model
-    model = cfg.get_model().to(device)
-
-    train_state = None
-    if args.resume:
-        train_state = get_exp_train_state(exp_root)
-
-    # Data loader
-    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
-                                               batch_size=batch_size,
-                                               shuffle=True,
-                                               num_workers=8)
-
-    if args.validate:
-        val_dataset = cfg.get_dataset("val")
-        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
-                                                 batch_size=batch_size,
-                                                 shuffle=False,
-                                                 num_workers=8)
-    # Train regressor
-    try:
-        model = train(
-            model,
-            train_loader,
-            exp_root,
-            cfg,
-            val_loader=val_loader if args.validate else None,
-            train_state=train_state,
-        )
-    except KeyboardInterrupt:
-        logging.info("Training session terminated.")
-    test_epoch = -1
-    if cfg['backup'] is not None:
-        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
-
-    # Eval model after training
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size,
-                                              shuffle=False,
-                                              num_workers=8)
-
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import shutil
+import logging
+import argparse
+import subprocess
+from time import time
+
+import numpy as np
+import torch
+
+from test import test
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
+    # Get initial train state
+    optimizer = cfg.get_optimizer(model.parameters())
+    scheduler = cfg.get_lr_scheduler(optimizer)
+    starting_epoch = 1
+
+    if train_state is not None:
+        model.load_state_dict(train_state['model'])
+        optimizer.load_state_dict(train_state['optimizer'])
+        scheduler.load_state_dict(train_state['lr_scheduler'])
+        starting_epoch = train_state['epoch'] + 1
+        scheduler.step(starting_epoch)
+
+    # Train the model
+    criterion_parameters = cfg.get_loss_parameters()
+    criterion = model.loss
+    total_step = len(train_loader)
+    ITER_LOG_INTERVAL = cfg['iter_log_interval']
+    ITER_TIME_WINDOW = cfg['iter_time_window']
+    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
+    t0 = time()
+    total_iter = 0
+    iter_times = []
+    logging.info("Starting training.")
+    for epoch in range(starting_epoch, num_epochs + 1):
+        epoch_t0 = time()
+        logging.info("Beginning epoch {}".format(epoch))
+        accum_loss = 0
+        for i, (images, labels, img_idxs) in enumerate(train_loader):
+            total_iter += 1
+            iter_t0 = time()
+            images = images.to(device)
+            labels = labels.to(device)
+
+            # Forward pass
+            outputs = model(images, epoch=epoch)
+            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            accum_loss += loss.item()
+
+            # Backward and optimize
+            optimizer.zero_grad()
+            loss.backward()
+            optimizer.step()
+
+            iter_times.append(time() - iter_t0)
+            if len(iter_times) > 100:
+                iter_times = iter_times[-ITER_TIME_WINDOW:]
+            if (i + 1) % ITER_LOG_INTERVAL == 0:
+                loss_str = ', '.join(
+                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
+                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
+                    epoch,
+                    num_epochs,
+                    i + 1,
+                    total_step,
+                    accum_loss / (i + 1),
+                    loss_str,
+                    np.mean(iter_times),
+                    optimizer.param_groups[0]["lr"],
+                ))
+        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
+        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
+            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
+            save_train_state(model_path, model, optimizer, scheduler, epoch)
+        if val_loader is not None:
+            evaluator = Evaluator(val_loader.dataset, exp_root)
+            evaluator, val_loss = test(
+                model,
+                val_loader,
+                evaluator,
+                None,
+                cfg,
+                view=False,
+                epoch=-1,
+                verbose=False,
+            )
+            _, results = evaluator.eval(label=None, only_metrics=True)
+            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
+            model.train()
+        scheduler.step()
+    logging.info("Training time: {:.4f}".format(time() - t0))
+
+    return model
+
+
+def save_train_state(path, model, optimizer, lr_scheduler, epoch):
+    train_state = {
+        'model': model.state_dict(),
+        'optimizer': optimizer.state_dict(),
+        'lr_scheduler': lr_scheduler.state_dict(),
+        'epoch': epoch
+    }
+
+    torch.save(train_state, path)
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--resume", action="store_true", help="Resume training")
+    parser.add_argument("--validate", action="store_true", help="Validate model during training")
+    parser.add_argument("--deterministic",
+                        action="store_true",
+                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def setup_exp_dir(exps_dir, exp_name, cfg_path):
+    dirs = ["models"]
+    exp_root = os.path.join(exps_dir, exp_name)
+
+    for dirname in dirs:
+        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
+
+    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
+    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
+        file.write(get_code_state())
+
+    return exp_root
+
+
+def get_exp_train_state(exp_root):
+    models_dir = os.path.join(exp_root, "models")
+    models = os.listdir(models_dir)
+    last_epoch, last_modelname = sorted(
+        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
+        key=lambda x: x[0],
+    )[-1]
+    train_state = torch.load(os.path.join(models_dir, last_modelname))
+
+    return train_state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    if args.deterministic:
+        torch.backends.cudnn.deterministic = True
+        torch.backends.cudnn.benchmark = False
+
+    # Set up experiment
+    if not args.resume:
+        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
+    else:
+        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Get data sets
+    train_dataset = cfg.get_dataset("train")
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    # Model
+    model = cfg.get_model().to(device)
+
+    train_state = None
+    if args.resume:
+        train_state = get_exp_train_state(exp_root)
+
+    # Data loader
+    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
+                                               batch_size=batch_size,
+                                               shuffle=True,
+                                               num_workers=8)
+
+    if args.validate:
+        val_dataset = cfg.get_dataset("val")
+        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
+                                                 batch_size=batch_size,
+                                                 shuffle=False,
+                                                 num_workers=8)
+    # Train regressor
+    try:
+        model = train(
+            model,
+            train_loader,
+            exp_root,
+            cfg,
+            val_loader=val_loader if args.validate else None,
+            train_state=train_state,
+        )
+    except KeyboardInterrupt:
+        logging.info("Training session terminated.")
+    test_epoch = -1
+    if cfg['backup'] is not None:
+        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
+
+    # Eval model after training
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size,
+                                              shuffle=False,
+                                              num_workers=8)
+
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/utils/evaluator.py b/utils/evaluator.py
index b4d51a1..9793857 100644
--- a/utils/evaluator.py
+++ b/utils/evaluator.py
@@ -1,33 +1,33 @@
-import sys
-
-import numpy as np
-
-from lib.datasets.lane_dataset import LaneDataset
-
-EXPS_DIR = 'experiments'
-
-
-class Evaluator(object):
-    def __init__(self, dataset, exp_dir, poly_degree=3):
-        self.dataset = dataset
-        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
-        self.predictions = None
-        self.runtimes = np.zeros(len(dataset))
-        self.loss = np.zeros(len(dataset))
-        self.exp_dir = exp_dir
-        self.new_preds = False
-
-    def add_prediction(self, idx, pred, runtime):
-        if self.predictions is None:
-            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
-        self.predictions[idx, :pred.shape[1], :] = pred
-        self.runtimes[idx] = runtime
-        self.new_preds = True
-
-    def eval(self, **kwargs):
-        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
-
-
-if __name__ == "__main__":
-    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
-    evaluator.tusimple_eval()
+import sys
+
+import numpy as np
+
+from lib.datasets.lane_dataset import LaneDataset
+
+EXPS_DIR = 'experiments'
+
+
+class Evaluator(object):
+    def __init__(self, dataset, exp_dir, poly_degree=3):
+        self.dataset = dataset
+        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
+        self.predictions = None
+        self.runtimes = np.zeros(len(dataset))
+        self.loss = np.zeros(len(dataset))
+        self.exp_dir = exp_dir
+        self.new_preds = False
+
+    def add_prediction(self, idx, pred, runtime):
+        if self.predictions is None:
+            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
+        self.predictions[idx, :pred.shape[1], :] = pred
+        self.runtimes[idx] = runtime
+        self.new_preds = True
+
+    def eval(self, **kwargs):
+        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
+
+
+if __name__ == "__main__":
+    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
+    evaluator.tusimple_eval()
diff --git a/utils/gen_video.py b/utils/gen_video.py
index b4a3b4d..8dff9a8 100644
--- a/utils/gen_video.py
+++ b/utils/gen_video.py
@@ -1,67 +1,67 @@
-import pickle
-import argparse
-
-import cv2
-from tqdm import tqdm
-
-from lib.config import Config
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
-    parser.add_argument("--pred", help=".pkl file to load predictions from")
-    parser.add_argument("--cfg", default="config.yaml", help="Config file")
-    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
-    parser.add_argument("--out", default="video.avi", help="Output filename")
-    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
-
-    return parser.parse_args()
-
-
-def add_cover_img(video, cover_path, frames=90):
-    cover = cv2.imread(cover_path)
-    for _ in range(frames):
-        video.write(cover)
-
-
-def create_video(filename, width, height, fps=30):
-    fourcc = cv2.VideoWriter_fourcc(*'MP42')
-    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
-
-    return video
-
-
-def main():
-    args = parse_args()
-    cfg = Config(args.cfg)
-    dataset = cfg.get_dataset('test')
-    height, width = cfg['datasets']['test']['parameters']['img_size']
-    print('Using resolution {}x{}'.format(width, height))
-    if not args.view:
-        video = create_video(args.out, width, height)
-    # add_cover_img(video, args.cover)
-    with open(args.pred, "rb") as pred_file:
-        predictions = pickle.load(pred_file)
-
-    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
-        if idx < 2200: continue
-        if idx > 3000: break
-        det_pred, cls_pred = pred
-        assert det_pred.shape[0] == 1  # batch size == 1
-        frame = dataset.draw_annotation(idx,
-                                        pred=det_pred[0].cpu().numpy(),
-                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
-        assert frame.shape[:2] == (height, width)
-        if args.view:
-            cv2.imshow('frame', frame)
-            cv2.waitKey(0)
-        else:
-            video.write(frame)
-
-    if not args.view:
-        video.release()
-        print('Video saved as {}'.format(args.out))
-
-
-if __name__ == '__main__':
-    main()
+import pickle
+import argparse
+
+import cv2
+from tqdm import tqdm
+
+from lib.config import Config
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
+    parser.add_argument("--pred", help=".pkl file to load predictions from")
+    parser.add_argument("--cfg", default="config.yaml", help="Config file")
+    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
+    parser.add_argument("--out", default="video.avi", help="Output filename")
+    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
+
+    return parser.parse_args()
+
+
+def add_cover_img(video, cover_path, frames=90):
+    cover = cv2.imread(cover_path)
+    for _ in range(frames):
+        video.write(cover)
+
+
+def create_video(filename, width, height, fps=30):
+    fourcc = cv2.VideoWriter_fourcc(*'MP42')
+    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
+
+    return video
+
+
+def main():
+    args = parse_args()
+    cfg = Config(args.cfg)
+    dataset = cfg.get_dataset('test')
+    height, width = cfg['datasets']['test']['parameters']['img_size']
+    print('Using resolution {}x{}'.format(width, height))
+    if not args.view:
+        video = create_video(args.out, width, height)
+    # add_cover_img(video, args.cover)
+    with open(args.pred, "rb") as pred_file:
+        predictions = pickle.load(pred_file)
+
+    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
+        if idx < 2200: continue
+        if idx > 3000: break
+        det_pred, cls_pred = pred
+        assert det_pred.shape[0] == 1  # batch size == 1
+        frame = dataset.draw_annotation(idx,
+                                        pred=det_pred[0].cpu().numpy(),
+                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
+        assert frame.shape[:2] == (height, width)
+        if args.view:
+            cv2.imshow('frame', frame)
+            cv2.waitKey(0)
+        else:
+            video.write(frame)
+
+    if not args.view:
+        video.release()
+        print('Video saved as {}'.format(args.out))
+
+
+if __name__ == '__main__':
+    main()
diff --git a/utils/lane.py b/utils/lane.py
index 863a92a..6fd2a7d 100644
--- a/utils/lane.py
+++ b/utils/lane.py
@@ -1,133 +1,133 @@
-import numpy as np
-import ujson as json
-from sklearn.linear_model import LinearRegression
-
-
-class LaneEval(object):
-    lr = LinearRegression()
-    pixel_thresh = 20
-    pt_thresh = 0.85
-
-    @staticmethod
-    def get_angle(xs, y_samples):
-        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
-        if len(xs) > 1:
-            LaneEval.lr.fit(ys[:, None], xs)
-            k = LaneEval.lr.coef_[0]
-            theta = np.arctan(k)
-        else:
-            theta = 0
-        return theta
-
-    @staticmethod
-    def line_accuracy(pred, gt, thresh):
-        pred = np.array([p if p >= 0 else -100 for p in pred])
-        gt = np.array([g if g >= 0 else -100 for g in gt])
-        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
-
-    @staticmethod
-    def distances(pred, gt):
-        return np.abs(pred - gt)
-
-    @staticmethod
-    def bench(pred, gt, y_samples, running_time, get_matches=False):
-        if any(len(p) != len(y_samples) for p in pred):
-            raise Exception('Format of lanes error.')
-        if running_time > 20000 or len(gt) + 2 < len(pred):
-            return 0., 0., 1.
-        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
-        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
-        line_accs = []
-        fp, fn = 0., 0.
-        matched = 0.
-        my_matches = [False] * len(pred)
-        my_accs = [0] * len(pred)
-        my_dists = [None] * len(pred)
-        for x_gts, thresh in zip(gt, threshs):
-            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
-            my_accs = np.maximum(my_accs, accs)
-            max_acc = np.max(accs) if len(accs) > 0 else 0.
-            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
-            if len(accs) > 0:
-                my_dists[np.argmax(accs)] = {
-                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
-                    'dists': list(my_dist[np.argmax(accs)])
-                }
-
-            if max_acc < LaneEval.pt_thresh:
-                fn += 1
-            else:
-                my_matches[np.argmax(accs)] = True
-                matched += 1
-            line_accs.append(max_acc)
-        fp = len(pred) - matched
-        if len(gt) > 4 and fn > 0:
-            fn -= 1
-        s = sum(line_accs)
-        if len(gt) > 4:
-            s -= min(line_accs)
-        if get_matches:
-            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
-                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
-        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
-
-    @staticmethod
-    def bench_one_submit(pred_file, gt_file):
-        try:
-            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-        except BaseException as e:
-            raise Exception('Fail to load json file of the prediction.')
-        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-        if len(json_gt) != len(json_pred):
-            raise Exception('We do not get the predictions of all the test tasks')
-        gts = {l['raw_file']: l for l in json_gt}
-        accuracy, fp, fn = 0., 0., 0.
-        run_times = []
-        for pred in json_pred:
-            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
-                raise Exception('raw_file or lanes or run_time not in some predictions.')
-            raw_file = pred['raw_file']
-            pred_lanes = pred['lanes']
-            run_time = pred['run_time']
-            run_times.append(run_time)
-            if raw_file not in gts:
-                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-            gt = gts[raw_file]
-            gt_lanes = gt['lanes']
-            y_samples = gt['h_samples']
-            try:
-                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
-            except BaseException as e:
-                raise Exception('Format of lanes error.')
-            accuracy += a
-            fp += p
-            fn += n
-        num = len(gts)
-        # the first return parameter is the default ranking parameter
-        return json.dumps([{
-            'name': 'Accuracy',
-            'value': accuracy / num,
-            'order': 'desc'
-        }, {
-            'name': 'FP',
-            'value': fp / num,
-            'order': 'asc'
-        }, {
-            'name': 'FN',
-            'value': fn / num,
-            'order': 'asc'
-        }, {
-            'name': 'FPS',
-            'value': 1000. / np.mean(run_times)
-        }])
-
-
-if __name__ == '__main__':
-    import sys
-    try:
-        if len(sys.argv) != 3:
-            raise Exception('Invalid input arguments')
-        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
-    except Exception as e:
-        print(e)
-        # sys.exit(e.message)
+import numpy as np
+import ujson as json
+from sklearn.linear_model import LinearRegression
+
+
+class LaneEval(object):
+    lr = LinearRegression()
+    pixel_thresh = 20
+    pt_thresh = 0.85
+
+    @staticmethod
+    def get_angle(xs, y_samples):
+        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
+        if len(xs) > 1:
+            LaneEval.lr.fit(ys[:, None], xs)
+            k = LaneEval.lr.coef_[0]
+            theta = np.arctan(k)
+        else:
+            theta = 0
+        return theta
+
+    @staticmethod
+    def line_accuracy(pred, gt, thresh):
+        pred = np.array([p if p >= 0 else -100 for p in pred])
+        gt = np.array([g if g >= 0 else -100 for g in gt])
+        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
+
+    @staticmethod
+    def distances(pred, gt):
+        return np.abs(pred - gt)
+
+    @staticmethod
+    def bench(pred, gt, y_samples, running_time, get_matches=False):
+        if any(len(p) != len(y_samples) for p in pred):
+            raise Exception('Format of lanes error.')
+        if running_time > 20000 or len(gt) + 2 < len(pred):
+            return 0., 0., 1.
+        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
+        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
+        line_accs = []
+        fp, fn = 0., 0.
+        matched = 0.
+        my_matches = [False] * len(pred)
+        my_accs = [0] * len(pred)
+        my_dists = [None] * len(pred)
+        for x_gts, thresh in zip(gt, threshs):
+            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
+            my_accs = np.maximum(my_accs, accs)
+            max_acc = np.max(accs) if len(accs) > 0 else 0.
+            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
+            if len(accs) > 0:
+                my_dists[np.argmax(accs)] = {
+                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
+                    'dists': list(my_dist[np.argmax(accs)])
+                }
+
+            if max_acc < LaneEval.pt_thresh:
+                fn += 1
+            else:
+                my_matches[np.argmax(accs)] = True
+                matched += 1
+            line_accs.append(max_acc)
+        fp = len(pred) - matched
+        if len(gt) > 4 and fn > 0:
+            fn -= 1
+        s = sum(line_accs)
+        if len(gt) > 4:
+            s -= min(line_accs)
+        if get_matches:
+            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
+                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
+        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
+
+    @staticmethod
+    def bench_one_submit(pred_file, gt_file):
+        try:
+            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+        except BaseException as e:
+            raise Exception('Fail to load json file of the prediction.')
+        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+        if len(json_gt) != len(json_pred):
+            raise Exception('We do not get the predictions of all the test tasks')
+        gts = {l['raw_file']: l for l in json_gt}
+        accuracy, fp, fn = 0., 0., 0.
+        run_times = []
+        for pred in json_pred:
+            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
+                raise Exception('raw_file or lanes or run_time not in some predictions.')
+            raw_file = pred['raw_file']
+            pred_lanes = pred['lanes']
+            run_time = pred['run_time']
+            run_times.append(run_time)
+            if raw_file not in gts:
+                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+            gt = gts[raw_file]
+            gt_lanes = gt['lanes']
+            y_samples = gt['h_samples']
+            try:
+                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
+            except BaseException as e:
+                raise Exception('Format of lanes error.')
+            accuracy += a
+            fp += p
+            fn += n
+        num = len(gts)
+        # the first return parameter is the default ranking parameter
+        return json.dumps([{
+            'name': 'Accuracy',
+            'value': accuracy / num,
+            'order': 'desc'
+        }, {
+            'name': 'FP',
+            'value': fp / num,
+            'order': 'asc'
+        }, {
+            'name': 'FN',
+            'value': fn / num,
+            'order': 'asc'
+        }, {
+            'name': 'FPS',
+            'value': 1000. / np.mean(run_times)
+        }])
+
+
+if __name__ == '__main__':
+    import sys
+    try:
+        if len(sys.argv) != 3:
+            raise Exception('Invalid input arguments')
+        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
+    except Exception as e:
+        print(e)
+        # sys.exit(e.message)
diff --git a/utils/metric.py b/utils/metric.py
index f2c066d..9fe866e 100644
--- a/utils/metric.py
+++ b/utils/metric.py
@@ -1,177 +1,177 @@
-import argparse
-from pprint import pprint
-
-import cv2
-import numpy as np
-import ujson as json
-from tqdm import tqdm
-from tabulate import tabulate
-from scipy.spatial import distance
-
-
-def show_preds(pred, gt):
-    img = np.zeros((720, 1280, 3), dtype=np.uint8)
-    print(len(gt), 'gts and', len(pred), 'preds')
-    for lane in gt:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
-    for lane in pred:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
-    cv2.imshow('img', img)
-    cv2.waitKey(0)
-
-
-def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
-    pred = np.vstack([pred_x, pred_y]).T
-    gt = np.vstack([gt_x, gt_y]).T
-
-    # pred = pred[pred[:, 0] > 0][:3, :]
-    # gt = gt[gt[:, 0] > 0][:5, :]
-
-    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
-
-    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
-    dist /= np.max(gt_y) - np.min(gt_y)
-    return dist
-
-
-def area_metric(pred, gt, debug=None):
-    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    if len(pred) == 0:
-        return 0., 0., len(gt)
-    line_dists = []
-    fp = 0.
-    matched = 0.
-    gt_matches = [False] * len(gt)
-    pred_matches = [False] * len(pred)
-    pred_dists = [None] * len(pred)
-
-    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
-    for i_gt, gt_points in enumerate(gt):
-        x_gts = [x for x, _ in gt_points]
-        y_gts = [y for _, y in gt_points]
-        for i_pred, pred_points in enumerate(pred):
-            x_preds = [x for x, _ in pred_points]
-            y_preds = [y for _, y in pred_points]
-            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
-
-    best_preds = np.argmin(distances, axis=1)
-    best_gts = np.argmin(distances, axis=0)
-    fp = 0.
-    fn = 0.
-    dist = 0.
-    is_fp = []
-    is_fn = []
-    for i_pred, best_gt in enumerate(best_gts):
-        if best_preds[best_gt] == i_pred:
-            dist += distances[best_gt, i_pred]
-            is_fp.append(False)
-        else:
-            fp += 1
-            is_fp.append(True)
-    for i_gt, best_pred in enumerate(best_preds):
-        if best_gts[best_pred] != i_gt:
-            fn += 1
-            is_fn.append(True)
-        else:
-            is_fn.append(False)
-    if debug:
-        print('is fp')
-        print(is_fp)
-        print('is fn')
-        print(is_fn)
-        print('distances')
-        dists = np.min(distances, axis=0)
-        dists[np.array(is_fp)] = 0
-        print(dists)
-        show_preds(pred, gt)
-
-    return dist, fp, fn
-
-
-def convert_tusimple_format(json_gt):
-    output = []
-    for data in json_gt:
-        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
-                 if any(x > 0 for x in lane)]
-        output.append({
-            'raw_file': data['raw_file'],
-            'run_time': data['run_time'] if 'run_time' in data else None,
-            'lanes': lanes
-        })
-    return output
-
-
-def eval_json(pred_file, gt_file, json_type=None, debug=False):
-    try:
-        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-    except BaseException as e:
-        raise Exception('Fail to load json file of the prediction.')
-    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-    if len(json_gt) != len(json_pred):
-        raise Exception('We do not get the predictions of all the test tasks')
-
-    if json_type == 'tusimple':
-        for gt, pred in zip(json_gt, json_pred):
-            pred['h_samples'] = gt['h_samples']
-        json_gt = convert_tusimple_format(json_gt)
-        json_pred = convert_tusimple_format(json_pred)
-    gts = {l['raw_file']: l for l in json_gt}
-
-    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
-    for pred in tqdm(json_pred):
-        if 'raw_file' not in pred or 'lanes' not in pred:
-            raise Exception('raw_file or lanes not in some predictions.')
-        raw_file = pred['raw_file']
-        pred_lanes = pred['lanes']
-        run_time += pred['run_time'] if 'run_time' in pred else 1.
-
-        if raw_file not in gts:
-            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-        gt = gts[raw_file]
-        gt_lanes = gt['lanes']
-
-        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
-
-        total_distance += distance
-        total_fp += fp
-        total_fn += fn
-
-    num = len(gts)
-    return json.dumps([{
-        'name': 'Distance',
-        'value': total_distance / num,
-        'order': 'desc'
-    }, {
-        'name': 'FP',
-        'value': total_fp,
-        'order': 'asc'
-    }, {
-        'name': 'FN',
-        'value': total_fn,
-        'order': 'asc'
-    }, {
-        'name': 'FPS',
-        'value': 1000. * num / run_time
-    }])
-
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(description="Compute the metrics")
-    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
-    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
-    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
-    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
-    argv = vars(parser.parse_args())
-
-    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
-
-    # pretty-print
-    table = {}
-    for metric in result:
-        if metric['name'] not in table.keys():
-            table[metric['name']] = []
-        table[metric['name']].append(metric['value'])
-    print(tabulate(table, headers='keys'))
+import argparse
+from pprint import pprint
+
+import cv2
+import numpy as np
+import ujson as json
+from tqdm import tqdm
+from tabulate import tabulate
+from scipy.spatial import distance
+
+
+def show_preds(pred, gt):
+    img = np.zeros((720, 1280, 3), dtype=np.uint8)
+    print(len(gt), 'gts and', len(pred), 'preds')
+    for lane in gt:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
+    for lane in pred:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
+    cv2.imshow('img', img)
+    cv2.waitKey(0)
+
+
+def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
+    pred = np.vstack([pred_x, pred_y]).T
+    gt = np.vstack([gt_x, gt_y]).T
+
+    # pred = pred[pred[:, 0] > 0][:3, :]
+    # gt = gt[gt[:, 0] > 0][:5, :]
+
+    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
+
+    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
+    dist /= np.max(gt_y) - np.min(gt_y)
+    return dist
+
+
+def area_metric(pred, gt, debug=None):
+    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    if len(pred) == 0:
+        return 0., 0., len(gt)
+    line_dists = []
+    fp = 0.
+    matched = 0.
+    gt_matches = [False] * len(gt)
+    pred_matches = [False] * len(pred)
+    pred_dists = [None] * len(pred)
+
+    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
+    for i_gt, gt_points in enumerate(gt):
+        x_gts = [x for x, _ in gt_points]
+        y_gts = [y for _, y in gt_points]
+        for i_pred, pred_points in enumerate(pred):
+            x_preds = [x for x, _ in pred_points]
+            y_preds = [y for _, y in pred_points]
+            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
+
+    best_preds = np.argmin(distances, axis=1)
+    best_gts = np.argmin(distances, axis=0)
+    fp = 0.
+    fn = 0.
+    dist = 0.
+    is_fp = []
+    is_fn = []
+    for i_pred, best_gt in enumerate(best_gts):
+        if best_preds[best_gt] == i_pred:
+            dist += distances[best_gt, i_pred]
+            is_fp.append(False)
+        else:
+            fp += 1
+            is_fp.append(True)
+    for i_gt, best_pred in enumerate(best_preds):
+        if best_gts[best_pred] != i_gt:
+            fn += 1
+            is_fn.append(True)
+        else:
+            is_fn.append(False)
+    if debug:
+        print('is fp')
+        print(is_fp)
+        print('is fn')
+        print(is_fn)
+        print('distances')
+        dists = np.min(distances, axis=0)
+        dists[np.array(is_fp)] = 0
+        print(dists)
+        show_preds(pred, gt)
+
+    return dist, fp, fn
+
+
+def convert_tusimple_format(json_gt):
+    output = []
+    for data in json_gt:
+        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
+                 if any(x > 0 for x in lane)]
+        output.append({
+            'raw_file': data['raw_file'],
+            'run_time': data['run_time'] if 'run_time' in data else None,
+            'lanes': lanes
+        })
+    return output
+
+
+def eval_json(pred_file, gt_file, json_type=None, debug=False):
+    try:
+        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+    except BaseException as e:
+        raise Exception('Fail to load json file of the prediction.')
+    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+    if len(json_gt) != len(json_pred):
+        raise Exception('We do not get the predictions of all the test tasks')
+
+    if json_type == 'tusimple':
+        for gt, pred in zip(json_gt, json_pred):
+            pred['h_samples'] = gt['h_samples']
+        json_gt = convert_tusimple_format(json_gt)
+        json_pred = convert_tusimple_format(json_pred)
+    gts = {l['raw_file']: l for l in json_gt}
+
+    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
+    for pred in tqdm(json_pred):
+        if 'raw_file' not in pred or 'lanes' not in pred:
+            raise Exception('raw_file or lanes not in some predictions.')
+        raw_file = pred['raw_file']
+        pred_lanes = pred['lanes']
+        run_time += pred['run_time'] if 'run_time' in pred else 1.
+
+        if raw_file not in gts:
+            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+        gt = gts[raw_file]
+        gt_lanes = gt['lanes']
+
+        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
+
+        total_distance += distance
+        total_fp += fp
+        total_fn += fn
+
+    num = len(gts)
+    return json.dumps([{
+        'name': 'Distance',
+        'value': total_distance / num,
+        'order': 'desc'
+    }, {
+        'name': 'FP',
+        'value': total_fp,
+        'order': 'asc'
+    }, {
+        'name': 'FN',
+        'value': total_fn,
+        'order': 'asc'
+    }, {
+        'name': 'FPS',
+        'value': 1000. * num / run_time
+    }])
+
+
+if __name__ == '__main__':
+    parser = argparse.ArgumentParser(description="Compute the metrics")
+    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
+    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
+    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
+    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
+    argv = vars(parser.parse_args())
+
+    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
+
+    # pretty-print
+    table = {}
+    for metric in result:
+        if metric['name'] not in table.keys():
+            table[metric['name']] = []
+        table[metric['name']].append(metric['value'])
+    print(tabulate(table, headers='keys'))
diff --git a/utils/plot_log.py b/utils/plot_log.py
index ee18cf1..aaba69a 100644
--- a/utils/plot_log.py
+++ b/utils/plot_log.py
@@ -1,161 +1,161 @@
-import os
-import re
-import argparse
-import datetime
-
-import numpy as np
-import matplotlib.dates as mdates
-import matplotlib.colors as colors
-import matplotlib.pyplot as plt
-
-ITER_PATTERN = re.compile(
-    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
-)
-LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
-EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
-EXPS_DIR = '../data_lane-regression/experiments'
-
-# TODO: refactor this file
-
-
-def smooth_curve(xs, factor):
-    smoothed = [None] * len(xs)
-    smoothed[0] = xs[0]
-    for i in range(1, len(xs)):
-        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
-
-    return smoothed
-
-
-def plot_loss(data,
-              fig,
-              ax,
-              label,
-              plot_lr=True,
-              smoothing=0,
-              xaxis='time',
-              only_epoch_end=False,
-              plot_val=False,
-              plot_loss_comps=False):
-    iter_data = data['iter_update']
-    epoch_data = data['epoch_update']
-    now = datetime.datetime.today()
-    if xaxis == 'epoch':
-        if only_epoch_end:
-            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
-        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
-    elif xaxis == 'time':
-        d0 = iter_data[0]['date']
-        x = [now + (d['date'] - d0) for d in iter_data]
-    elif xaxis == 'iter':
-        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
-    loss = [d['loss'] for d in iter_data]
-    if plot_loss_comps:
-        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
-    if plot_val:
-        val_loss = [d['val_loss'] for d in epoch_data]
-        if xaxis == 'epoch':
-            val_loss_x = [d['epoch'] for d in epoch_data]
-        else:
-            val_loss_d0 = epoch_data[0]['date']
-            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
-    loss_smooth = smooth_curve(loss, factor=smoothing)
-    if plot_lr:
-        lr = [d['lr'] for d in iter_data]
-        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
-                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
-        if len(lr_decays) < 10:
-            for epoch, old, new in lr_decays:
-                ax.axvline(x=epoch, linestyle='--')
-        ax.plot(x, lr, label='LR: {}'.format(label))
-    ax.set_yscale('log')
-    ax.set_title('Loss')
-    ax.set_xlabel('Epoch')
-    ax.set_ylabel('Loss')
-    loss_line = ax.plot(x, loss_smooth)[0]
-    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
-    loss_line_color[-1] = 0.5
-    if plot_loss_comps:
-        for loss_comp in loss_comps:
-            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
-            line_color = np.array(colors.to_rgba(line.get_color()))
-            line_color[-1] = 0.5
-            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
-    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
-    if plot_val:
-        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
-    if xaxis == 'time':
-        fig.autofmt_xdate()
-        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
-
-
-def parse_line(line):
-    iter_match = re.match(ITER_PATTERN, line)
-    epoch_match = re.match(EPOCH_PATTERN, line)
-    data = {}
-    if iter_match is not None:
-        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
-        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
-            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
-                loss), float(speed), float(lr)
-        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
-        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
-        data['iter_update'] = {
-            'date': date,
-            'epoch': epoch,
-            'total_epochs': total_epochs,
-            'iter_nb': iter_nb,
-            'total_iters': total_iters,
-            'loss': loss,
-            'speed': date,
-            'loss_comps': loss_comps,
-            'lr': lr,
-        }
-    if epoch_match is not None:
-        date, epoch, _, val_loss = epoch_match.groups()
-        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
-        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
-
-    return data
-
-
-def parse_log(log_path):
-    with open(log_path, 'r') as log_file:
-        lines = [line.rstrip() for line in log_file.readlines()]
-    data = {'iter_update': [], 'epoch_update': []}
-    for line in lines:
-        line_data = parse_line(line)
-        for key in line_data:
-            data[key].append(line_data[key])
-    return data
-
-
-def get_logfilepath(exp_name):
-    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description='Visualization')
-    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
-    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
-    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
-
-    return parser.parse_args()
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    fig, ax = plt.subplots(nrows=1, ncols=1)
-    for exp_name in args.exp_name:
-        log_filepath = get_logfilepath(exp_name)
-        data = parse_log(log_filepath)
-        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
-
-    # Show the major grid lines with dark grey lines
-    plt.grid(b=True, which='major', color='#666666', linestyle='-')
-
-    # Show the minor grid lines with very faint and almost transparent grey lines
-    plt.minorticks_on()
-    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
-    plt.legend()
-    plt.show()
+import os
+import re
+import argparse
+import datetime
+
+import numpy as np
+import matplotlib.dates as mdates
+import matplotlib.colors as colors
+import matplotlib.pyplot as plt
+
+ITER_PATTERN = re.compile(
+    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
+)
+LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
+EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
+EXPS_DIR = '../data_lane-regression/experiments'
+
+# TODO: refactor this file
+
+
+def smooth_curve(xs, factor):
+    smoothed = [None] * len(xs)
+    smoothed[0] = xs[0]
+    for i in range(1, len(xs)):
+        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
+
+    return smoothed
+
+
+def plot_loss(data,
+              fig,
+              ax,
+              label,
+              plot_lr=True,
+              smoothing=0,
+              xaxis='time',
+              only_epoch_end=False,
+              plot_val=False,
+              plot_loss_comps=False):
+    iter_data = data['iter_update']
+    epoch_data = data['epoch_update']
+    now = datetime.datetime.today()
+    if xaxis == 'epoch':
+        if only_epoch_end:
+            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
+        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
+    elif xaxis == 'time':
+        d0 = iter_data[0]['date']
+        x = [now + (d['date'] - d0) for d in iter_data]
+    elif xaxis == 'iter':
+        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
+    loss = [d['loss'] for d in iter_data]
+    if plot_loss_comps:
+        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
+    if plot_val:
+        val_loss = [d['val_loss'] for d in epoch_data]
+        if xaxis == 'epoch':
+            val_loss_x = [d['epoch'] for d in epoch_data]
+        else:
+            val_loss_d0 = epoch_data[0]['date']
+            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
+    loss_smooth = smooth_curve(loss, factor=smoothing)
+    if plot_lr:
+        lr = [d['lr'] for d in iter_data]
+        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
+                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
+        if len(lr_decays) < 10:
+            for epoch, old, new in lr_decays:
+                ax.axvline(x=epoch, linestyle='--')
+        ax.plot(x, lr, label='LR: {}'.format(label))
+    ax.set_yscale('log')
+    ax.set_title('Loss')
+    ax.set_xlabel('Epoch')
+    ax.set_ylabel('Loss')
+    loss_line = ax.plot(x, loss_smooth)[0]
+    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
+    loss_line_color[-1] = 0.5
+    if plot_loss_comps:
+        for loss_comp in loss_comps:
+            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
+            line_color = np.array(colors.to_rgba(line.get_color()))
+            line_color[-1] = 0.5
+            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
+    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
+    if plot_val:
+        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
+    if xaxis == 'time':
+        fig.autofmt_xdate()
+        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
+
+
+def parse_line(line):
+    iter_match = re.match(ITER_PATTERN, line)
+    epoch_match = re.match(EPOCH_PATTERN, line)
+    data = {}
+    if iter_match is not None:
+        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
+        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
+            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
+                loss), float(speed), float(lr)
+        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
+        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
+        data['iter_update'] = {
+            'date': date,
+            'epoch': epoch,
+            'total_epochs': total_epochs,
+            'iter_nb': iter_nb,
+            'total_iters': total_iters,
+            'loss': loss,
+            'speed': date,
+            'loss_comps': loss_comps,
+            'lr': lr,
+        }
+    if epoch_match is not None:
+        date, epoch, _, val_loss = epoch_match.groups()
+        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
+        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
+
+    return data
+
+
+def parse_log(log_path):
+    with open(log_path, 'r') as log_file:
+        lines = [line.rstrip() for line in log_file.readlines()]
+    data = {'iter_update': [], 'epoch_update': []}
+    for line in lines:
+        line_data = parse_line(line)
+        for key in line_data:
+            data[key].append(line_data[key])
+    return data
+
+
+def get_logfilepath(exp_name):
+    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description='Visualization')
+    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
+    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
+    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
+
+    return parser.parse_args()
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    fig, ax = plt.subplots(nrows=1, ncols=1)
+    for exp_name in args.exp_name:
+        log_filepath = get_logfilepath(exp_name)
+        data = parse_log(log_filepath)
+        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
+
+    # Show the major grid lines with dark grey lines
+    plt.grid(b=True, which='major', color='#666666', linestyle='-')
+
+    # Show the minor grid lines with very faint and almost transparent grey lines
+    plt.minorticks_on()
+    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
+    plt.legend()
+    plt.show()
diff --git a/utils/upperbound.py b/utils/upperbound.py
index 78af9b3..1fbce9e 100644
--- a/utils/upperbound.py
+++ b/utils/upperbound.py
@@ -1,44 +1,44 @@
-import sys
-import warnings
-
-import numpy as np
-from progressbar import progressbar
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-warnings.simplefilter('ignore', np.RankWarning)
-
-
-def polyfit_upperbound(dataset, degree):
-    evaluator = Evaluator(dataset, '/tmp', degree)
-    print('Predicting with upperbound...')
-    for i, anno in enumerate(progressbar(dataset.annotations)):
-        label = anno['label']
-        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
-        pred[:, :3] = label[:, :3]
-        for j, lane in enumerate(label):
-            if lane[0] == 0:
-                continue
-            xy = lane[3:]
-            x = xy[:(len(xy) // 2)]
-            y = xy[(len(xy) // 2):]
-            ind = x > 0
-            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
-        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
-    _, result = evaluator.eval(label='upperbound', only_metrics=True)
-
-    return result
-
-
-if __name__ == "__main__":
-    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
-    dataset = cfg.get_dataset('test')
-    for n in range(1, 5 + 1):
-        result = polyfit_upperbound(dataset, n)
-        print('Degree {} upperbound:'.format(n))
-        for metric in result:
-            if metric['name'] == 'Accuracy':
-                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
-            else:
-                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))
+import sys
+import warnings
+
+import numpy as np
+from progressbar import progressbar
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+warnings.simplefilter('ignore', np.RankWarning)
+
+
+def polyfit_upperbound(dataset, degree):
+    evaluator = Evaluator(dataset, '/tmp', degree)
+    print('Predicting with upperbound...')
+    for i, anno in enumerate(progressbar(dataset.annotations)):
+        label = anno['label']
+        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
+        pred[:, :3] = label[:, :3]
+        for j, lane in enumerate(label):
+            if lane[0] == 0:
+                continue
+            xy = lane[3:]
+            x = xy[:(len(xy) // 2)]
+            y = xy[(len(xy) // 2):]
+            ind = x > 0
+            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
+        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
+    _, result = evaluator.eval(label='upperbound', only_metrics=True)
+
+    return result
+
+
+if __name__ == "__main__":
+    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
+    dataset = cfg.get_dataset('test')
+    for n in range(1, 5 + 1):
+        result = polyfit_upperbound(dataset, n)
+        print('Degree {} upperbound:'.format(n))
+        for metric in result:
+            if metric['name'] == 'Accuracy':
+                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
+            else:
+                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))

[2021-08-04 23:37:54,651] [INFO] Starting testing.
[2021-08-04 23:37:58,823] [INFO] Testing iteration: 1/2782
[2021-08-06 23:28:08,451] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-06 23:28:08,471] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-06 23:28:08,482] [INFO] Args:
Namespace(batch_size=None, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=None, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-06 23:28:10,569] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/.gitignore b/.gitignore
index e4bcbf2..fdf6f3f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,8 +1,8 @@
-__pycache__
-experiments
-.vscode
-venv
-config.yaml
-/datasets/
-lib/nms/build/
-lib/nms/dist/
+__pycache__
+experiments
+.vscode
+venv
+config.yaml
+/datasets/
+lib/nms/build/
+lib/nms/dist/
diff --git a/LICENSE b/LICENSE
index f8fe53d..33d52bc 100644
--- a/LICENSE
+++ b/LICENSE
@@ -1,21 +1,21 @@
-MIT License
-
-Copyright (c) 2020 Lucas Tabelini Torres
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+MIT License
+
+Copyright (c) 2020 Lucas Tabelini Torres
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
diff --git a/README.md b/README.md
index b4af404..d49fcb0 100644
--- a/README.md
+++ b/README.md
@@ -1,165 +1,166 @@
-<div align="center">
-
-# PolyLaneNet
-![Method overview](figures/method-overview.png "Method overview")
-</div>
-
-## Description
-Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
-[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
-
-**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
-
-## Table of Contents
-1. [Installation](#installation)
-2. [Usage](#usage)
-3. [Reproducing the paper results](#reproducing)
-
-<a name="installation"/>
-
-### Installation
-The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
-
-Install dependencies:
-```
-pip install -r requirements.txt
-```
-
-<a name="usage"/>
-
-### Usage
-#### Training
-Every setting for a training is set through a YAML configuration file.
-Thus, in order to train a model you will have to setup the configuration file.
-An example is shown:
-```yaml
-# Training settings
-exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
-iter_log_interval: 1 # Log training iteration every N iterations
-iter_time_window: 100 # Moving average iterations window for the printed loss metric
-model_save_interval: 1 # Save model every N epochs
-seed: 0 # Seed for randomness
-backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
-
-# Dataset settings
-datasets:
-  train:
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: # ImgAug augmentations
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "datasets/tusimple" # Dataset root
-
-  test: &test
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      img_size: [360, 640]
-      root: "datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
-```
-
-With the config file created, run the training script:
-```bash
-python train.py --exp_name tusimple --cfg config.yaml
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the training (.yaml)
-  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
-  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
-  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
-```
-
-#### Testing
-After training, run the `test.py` script to get the metrics:
-```bash
-python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
-  --epoch EPOCH         Epoch to test the model on
-  --batch_size          Number of images per batch
-  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
-```
-
-If you have any issues with either training or testing feel free to open an issue.
-
-<a name="reproducing"/>
-
-### Reproducing the paper results
-
-#### Models
-All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
-
-#### Datasets
-- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
-- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
-- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
-
-#### How to
-To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
-If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
-If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
-1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
-1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
-1. Move the downloaded experiment to your `exps_dir` folder.
-
-Then, run:
-
-```bash
-python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
-```
-Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
-
-
+<div align="center">
+
+# PolyLaneNet
+![Method overview](figures/method-overview.png "Method overview")
+</div>
+
+## Description
+Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
+[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
+
+**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
+
+## Table of Contents
+1. [Installation](#installation)
+2. [Usage](#usage)
+3. [Reproducing the paper results](#reproducing)
+
+<a name="installation"/>
+
+### Installation
+The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
+
+Install dependencies:
+```
+pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
+```
+
+<a name="usage"/>
+
+### Usage
+#### Training
+Every setting for a training is set through a YAML configuration file.
+Thus, in order to train a model you will have to setup the configuration file.
+An example is shown:
+```yaml
+# Training settings
+exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
+iter_log_interval: 1 # Log training iteration every N iterations
+iter_time_window: 100 # Moving average iterations window for the printed loss metric
+model_save_interval: 1 # Save model every N epochs
+seed: 0 # Seed for randomness
+backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
+
+# Dataset settings
+datasets:
+  train:
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: # ImgAug augmentations
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "datasets/tusimple" # Dataset root
+
+  test: &test
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      img_size: [360, 640]
+      root: "datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
+```
+
+With the config file created, run the training script:
+```bash
+python train.py --exp_name tusimple --cfg config.yaml
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the training (.yaml)
+  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
+  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
+  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
+```
+
+#### Testing
+After training, run the `test.py` script to get the metrics:
+```bash
+python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
+  --epoch EPOCH         Epoch to test the model on
+  --batch_size          Number of images per batch
+  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
+```
+
+If you have any issues with either training or testing feel free to open an issue.
+
+<a name="reproducing"/>
+
+### Reproducing the paper results
+
+#### Models
+All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
+
+#### Datasets
+- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
+- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
+- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
+
+#### How to
+To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
+If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
+If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
+1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
+1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
+1. Move the downloaded experiment to your `exps_dir` folder.
+
+Then, run:
+
+```bash
+python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
+```
+Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
+
+
diff --git a/cfgs/elas.yaml b/cfgs/elas.yaml
index 98a03bd..8d9f910 100644
--- a/cfgs/elas.yaml
+++ b/cfgs/elas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 35
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 35
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 35
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 35
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/elas_cls.yaml b/cfgs/elas_cls.yaml
index a251b94..db6d9c8 100644
--- a/cfgs/elas_cls.yaml
+++ b/cfgs/elas_cls.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: true
-    extra_outputs: 40 # 5 lanes * 8 classes
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 1
-  poly_weight: 300
-batch_size: 16
-epochs: 385
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: true
+    extra_outputs: 40 # 5 lanes * 8 classes
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 1
+  poly_weight: 300
+batch_size: 16
+epochs: 385
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/llamas.yaml b/cfgs/llamas.yaml
index 5806168..1af205d 100644
--- a/cfgs/llamas.yaml
+++ b/cfgs/llamas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 75
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 75
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: llamas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/llamas"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: llamas
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/llamas"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 75
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 75
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: llamas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/llamas"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: llamas
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/llamas"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple.yaml b/cfgs/tusimple.yaml
index 01da72b..2a13cb1 100644
--- a/cfgs/tusimple.yaml
+++ b/cfgs/tusimple.yaml
@@ -1,73 +1,73 @@
-# Training settings
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-seed: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+seed: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_1order.yaml b/cfgs/tusimple_1order.yaml
index 66a8607..3e5f617 100644
--- a/cfgs/tusimple_1order.yaml
+++ b/cfgs/tusimple_1order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 1 
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 9000, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression//datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression//datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 1 
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 9000, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression//datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression//datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_2order.yaml b/cfgs/tusimple_2order.yaml
index 9091dcc..2e3cdca 100644
--- a/cfgs/tusimple_2order.yaml
+++ b/cfgs/tusimple_2order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_320x180.yaml b/cfgs/tusimple_320x180.yaml
index fb61010..32b8f5e 100644
--- a/cfgs/tusimple_320x180.yaml
+++ b/cfgs/tusimple_320x180.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [180, 320]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [180, 320]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [180, 320]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [180, 320]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_480x270.yaml b/cfgs/tusimple_480x270.yaml
index e9077d4..3312074 100644
--- a/cfgs/tusimple_480x270.yaml
+++ b/cfgs/tusimple_480x270.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [270, 480]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [270, 480]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [270, 480]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [270, 480]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_efficientnetb1.yaml b/cfgs/tusimple_efficientnetb1.yaml
index f085635..b1a080a 100644
--- a/cfgs/tusimple_efficientnetb1.yaml
+++ b/cfgs/tusimple_efficientnetb1.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b1'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b1'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_fulltrain.yaml b/cfgs/tusimple_fulltrain.yaml
index 0c0f485..69dfe67 100644
--- a/cfgs/tusimple_fulltrain.yaml
+++ b/cfgs/tusimple_fulltrain.yaml
@@ -1,72 +1,72 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train+val
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple-test"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train+val
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple-test"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_no_share_top_y.yaml b/cfgs/tusimple_no_share_top_y.yaml
index ec81eb2..e1081a5 100644
--- a/cfgs/tusimple_no_share_top_y.yaml
+++ b/cfgs/tusimple_no_share_top_y.yaml
@@ -1,74 +1,74 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    share_top_y: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    share_top_y: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_noaug.yaml b/cfgs/tusimple_noaug.yaml
index 8b4b9db..edd5362 100644
--- a/cfgs/tusimple_noaug.yaml
+++ b/cfgs/tusimple_noaug.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: []
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: []
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_nopretrain.yaml b/cfgs/tusimple_nopretrain.yaml
index 0de222f..ccf039f 100644
--- a/cfgs/tusimple_nopretrain.yaml
+++ b/cfgs/tusimple_nopretrain.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: false 
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: false 
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet34.yaml b/cfgs/tusimple_resnet34.yaml
index 6eafef9..753dc12 100644
--- a/cfgs/tusimple_resnet34.yaml
+++ b/cfgs/tusimple_resnet34.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet34'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet34'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet50.yaml b/cfgs/tusimple_resnet50.yaml
index 58784a8..a32ef90 100644
--- a/cfgs/tusimple_resnet50.yaml
+++ b/cfgs/tusimple_resnet50.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet50'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "/dados/tabelini/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "/dados/tabelini/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet50'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "/dados/tabelini/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "/dados/tabelini/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/lib/config.py b/lib/config.py
index d5d6275..e9405c9 100644
--- a/lib/config.py
+++ b/lib/config.py
@@ -1,45 +1,45 @@
-import yaml
-import torch
-
-import lib.models as models
-import lib.datasets as datasets
-
-
-class Config(object):
-    def __init__(self, config_path):
-        self.config = {}
-        self.load(config_path)
-
-    def load(self, path):
-        with open(path, 'r') as file:
-            self.config_str = file.read()
-        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
-
-    def __repr__(self):
-        return self.config_str
-
-    def get_dataset(self, split):
-        return getattr(datasets,
-                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
-
-    def get_model(self):
-        name = self.config['model']['name']
-        parameters = self.config['model']['parameters']
-        return getattr(models, name)(**parameters)
-
-    def get_optimizer(self, model_parameters):
-        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
-                                                                      **self.config['optimizer']['parameters'])
-
-    def get_lr_scheduler(self, optimizer):
-        return getattr(torch.optim.lr_scheduler,
-                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
-
-    def get_loss_parameters(self):
-        return self.config['loss_parameters']
-
-    def get_test_parameters(self):
-        return self.config['test_parameters']
-
-    def __getitem__(self, item):
-        return self.config[item]
+import yaml
+import torch
+
+import lib.models as models
+import lib.datasets as datasets
+
+
+class Config(object):
+    def __init__(self, config_path):
+        self.config = {}
+        self.load(config_path)
+
+    def load(self, path):
+        with open(path, 'r') as file:
+            self.config_str = file.read()
+        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
+
+    def __repr__(self):
+        return self.config_str
+
+    def get_dataset(self, split):
+        return getattr(datasets,
+                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
+
+    def get_model(self):
+        name = self.config['model']['name']
+        parameters = self.config['model']['parameters']
+        return getattr(models, name)(**parameters)
+
+    def get_optimizer(self, model_parameters):
+        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
+                                                                      **self.config['optimizer']['parameters'])
+
+    def get_lr_scheduler(self, optimizer):
+        return getattr(torch.optim.lr_scheduler,
+                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
+
+    def get_loss_parameters(self):
+        return self.config['loss_parameters']
+
+    def get_test_parameters(self):
+        return self.config['test_parameters']
+
+    def __getitem__(self, item):
+        return self.config[item]
diff --git a/lib/datasets/__init__.py b/lib/datasets/__init__.py
index bc2eb7a..a870757 100644
--- a/lib/datasets/__init__.py
+++ b/lib/datasets/__init__.py
@@ -1,3 +1,3 @@
-from .lane_dataset import LaneDataset
-
-__all__ = ["LaneDataset"]
+from .lane_dataset import LaneDataset
+
+__all__ = ["LaneDataset"]
diff --git a/lib/datasets/elas.py b/lib/datasets/elas.py
index 490f37a..c2a0823 100644
--- a/lib/datasets/elas.py
+++ b/lib/datasets/elas.py
@@ -1,137 +1,137 @@
-import os
-import math
-import random
-
-import cv2
-import numpy as np
-import xmljson
-from scipy import interpolate
-from lxml.etree import fromstring
-
-SPLIT_DIRECTORIES = {
-    'train': [
-        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
-        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
-    ],
-    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
-}
-
-CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
-ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
-
-
-class ELAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.root = root
-        self.split = split
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_directories = SPLIT_DIRECTORIES[split]
-
-        self.img_w, self.img_h = 640, 480
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-        self.class_icons = {
-            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
-            for cls_id in ID_TO_CATEGORY
-        }
-
-    def get_class_icon(self, cls_id):
-        return self.class_icons[cls_id]
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def interp_lane(self, lane, ys, step=10):
-        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
-        if len(pts) <= 1:
-            return None
-        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
-        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
-        interp_xs = interpolate.splev(interp_ys, spline)
-
-        return list(zip(interp_xs, interp_ys))
-
-    def load_dir_annotations(self, dataset_dir):
-        annotations = []
-        max_points = 0
-        max_lanes = 0
-
-        # read config.xml
-        config_fname = os.path.join(dataset_dir, 'config.xml')
-        if not os.path.isfile(config_fname):
-            raise Exception('config.xml not found: {}'.format(config_fname))
-        with open(config_fname, 'r') as hf:
-            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
-
-        # read ground truth
-        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
-        if not os.path.isfile(gt_fname):
-            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
-        with open(gt_fname, 'r') as hf:
-            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
-
-        # read frame annotations
-        for frame in gt['frames']['frame']:
-            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
-
-            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
-            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
-            pts = ['p1', 'p2', 'p3', 'p4']
-            lanes = []
-            categories = []
-            for side in ['Left', 'Right']:
-                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
-                lane = self.interp_lane(lane, ys)
-                if lane is None:
-                    continue
-                max_points = max(max_points, len(lane))
-                lanes.append(lane)
-                category = str(frame['@lmt{}'.format(side)])
-                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
-            max_lanes = max(max_lanes, len(lanes))
-            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
-
-        return annotations, max_points, max_lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        for directory in self.anno_directories:
-            dir_path = os.path.join(self.root, directory)
-            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
-
-            self.annotations.extend(dir_annos)
-            self.max_points = max(self.max_points, dir_max_points)
-            self.max_lanes = max(self.max_lanes, dir_max_lanes)
-
-        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
-                                                                            self.max_lanes))
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import math
+import random
+
+import cv2
+import numpy as np
+import xmljson
+from scipy import interpolate
+from lxml.etree import fromstring
+
+SPLIT_DIRECTORIES = {
+    'train': [
+        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
+        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
+    ],
+    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
+}
+
+CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
+ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
+
+
+class ELAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.root = root
+        self.split = split
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_directories = SPLIT_DIRECTORIES[split]
+
+        self.img_w, self.img_h = 640, 480
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+        self.class_icons = {
+            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
+            for cls_id in ID_TO_CATEGORY
+        }
+
+    def get_class_icon(self, cls_id):
+        return self.class_icons[cls_id]
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def interp_lane(self, lane, ys, step=10):
+        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
+        if len(pts) <= 1:
+            return None
+        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
+        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
+        interp_xs = interpolate.splev(interp_ys, spline)
+
+        return list(zip(interp_xs, interp_ys))
+
+    def load_dir_annotations(self, dataset_dir):
+        annotations = []
+        max_points = 0
+        max_lanes = 0
+
+        # read config.xml
+        config_fname = os.path.join(dataset_dir, 'config.xml')
+        if not os.path.isfile(config_fname):
+            raise Exception('config.xml not found: {}'.format(config_fname))
+        with open(config_fname, 'r') as hf:
+            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
+
+        # read ground truth
+        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
+        if not os.path.isfile(gt_fname):
+            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
+        with open(gt_fname, 'r') as hf:
+            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
+
+        # read frame annotations
+        for frame in gt['frames']['frame']:
+            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
+
+            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
+            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
+            pts = ['p1', 'p2', 'p3', 'p4']
+            lanes = []
+            categories = []
+            for side in ['Left', 'Right']:
+                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
+                lane = self.interp_lane(lane, ys)
+                if lane is None:
+                    continue
+                max_points = max(max_points, len(lane))
+                lanes.append(lane)
+                category = str(frame['@lmt{}'.format(side)])
+                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
+            max_lanes = max(max_lanes, len(lanes))
+            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
+
+        return annotations, max_points, max_lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        for directory in self.anno_directories:
+            dir_path = os.path.join(self.root, directory)
+            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
+
+            self.annotations.extend(dir_annos)
+            self.max_points = max(self.max_points, dir_max_points)
+            self.max_lanes = max(self.max_lanes, dir_max_lanes)
+
+        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
+                                                                            self.max_lanes))
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..1f520dc 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -1,239 +1,239 @@
-import cv2
-import numpy as np
-import imgaug.augmenters as iaa
-from imgaug.augmenters import Resize
-from torchvision.transforms import ToTensor
-from torch.utils.data.dataset import Dataset
-from imgaug.augmentables.lines import LineString, LineStringsOnImage
-
-from .elas import ELAS
-from .llamas import LLAMAS
-from .tusimple import TuSimple
-from .nolabel_dataset import NoLabelDataset
-
-GT_COLOR = (255, 0, 0)
-PRED_HIT_COLOR = (0, 255, 0)
-PRED_MISS_COLOR = (0, 0, 255)
-IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
-IMAGENET_STD = np.array([0.229, 0.224, 0.225])
-
-
-class LaneDataset(Dataset):
-    def __init__(self,
-                 dataset='tusimple',
-                 augmentations=None,
-                 normalize=False,
-                 split='train',
-                 img_size=(360, 640),
-                 aug_chance=1.,
-                 **kwargs):
-        super(LaneDataset, self).__init__()
-        if dataset == 'tusimple':
-            self.dataset = TuSimple(split=split, **kwargs)
-        elif dataset == 'llamas':
-            self.dataset = LLAMAS(split=split, **kwargs)
-        elif dataset == 'elas':
-            self.dataset = ELAS(split=split, **kwargs)
-        elif dataset == 'nolabel_dataset':
-            self.dataset = NoLabelDataset(**kwargs)
-        else:
-            raise NotImplementedError()
-
-        self.transform_annotations()
-        self.img_h, self.img_w = img_size
-
-        if augmentations is not None:
-            # add augmentations
-            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
-                             for aug in augmentations]  # add augmentation
-
-        self.normalize = normalize
-        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
-        self.to_tensor = ToTensor()
-        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
-        self.max_lanes = self.dataset.max_lanes
-
-    def transform_annotation(self, anno, img_wh=None):
-        if img_wh is None:
-            img_h = self.dataset.get_img_heigth(anno['path'])
-            img_w = self.dataset.get_img_width(anno['path'])
-        else:
-            img_w, img_h = img_wh
-
-        old_lanes = anno['lanes']
-        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
-        old_lanes = zip(old_lanes, categories)
-        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
-        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
-        lanes[:, 0] = 0
-        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
-        for lane_pos, (lane, category) in enumerate(old_lanes):
-            lower, upper = lane[0][1], lane[-1][1]
-            xs = np.array([p[0] for p in lane]) / img_w
-            ys = np.array([p[1] for p in lane]) / img_h
-            lanes[lane_pos, 0] = category
-            lanes[lane_pos, 1] = lower / img_h
-            lanes[lane_pos, 2] = upper / img_h
-            lanes[lane_pos, 3:3 + len(xs)] = xs
-            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
-
-        new_anno = {
-            'path': anno['path'],
-            'label': lanes,
-            'old_anno': anno,
-            'categories': [cat for _, cat in old_lanes]
-        }
-
-        return new_anno
-
-    @property
-    def annotations(self):
-        return self.dataset.annotations
-
-    def transform_annotations(self):
-        print('Transforming annotations...')
-        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
-        print('Done.')
-
-    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
-        if img is None:
-            img, label, _ = self.__getitem__(idx, transform=True)
-            # Tensor to opencv image
-            img = img.permute(1, 2, 0).numpy()
-            # Unnormalize
-            if self.normalize:
-                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
-            img = (img * 255).astype(np.uint8)
-        else:
-            _, label, _ = self.__getitem__(idx)
-
-        img_h, img_w, _ = img.shape
-
-        # Draw label
-        for i, lane in enumerate(label):
-            if lane[0] == 0:  # Skip invalid lanes
-                continue
-            lane = lane[3:]  # remove conf, upper and lower positions
-            xs = lane[:len(lane) // 2]
-            ys = lane[len(lane) // 2:]
-            ys = ys[xs >= 0]
-            xs = xs[xs >= 0]
-
-            # draw GT points
-            for p in zip(xs, ys):
-                p = (int(p[0] * img_w), int(p[1] * img_h))
-                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
-
-            # draw GT lane ID
-            cv2.putText(img,
-                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
-                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                        fontScale=1,
-                        color=(0, 255, 0))
-
-        if pred is None:
-            return img
-
-        # Draw predictions
-        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
-        matches, accs, _ = self.dataset.get_metrics(pred, idx)
-        overlay = img.copy()
-        for i, lane in enumerate(pred):
-            if matches[i]:
-                color = PRED_HIT_COLOR
-            else:
-                color = PRED_MISS_COLOR
-            lane = lane[1:]  # remove conf
-            lower, upper = lane[0], lane[1]
-            lane = lane[2:]  # remove upper, lower positions
-
-            # generate points from the polynomial
-            ys = np.linspace(lower, upper, num=100)
-            points = np.zeros((len(ys), 2), dtype=np.int32)
-            points[:, 1] = (ys * img_h).astype(int)
-            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
-            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
-
-            # draw lane with a polyline on the overlay
-            for current_point, next_point in zip(points[:-1], points[1:]):
-                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
-
-            # draw class icon
-            if cls_pred is not None and len(points) > 0:
-                class_icon = self.dataset.get_class_icon(cls_pred[i])
-                class_icon = cv2.resize(class_icon, (32, 32))
-                mid = tuple(points[len(points) // 2] - 60)
-                x, y = mid
-
-                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
-
-            # draw lane ID
-            if len(points) > 0:
-                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
-
-            # draw lane accuracy
-            if len(points) > 0:
-                cv2.putText(img,
-                            '{:.2f}'.format(accs[i] * 100),
-                            tuple(points[len(points) // 2] - 30),
-                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                            fontScale=.75,
-                            color=color)
-        # Add lanes overlay
-        w = 0.6
-        img = ((1. - w) * img + w * overlay).astype(np.uint8)
-
-        return img
-
-    def lane_to_linestrings(self, lanes):
-        lines = []
-        for lane in lanes:
-            lines.append(LineString(lane))
-
-        return lines
-
-    def linestrings_to_lanes(self, lines):
-        lanes = []
-        for line in lines:
-            lanes.append(line.coords)
-
-        return lanes
-
-    def __getitem__(self, idx, transform=True):
-        item = self.dataset[idx]
-        img = cv2.imread(item['path'])
-        label = item['label']
-        if transform:
-            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
-            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
-            img, line_strings = self.transform(image=img, line_strings=line_strings)
-            line_strings.clip_out_of_image_()
-            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
-            new_anno['categories'] = item['categories']
-            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
-
-        img = img / 255.
-        if self.normalize:
-            img = (img - IMAGENET_MEAN) / IMAGENET_STD
-        img = self.to_tensor(img.astype(np.float32))
-        return (img, label, idx)
-
-    def __len__(self):
-        return len(self.dataset)
-
-
-def main():
-    import torch
-    from lib.config import Config
-    np.random.seed(0)
-    torch.manual_seed(0)
-    cfg = Config('config.yaml')
-    train_dataset = cfg.get_dataset('train')
-    for idx in range(len(train_dataset)):
-        img = train_dataset.draw_annotation(idx)
-        cv2.imshow('sample', img)
-        cv2.waitKey(0)
-
-
-if __name__ == "__main__":
-    main()
+import cv2
+import numpy as np
+import imgaug.augmenters as iaa
+from imgaug.augmenters import Resize
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+from imgaug.augmentables.lines import LineString, LineStringsOnImage
+
+from .elas import ELAS
+from .llamas import LLAMAS
+from .tusimple import TuSimple
+from .nolabel_dataset import NoLabelDataset
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+
+class LaneDataset(Dataset):
+    def __init__(self,
+                 dataset='tusimple',
+                 augmentations=None,
+                 normalize=False,
+                 split='train',
+                 img_size=(360, 640),
+                 aug_chance=1.,
+                 **kwargs):
+        super(LaneDataset, self).__init__()
+        if dataset == 'tusimple':
+            self.dataset = TuSimple(split=split, **kwargs)
+        elif dataset == 'llamas':
+            self.dataset = LLAMAS(split=split, **kwargs)
+        elif dataset == 'elas':
+            self.dataset = ELAS(split=split, **kwargs)
+        elif dataset == 'nolabel_dataset':
+            self.dataset = NoLabelDataset(**kwargs)
+        else:
+            raise NotImplementedError()
+
+        self.transform_annotations()
+        self.img_h, self.img_w = img_size
+
+        if augmentations is not None:
+            # add augmentations
+            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
+                             for aug in augmentations]  # add augmentation
+
+        self.normalize = normalize
+        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
+        self.to_tensor = ToTensor()
+        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
+        self.max_lanes = self.dataset.max_lanes
+
+    def transform_annotation(self, anno, img_wh=None):
+        if img_wh is None:
+            img_h = self.dataset.get_img_heigth(anno['path'])
+            img_w = self.dataset.get_img_width(anno['path'])
+        else:
+            img_w, img_h = img_wh
+
+        old_lanes = anno['lanes']
+        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
+        old_lanes = zip(old_lanes, categories)
+        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
+        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
+        lanes[:, 0] = 0
+        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
+        for lane_pos, (lane, category) in enumerate(old_lanes):
+            lower, upper = lane[0][1], lane[-1][1]
+            xs = np.array([p[0] for p in lane]) / img_w
+            ys = np.array([p[1] for p in lane]) / img_h
+            lanes[lane_pos, 0] = category
+            lanes[lane_pos, 1] = lower / img_h
+            lanes[lane_pos, 2] = upper / img_h
+            lanes[lane_pos, 3:3 + len(xs)] = xs
+            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
+
+        new_anno = {
+            'path': anno['path'],
+            'label': lanes,
+            'old_anno': anno,
+            'categories': [cat for _, cat in old_lanes]
+        }
+
+        return new_anno
+
+    @property
+    def annotations(self):
+        return self.dataset.annotations
+
+    def transform_annotations(self):
+        print('Transforming annotations...')
+        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
+        print('Done.')
+
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+        if img is None:
+            img, label, _ = self.__getitem__(idx, transform=True)
+            # Tensor to opencv image
+            img = img.permute(1, 2, 0).numpy()
+            # Unnormalize
+            if self.normalize:
+                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+            img = (img * 255).astype(np.uint8)
+        else:
+            _, label, _ = self.__getitem__(idx)
+
+        img_h, img_w, _ = img.shape
+
+        # Draw label
+        for i, lane in enumerate(label):
+            if lane[0] == 0:  # Skip invalid lanes
+                continue
+            lane = lane[3:]  # remove conf, upper and lower positions
+            xs = lane[:len(lane) // 2]
+            ys = lane[len(lane) // 2:]
+            ys = ys[xs >= 0]
+            xs = xs[xs >= 0]
+
+            # draw GT points
+            for p in zip(xs, ys):
+                p = (int(p[0] * img_w), int(p[1] * img_h))
+                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
+
+            # draw GT lane ID
+            cv2.putText(img,
+                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
+                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                        fontScale=1,
+                        color=(0, 255, 0))
+
+        if pred is None:
+            return img
+
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        matches, accs, _ = self.dataset.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+            if matches[i]:
+                color = PRED_HIT_COLOR
+            else:
+                color = PRED_MISS_COLOR
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(accs[i] * 100),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+    def lane_to_linestrings(self, lanes):
+        lines = []
+        for lane in lanes:
+            lines.append(LineString(lane))
+
+        return lines
+
+    def linestrings_to_lanes(self, lines):
+        lanes = []
+        for line in lines:
+            lanes.append(line.coords)
+
+        return lanes
+
+    def __getitem__(self, idx, transform=True):
+        item = self.dataset[idx]
+        img = cv2.imread(item['path'])
+        label = item['label']
+        if transform:
+            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
+            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
+            img, line_strings = self.transform(image=img, line_strings=line_strings)
+            line_strings.clip_out_of_image_()
+            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
+            new_anno['categories'] = item['categories']
+            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
+
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, label, idx)
+
+    def __len__(self):
+        return len(self.dataset)
+
+
+def main():
+    import torch
+    from lib.config import Config
+    np.random.seed(0)
+    torch.manual_seed(0)
+    cfg = Config('config.yaml')
+    train_dataset = cfg.get_dataset('train')
+    for idx in range(len(train_dataset)):
+        img = train_dataset.draw_annotation(idx)
+        cv2.imshow('sample', img)
+        cv2.waitKey(0)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/lib/datasets/llamas.py b/lib/datasets/llamas.py
index 595e17b..aba4654 100644
--- a/lib/datasets/llamas.py
+++ b/lib/datasets/llamas.py
@@ -1,451 +1,451 @@
-import os
-import json
-import pickle as pkl
-
-import numpy as np
-from progressbar import progressbar
-
-TRAIN_LABELS_DIR = 'labels/train'
-TEST_LABELS_DIR = 'labels/valid'
-SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
-
-
-class LLAMAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.split = split
-        self.root = root
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
-
-        self.img_w, self.img_h = 1276, 717
-        self.offset = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def get_img_path(self, json_path):
-        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
-        base_name = '/'.join(json_path.split('/')[-3:])
-        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
-        return image_path
-
-    def get_json_paths(self):
-        json_paths = []
-        for root, dirs, files in os.walk(self.labels_dir):
-            for file in files:
-                if file.endswith(".json"):
-                    json_paths.append(os.path.join(root, file))
-        return json_paths
-
-    def load_annotations(self):
-        # Waiting for the dataset to load is tedious, let's cache it
-        os.makedirs('cache', exist_ok=True)
-        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
-        if os.path.exists(cache_path):
-            with open(cache_path, 'rb') as cache_file:
-                self.annotations = pkl.load(cache_file)
-                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
-                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
-                return
-
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        print("Searching annotation files...")
-        json_paths = self.get_json_paths()
-        print('{} annotations found.'.format(len(json_paths)))
-
-        for json_path in progressbar(json_paths):
-            lanes = get_horizontal_values_for_four_lanes(json_path)
-            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
-            lanes = [lane for lane in lanes if len(lane) > 0]
-            relative_path = self.get_img_path(json_path)
-            img_path = os.path.join(self.root, relative_path)
-            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
-            self.max_lanes = max(self.max_lanes, len(lanes))
-            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
-
-        with open(cache_path, 'wb') as cache_file:
-            pkl.dump(self.annotations, cache_file)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
-
-
-# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
-# Its license is copied here
-
-# ##### Begin License ######
-# MIT License
-
-# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
-
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-
-# The above copyright notice and this permission notice shall be included in all
-# copies or substantial portions of the Software.
-
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# ##### End License ######
-
-# Start code under the previous license
-
-
-def _extend_lane(lane, projection_matrix):
-    """Extends marker closest to the camera
-
-    Adds an extra marker that reaches the end of the image
-
-    Parameters
-    ----------
-    lane : iterable of markers
-    projection_matrix : 3x3 projection matrix
-    """
-    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
-    # z is the orthongal distance to the car. It's good enough
-
-    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
-    # e.g., horizontal markers which need to be filtered
-    filtered_markers = filter(
-        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
-        lane['markers'])
-    # might be the first marker in the list but not guaranteed
-    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
-
-    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
-        return lane
-
-    # World marker extension approximation
-    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-
-    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
-    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
-
-    # Pixel marker extension approximation
-    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
-        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
-    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
-        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
-
-    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
-    if pixel_zero_x < 0:
-        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
-        new_pixel_point = (0, left_y)
-    elif pixel_zero_x > 1276:
-        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
-        new_pixel_point = (1276, right_y)
-    else:
-        new_pixel_point = (pixel_zero_x, 716)
-
-    new_marker = {
-        'lane_marker_id': 'FAKE',
-        'world_end': {
-            'x': closest_marker['world_start']['x'],
-            'y': closest_marker['world_start']['y'],
-            'z': closest_marker['world_start']['z']
-        },
-        'world_start': {
-            'x': zero_x,
-            'y': zero_y,
-            'z': 1
-        },
-        'pixel_end': {
-            'x': closest_marker['pixel_start']['x'],
-            'y': closest_marker['pixel_start']['y']
-        },
-        'pixel_start': {
-            'x': ir(new_pixel_point[0]),
-            'y': ir(new_pixel_point[1])
-        }
-    }
-    lane['markers'].insert(0, new_marker)
-
-    return lane
-
-
-class SplineCreator():
-    """
-    For each lane divder
-      - all lines are projected
-      - linearly interpolated to limit oscillations
-      - interpolated by a spline
-      - subsampled to receive individual pixel values
-
-    The spline creation can be optimized!
-      - Better spline parameters
-      - Extend lowest marker to reach bottom of image would also help
-      - Extending last marker may in some cases be interesting too
-    Any help is welcome.
-
-    Call create_all_points and get the points in self.sampled_points
-    It has an x coordinate for each value for each lane
-
-    """
-    def __init__(self, json_path):
-        self.json_path = json_path
-        self.json_content = read_json(json_path)
-        self.lanes = self.json_content['lanes']
-        self.lane_marker_points = {}
-        self.sampled_points = {}  # <--- the interesting part
-        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
-
-    def _sample_points(self, lane, ypp=5, between_markers=True):
-        """ Markers are given by start and endpoint. This one adds extra points
-        which need to be considered for the interpolation. Otherwise the spline
-        could arbitrarily oscillate between start and end of the individual markers
-
-        Parameters
-        ----------
-        lane: polyline, in theory but there are artifacts which lead to inconsistencies
-              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
-        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
-        between_markers : bool, interpolates inbetween dashes
-
-        Notes
-        -----
-        Especially, adding points in the lower parts of the image (high y-values) because
-        the start and end points are too sparse.
-        Removing upper lane markers that have starting and end points mapped into the same pixel.
-        """
-
-        # Collect all x values from all markers along a given line. There may be multiple
-        # intersecting markers, i.e., multiple entries for some y values
-        x_values = [[] for i in range(717)]
-        for marker in lane['markers']:
-            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
-
-            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
-            if height > 2:
-                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
-                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
-                for i in range(height + 1):
-                    x = marker['pixel_start']['x'] + slope * step_size * i
-                    y = marker['pixel_start']['y'] - step_size * i
-                    x_values[ir(y)].append(ir(x))
-
-        # Calculate average x values for each y value
-        for y, xs in enumerate(x_values):
-            if not xs:
-                x_values[y] = -1
-            else:
-                x_values[y] = sum(xs) / float(len(xs))
-
-        # In the following, we will only interpolate between markers if needed
-        if not between_markers:
-            return x_values  # TODO ypp
-
-        # # interpolate between markers
-        current_y = 0
-        while x_values[current_y] == -1:  # skip missing first entries
-            current_y += 1
-
-        # Also possible using numpy.interp when accounting for beginning and end
-        next_set_y = 0
-        try:
-            while current_y < 717:
-                if x_values[current_y] != -1:  # set. Nothing to be done
-                    current_y += 1
-                    continue
-
-                # Finds target x value for interpolation
-                while next_set_y <= current_y or x_values[next_set_y] == -1:
-                    next_set_y += 1
-                    if next_set_y >= 717:
-                        raise StopIteration
-
-                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
-                    (next_set_y - current_y + 1)
-                current_y += 1
-
-        except StopIteration:
-            pass  # Done with lane
-
-        return x_values
-
-    def _lane_points_fit(self, lane):
-        # TODO name and docstring
-        """ Fits spline in image space for the markers of a single lane (side)
-
-        Parameters
-        ----------
-        lane: dict as specified in label
-
-        Returns
-        -------
-        Pixel level values for curve along the y-axis
-
-        Notes
-        -----
-        This one can be drastically improved. Probably fairly easy as well.
-        """
-        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
-        lane = _extend_lane(lane, self.json_content['projection_matrix'])
-        sampled_points = self._sample_points(lane, ypp=1)
-        self.sampled_points[lane['lane_id']] = sampled_points
-
-        return sampled_points
-
-    def create_all_points(self, ):
-        """ Creates splines for given label """
-        for lane in self.lanes:
-            self._lane_points_fit(lane)
-
-
-def get_horizontal_values_for_four_lanes(json_path):
-    """ Gets an x value for every y coordinate for l1, l0, r0, r1
-
-    This allows to easily train a direct curve approximation. For each value along
-    the y-axis, the respective x-values can be compared, e.g. squared distance.
-    Missing values are filled with -1. Missing values are values missing from the spline.
-    There is no extrapolation to the image start/end (yet).
-    But values are interpolated between markers. Space between dashed markers is not missing.
-
-    Parameters
-    ----------
-    json_path: str
-               path to label-file
-
-    Returns
-    -------
-    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
-    the number of vertical pixels of the image
-
-    Notes
-    -----
-    The points are currently based on the splines. The splines are interpolated based on the
-    segmentation values. The spline interpolation has lots of room for improvement, e.g.
-    the lines could be interpolated in 3D, a better approach to spline interpolation could
-    be used, there is barely any error checking, sometimes the splines oscillate too much.
-    This was used for a quick poly-line regression training only.
-    """
-
-    sc = SplineCreator(json_path)
-    sc.create_all_points()
-
-    l1 = sc.sampled_points.get('l1', [-1] * 717)
-    l0 = sc.sampled_points.get('l0', [-1] * 717)
-    r0 = sc.sampled_points.get('r0', [-1] * 717)
-    r1 = sc.sampled_points.get('r1', [-1] * 717)
-
-    lanes = [l1, l0, r0, r1]
-    return lanes
-
-
-def _filter_lanes_by_size(label, min_height=40):
-    """ May need some tuning """
-    filtered_lanes = []
-    for lane in label['lanes']:
-        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        if (lane_end - lane_start) < min_height:
-            continue
-        filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _filter_few_markers(label, min_markers=2):
-    """Filter lines that consist of only few markers"""
-    filtered_lanes = []
-    for lane in label['lanes']:
-        if len(lane['markers']) >= min_markers:
-            filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _fix_lane_names(label):
-    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
-
-    # Create mapping
-    l_counter = 0
-    r_counter = 0
-    mapping = {}
-    lane_ids = [lane['lane_id'] for lane in label['lanes']]
-    for key in sorted(lane_ids):
-        if key[0] == 'l':
-            mapping[key] = 'l' + str(l_counter)
-            l_counter += 1
-        if key[0] == 'r':
-            mapping[key] = 'r' + str(r_counter)
-            r_counter += 1
-    for lane in label['lanes']:
-        lane['lane_id'] = mapping[lane['lane_id']]
-
-
-def read_json(json_path, min_lane_height=20):
-    """ Reads and cleans label file information by path"""
-    with open(json_path, 'r') as jf:
-        label_content = json.load(jf)
-
-    _filter_lanes_by_size(label_content, min_height=min_lane_height)
-    _filter_few_markers(label_content, min_markers=2)
-    _fix_lane_names(label_content)
-
-    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
-
-    for lane in content['lanes']:
-        for marker in lane['markers']:
-            for pixel_key in marker['pixel_start'].keys():
-                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
-            for pixel_key in marker['pixel_end'].keys():
-                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
-            for pixel_key in marker['world_start'].keys():
-                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
-            for pixel_key in marker['world_end'].keys():
-                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
-    return content
-
-
-def ir(some_value):
-    """ Rounds and casts to int
-    Useful for pixel values that cannot be floats
-    Parameters
-    ----------
-    some_value : float
-                 numeric value
-    Returns
-    --------
-    Rounded integer
-    Raises
-    ------
-    ValueError for non scalar types
-    """
-    return int(round(some_value))
-
-
-# End code under the previous license
+import os
+import json
+import pickle as pkl
+
+import numpy as np
+from progressbar import progressbar
+
+TRAIN_LABELS_DIR = 'labels/train'
+TEST_LABELS_DIR = 'labels/valid'
+SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
+
+
+class LLAMAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.split = split
+        self.root = root
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
+
+        self.img_w, self.img_h = 1276, 717
+        self.offset = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def get_img_path(self, json_path):
+        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
+        base_name = '/'.join(json_path.split('/')[-3:])
+        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
+        return image_path
+
+    def get_json_paths(self):
+        json_paths = []
+        for root, dirs, files in os.walk(self.labels_dir):
+            for file in files:
+                if file.endswith(".json"):
+                    json_paths.append(os.path.join(root, file))
+        return json_paths
+
+    def load_annotations(self):
+        # Waiting for the dataset to load is tedious, let's cache it
+        os.makedirs('cache', exist_ok=True)
+        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
+        if os.path.exists(cache_path):
+            with open(cache_path, 'rb') as cache_file:
+                self.annotations = pkl.load(cache_file)
+                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
+                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
+                return
+
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        print("Searching annotation files...")
+        json_paths = self.get_json_paths()
+        print('{} annotations found.'.format(len(json_paths)))
+
+        for json_path in progressbar(json_paths):
+            lanes = get_horizontal_values_for_four_lanes(json_path)
+            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
+            lanes = [lane for lane in lanes if len(lane) > 0]
+            relative_path = self.get_img_path(json_path)
+            img_path = os.path.join(self.root, relative_path)
+            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
+            self.max_lanes = max(self.max_lanes, len(lanes))
+            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
+
+        with open(cache_path, 'wb') as cache_file:
+            pkl.dump(self.annotations, cache_file)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
+
+
+# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
+# Its license is copied here
+
+# ##### Begin License ######
+# MIT License
+
+# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# ##### End License ######
+
+# Start code under the previous license
+
+
+def _extend_lane(lane, projection_matrix):
+    """Extends marker closest to the camera
+
+    Adds an extra marker that reaches the end of the image
+
+    Parameters
+    ----------
+    lane : iterable of markers
+    projection_matrix : 3x3 projection matrix
+    """
+    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
+    # z is the orthongal distance to the car. It's good enough
+
+    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
+    # e.g., horizontal markers which need to be filtered
+    filtered_markers = filter(
+        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
+        lane['markers'])
+    # might be the first marker in the list but not guaranteed
+    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
+
+    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
+        return lane
+
+    # World marker extension approximation
+    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+
+    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
+    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
+
+    # Pixel marker extension approximation
+    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
+        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
+    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
+        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
+
+    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
+    if pixel_zero_x < 0:
+        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
+        new_pixel_point = (0, left_y)
+    elif pixel_zero_x > 1276:
+        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
+        new_pixel_point = (1276, right_y)
+    else:
+        new_pixel_point = (pixel_zero_x, 716)
+
+    new_marker = {
+        'lane_marker_id': 'FAKE',
+        'world_end': {
+            'x': closest_marker['world_start']['x'],
+            'y': closest_marker['world_start']['y'],
+            'z': closest_marker['world_start']['z']
+        },
+        'world_start': {
+            'x': zero_x,
+            'y': zero_y,
+            'z': 1
+        },
+        'pixel_end': {
+            'x': closest_marker['pixel_start']['x'],
+            'y': closest_marker['pixel_start']['y']
+        },
+        'pixel_start': {
+            'x': ir(new_pixel_point[0]),
+            'y': ir(new_pixel_point[1])
+        }
+    }
+    lane['markers'].insert(0, new_marker)
+
+    return lane
+
+
+class SplineCreator():
+    """
+    For each lane divder
+      - all lines are projected
+      - linearly interpolated to limit oscillations
+      - interpolated by a spline
+      - subsampled to receive individual pixel values
+
+    The spline creation can be optimized!
+      - Better spline parameters
+      - Extend lowest marker to reach bottom of image would also help
+      - Extending last marker may in some cases be interesting too
+    Any help is welcome.
+
+    Call create_all_points and get the points in self.sampled_points
+    It has an x coordinate for each value for each lane
+
+    """
+    def __init__(self, json_path):
+        self.json_path = json_path
+        self.json_content = read_json(json_path)
+        self.lanes = self.json_content['lanes']
+        self.lane_marker_points = {}
+        self.sampled_points = {}  # <--- the interesting part
+        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
+
+    def _sample_points(self, lane, ypp=5, between_markers=True):
+        """ Markers are given by start and endpoint. This one adds extra points
+        which need to be considered for the interpolation. Otherwise the spline
+        could arbitrarily oscillate between start and end of the individual markers
+
+        Parameters
+        ----------
+        lane: polyline, in theory but there are artifacts which lead to inconsistencies
+              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
+        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
+        between_markers : bool, interpolates inbetween dashes
+
+        Notes
+        -----
+        Especially, adding points in the lower parts of the image (high y-values) because
+        the start and end points are too sparse.
+        Removing upper lane markers that have starting and end points mapped into the same pixel.
+        """
+
+        # Collect all x values from all markers along a given line. There may be multiple
+        # intersecting markers, i.e., multiple entries for some y values
+        x_values = [[] for i in range(717)]
+        for marker in lane['markers']:
+            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
+
+            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
+            if height > 2:
+                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
+                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
+                for i in range(height + 1):
+                    x = marker['pixel_start']['x'] + slope * step_size * i
+                    y = marker['pixel_start']['y'] - step_size * i
+                    x_values[ir(y)].append(ir(x))
+
+        # Calculate average x values for each y value
+        for y, xs in enumerate(x_values):
+            if not xs:
+                x_values[y] = -1
+            else:
+                x_values[y] = sum(xs) / float(len(xs))
+
+        # In the following, we will only interpolate between markers if needed
+        if not between_markers:
+            return x_values  # TODO ypp
+
+        # # interpolate between markers
+        current_y = 0
+        while x_values[current_y] == -1:  # skip missing first entries
+            current_y += 1
+
+        # Also possible using numpy.interp when accounting for beginning and end
+        next_set_y = 0
+        try:
+            while current_y < 717:
+                if x_values[current_y] != -1:  # set. Nothing to be done
+                    current_y += 1
+                    continue
+
+                # Finds target x value for interpolation
+                while next_set_y <= current_y or x_values[next_set_y] == -1:
+                    next_set_y += 1
+                    if next_set_y >= 717:
+                        raise StopIteration
+
+                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
+                    (next_set_y - current_y + 1)
+                current_y += 1
+
+        except StopIteration:
+            pass  # Done with lane
+
+        return x_values
+
+    def _lane_points_fit(self, lane):
+        # TODO name and docstring
+        """ Fits spline in image space for the markers of a single lane (side)
+
+        Parameters
+        ----------
+        lane: dict as specified in label
+
+        Returns
+        -------
+        Pixel level values for curve along the y-axis
+
+        Notes
+        -----
+        This one can be drastically improved. Probably fairly easy as well.
+        """
+        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
+        lane = _extend_lane(lane, self.json_content['projection_matrix'])
+        sampled_points = self._sample_points(lane, ypp=1)
+        self.sampled_points[lane['lane_id']] = sampled_points
+
+        return sampled_points
+
+    def create_all_points(self, ):
+        """ Creates splines for given label """
+        for lane in self.lanes:
+            self._lane_points_fit(lane)
+
+
+def get_horizontal_values_for_four_lanes(json_path):
+    """ Gets an x value for every y coordinate for l1, l0, r0, r1
+
+    This allows to easily train a direct curve approximation. For each value along
+    the y-axis, the respective x-values can be compared, e.g. squared distance.
+    Missing values are filled with -1. Missing values are values missing from the spline.
+    There is no extrapolation to the image start/end (yet).
+    But values are interpolated between markers. Space between dashed markers is not missing.
+
+    Parameters
+    ----------
+    json_path: str
+               path to label-file
+
+    Returns
+    -------
+    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
+    the number of vertical pixels of the image
+
+    Notes
+    -----
+    The points are currently based on the splines. The splines are interpolated based on the
+    segmentation values. The spline interpolation has lots of room for improvement, e.g.
+    the lines could be interpolated in 3D, a better approach to spline interpolation could
+    be used, there is barely any error checking, sometimes the splines oscillate too much.
+    This was used for a quick poly-line regression training only.
+    """
+
+    sc = SplineCreator(json_path)
+    sc.create_all_points()
+
+    l1 = sc.sampled_points.get('l1', [-1] * 717)
+    l0 = sc.sampled_points.get('l0', [-1] * 717)
+    r0 = sc.sampled_points.get('r0', [-1] * 717)
+    r1 = sc.sampled_points.get('r1', [-1] * 717)
+
+    lanes = [l1, l0, r0, r1]
+    return lanes
+
+
+def _filter_lanes_by_size(label, min_height=40):
+    """ May need some tuning """
+    filtered_lanes = []
+    for lane in label['lanes']:
+        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        if (lane_end - lane_start) < min_height:
+            continue
+        filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _filter_few_markers(label, min_markers=2):
+    """Filter lines that consist of only few markers"""
+    filtered_lanes = []
+    for lane in label['lanes']:
+        if len(lane['markers']) >= min_markers:
+            filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _fix_lane_names(label):
+    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
+
+    # Create mapping
+    l_counter = 0
+    r_counter = 0
+    mapping = {}
+    lane_ids = [lane['lane_id'] for lane in label['lanes']]
+    for key in sorted(lane_ids):
+        if key[0] == 'l':
+            mapping[key] = 'l' + str(l_counter)
+            l_counter += 1
+        if key[0] == 'r':
+            mapping[key] = 'r' + str(r_counter)
+            r_counter += 1
+    for lane in label['lanes']:
+        lane['lane_id'] = mapping[lane['lane_id']]
+
+
+def read_json(json_path, min_lane_height=20):
+    """ Reads and cleans label file information by path"""
+    with open(json_path, 'r') as jf:
+        label_content = json.load(jf)
+
+    _filter_lanes_by_size(label_content, min_height=min_lane_height)
+    _filter_few_markers(label_content, min_markers=2)
+    _fix_lane_names(label_content)
+
+    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
+
+    for lane in content['lanes']:
+        for marker in lane['markers']:
+            for pixel_key in marker['pixel_start'].keys():
+                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
+            for pixel_key in marker['pixel_end'].keys():
+                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
+            for pixel_key in marker['world_start'].keys():
+                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
+            for pixel_key in marker['world_end'].keys():
+                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
+    return content
+
+
+def ir(some_value):
+    """ Rounds and casts to int
+    Useful for pixel values that cannot be floats
+    Parameters
+    ----------
+    some_value : float
+                 numeric value
+    Returns
+    --------
+    Rounded integer
+    Raises
+    ------
+    ValueError for non scalar types
+    """
+    return int(round(some_value))
+
+
+# End code under the previous license
diff --git a/lib/datasets/nolabel_dataset.py b/lib/datasets/nolabel_dataset.py
index c8af627..1b3705b 100644
--- a/lib/datasets/nolabel_dataset.py
+++ b/lib/datasets/nolabel_dataset.py
@@ -1,44 +1,44 @@
-import glob
-
-import numpy as np
-
-
-class NoLabelDataset(object):
-    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
-        self.root = root
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = img_w, img_h
-        self.img_ext = img_ext
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        # On NoLabelDataset, always force it
-        self.max_lanes = max_lanes
-        self.max_points = 1
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def load_annotations(self):
-        self.annotations = []
-        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
-        print('Looking for image files with the pattern', pattern)
-        for file in glob.glob(pattern, recursive=True):
-            self.annotations.append({'lanes': [], 'path': file})
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import glob
+
+import numpy as np
+
+
+class NoLabelDataset(object):
+    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
+        self.root = root
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = img_w, img_h
+        self.img_ext = img_ext
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        # On NoLabelDataset, always force it
+        self.max_lanes = max_lanes
+        self.max_points = 1
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def load_annotations(self):
+        self.annotations = []
+        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
+        print('Looking for image files with the pattern', pattern)
+        for file in glob.glob(pattern, recursive=True):
+            self.annotations.append({'lanes': [], 'path': file})
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..55690dc 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -1,137 +1,137 @@
-import os
-import json
-import random
-
-import numpy as np
-from tabulate import tabulate
-
-from utils.lane import LaneEval
-from utils.metric import eval_json
-
-SPLIT_FILES = {
-    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
-    'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
-    'test': ['test_label.json'],
-}
-
-
-class TuSimple(object):
-    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
-        self.split = split
-        self.root = root
-        self.metric = metric
-
-        if split not in SPLIT_FILES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
-
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = 1280, 720
-        self.max_points = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return 720
-
-    def get_img_width(self, path):
-        return 1280
-
-    def get_metrics(self, lanes, idx):
-        label = self.annotations[idx]
-        org_anno = label['old_anno']
-        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
-        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
-
-        return matches, accs, dist
-
-    def pred2lanes(self, path, pred, y_samples):
-        ys = np.array(y_samples) / self.img_h
-        lanes = []
-        for lane in pred:
-            if lane[0] == 0:
-                continue
-            lane_pred = np.polyval(lane[3:], ys) * self.img_w
-            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
-            lanes.append(list(lane_pred))
-
-        return lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        max_lanes = 0
-        for anno_file in self.anno_files:
-            with open(anno_file, 'r') as anno_obj:
-                lines = anno_obj.readlines()
-            for line in lines:
-                data = json.loads(line)
-                y_samples = data['h_samples']
-                gt_lanes = data['lanes']
-                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
-                lanes = [lane for lane in lanes if len(lane) > 0]
-                max_lanes = max(max_lanes, len(lanes))
-                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
-                self.annotations.append({
-                    'path': os.path.join(self.root, data['raw_file']),
-                    'org_path': data['raw_file'],
-                    'org_lanes': gt_lanes,
-                    'lanes': lanes,
-                    'aug': False,
-                    'y_samples': y_samples
-                })
-
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-        print('total annos', len(self.annotations))
-        self.max_lanes = max_lanes
-
-    def transform_annotations(self, transform):
-        self.annotations = list(map(transform, self.annotations))
-
-    def pred2tusimpleformat(self, idx, pred, runtime):
-        runtime *= 1000.  # s to ms
-        img_name = self.annotations[idx]['old_anno']['org_path']
-        h_samples = self.annotations[idx]['old_anno']['y_samples']
-        lanes = self.pred2lanes(img_name, pred, h_samples)
-        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
-        return json.dumps(output)
-
-    def save_tusimple_predictions(self, predictions, runtimes, filename):
-        lines = []
-        for idx in range(len(predictions)):
-            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
-            lines.append(line)
-        with open(filename, 'w') as output_file:
-            output_file.write('\n'.join(lines))
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
-        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
-        if self.metric == 'default':
-            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
-        elif self.metric == 'ours':
-            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
-        table = {}
-        for metric in result:
-            table[metric['name']] = [metric['value']]
-        table = tabulate(table, headers='keys')
-
-        if not only_metrics:
-            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
-            with open(os.path.join(exp_dir, filename), 'w') as out_file:
-                json.dump(result, out_file)
-
-        return table, result
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import json
+import random
+
+import numpy as np
+from tabulate import tabulate
+
+from utils.lane import LaneEval
+from utils.metric import eval_json
+
+SPLIT_FILES = {
+    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
+    'train': ['label_data_0313.json', 'label_data_0601.json'],
+    'val': ['test_label.json'],
+    'test': ['test_label.json'],
+}
+
+
+class TuSimple(object):
+    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
+        self.split = split
+        self.root = root
+        self.metric = metric
+
+        if split not in SPLIT_FILES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
+
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = 1280, 720
+        self.max_points = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return 720
+
+    def get_img_width(self, path):
+        return 1280
+
+    def get_metrics(self, lanes, idx):
+        label = self.annotations[idx]
+        org_anno = label['old_anno']
+        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
+        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
+
+        return matches, accs, dist
+
+    def pred2lanes(self, path, pred, y_samples):
+        ys = np.array(y_samples) / self.img_h
+        lanes = []
+        for lane in pred:
+            if lane[0] == 0:
+                continue
+            lane_pred = np.polyval(lane[3:], ys) * self.img_w
+            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
+            lanes.append(list(lane_pred))
+
+        return lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        max_lanes = 0
+        for anno_file in self.anno_files:
+            with open(anno_file, 'r') as anno_obj:
+                lines = anno_obj.readlines()
+            for line in lines:
+                data = json.loads(line)
+                y_samples = data['h_samples']
+                gt_lanes = data['lanes']
+                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
+                lanes = [lane for lane in lanes if len(lane) > 0]
+                max_lanes = max(max_lanes, len(lanes))
+                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
+                self.annotations.append({
+                    'path': os.path.join(self.root, data['raw_file']),
+                    'org_path': data['raw_file'],
+                    'org_lanes': gt_lanes,
+                    'lanes': lanes,
+                    'aug': False,
+                    'y_samples': y_samples
+                })
+
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+        print('total annos', len(self.annotations))
+        self.max_lanes = max_lanes
+
+    def transform_annotations(self, transform):
+        self.annotations = list(map(transform, self.annotations))
+
+    def pred2tusimpleformat(self, idx, pred, runtime):
+        runtime *= 1000.  # s to ms
+        img_name = self.annotations[idx]['old_anno']['org_path']
+        h_samples = self.annotations[idx]['old_anno']['y_samples']
+        lanes = self.pred2lanes(img_name, pred, h_samples)
+        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
+        return json.dumps(output)
+
+    def save_tusimple_predictions(self, predictions, runtimes, filename):
+        lines = []
+        for idx in range(len(predictions)):
+            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
+            lines.append(line)
+        with open(filename, 'w') as output_file:
+            output_file.write('\n'.join(lines))
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
+        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
+        if self.metric == 'default':
+            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
+        elif self.metric == 'ours':
+            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
+        table = {}
+        for metric in result:
+            table[metric['name']] = [metric['value']]
+        table = tabulate(table, headers='keys')
+
+        if not only_metrics:
+            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
+            with open(os.path.join(exp_dir, filename), 'w') as out_file:
+                json.dump(result, out_file)
+
+        return table, result
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/models.py b/lib/models.py
index 15eb117..ad6e599 100644
--- a/lib/models.py
+++ b/lib/models.py
@@ -1,160 +1,160 @@
-import torch
-import torch.nn as nn
-from torchvision.models import resnet34, resnet50, resnet101
-from efficientnet_pytorch import EfficientNet
-
-
-class OutputLayer(nn.Module):
-    def __init__(self, fc, num_extra):
-        super(OutputLayer, self).__init__()
-        self.regular_outputs_layer = fc
-        self.num_extra = num_extra
-        if num_extra > 0:
-            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
-
-    def forward(self, x):
-        regular_outputs = self.regular_outputs_layer(x)
-        if self.num_extra > 0:
-            extra_outputs = self.extra_outputs_layer(x)
-        else:
-            extra_outputs = None
-
-        return regular_outputs, extra_outputs
-
-
-class PolyRegression(nn.Module):
-    def __init__(self,
-                 num_outputs,
-                 backbone,
-                 pretrained,
-                 curriculum_steps=None,
-                 extra_outputs=0,
-                 share_top_y=True,
-                 pred_category=False):
-        super(PolyRegression, self).__init__()
-        if 'efficientnet' in backbone:
-            if pretrained:
-                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
-            else:
-                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
-            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
-        elif backbone == 'resnet34':
-            self.model = resnet34(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet50':
-            self.model = resnet50(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet101':
-            self.model = resnet101(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        else:
-            raise NotImplementedError()
-
-        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
-        self.share_top_y = share_top_y
-        self.extra_outputs = extra_outputs
-        self.pred_category = pred_category
-        self.sigmoid = nn.Sigmoid()
-
-    def forward(self, x, epoch=None, **kwargs):
-        output, extra_outputs = self.model(x, **kwargs)
-        for i in range(len(self.curriculum_steps)):
-            if epoch is not None and epoch < self.curriculum_steps[i]:
-                output[:, -len(self.curriculum_steps) + i] = 0
-        return output, extra_outputs
-
-    def decode(self, all_outputs, labels, conf_threshold=0.5):
-        outputs, extra_outputs = all_outputs
-        if extra_outputs is not None:
-            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
-            extra_outputs = extra_outputs.argmax(dim=2)
-        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
-        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
-        outputs[outputs[:, :, 0] < conf_threshold] = 0
-
-        if False and self.share_top_y:
-            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
-
-        return outputs, extra_outputs
-
-    def loss(self,
-             outputs,
-             target,
-             conf_weight=1,
-             lower_weight=1,
-             upper_weight=1,
-             cls_weight=1,
-             poly_weight=300,
-             threshold=15 / 720.):
-        pred, extra_outputs = outputs
-        bce = nn.BCELoss()
-        mse = nn.MSELoss()
-        s = nn.Sigmoid()
-        threshold = nn.Threshold(threshold**2, 0.)
-        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
-        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
-        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
-        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
-        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
-
-        if self.share_top_y:
-            # inexistent lanes have -1e-5 as lower
-            # i'm just setting it to a high value here so that the .min below works fine
-            target_lowers[target_lowers < 0] = 1
-            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
-            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
-
-        target_lowers = target_lowers.reshape((-1, 1))
-        pred_lowers = pred_lowers.reshape((-1, 1))
-
-        target_confs = (target_categories > 0).float()
-        valid_lanes_idx = target_confs == 1
-        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
-        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
-        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
-
-        # classification loss
-        if self.pred_category and self.extra_outputs > 0:
-            ce = nn.CrossEntropyLoss()
-            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
-            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
-            pred_categories = pred_categories[target_categories > 0]
-            target_categories = target_categories[target_categories > 0]
-            cls_loss = ce(pred_categories, target_categories - 1)
-        else:
-            cls_loss = 0
-
-        # poly loss calc
-        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
-        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
-        valid_xs = target_xs >= 0
-        pred_polys = pred_polys[valid_lanes_idx_flat]
-        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
-        pred_xs.t_()
-        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
-        pred_xs = (pred_xs.t_() *
-                   weights).t()  # without this, lanes with more points would have more weight on the cost function
-        target_xs = (target_xs.t_() * weights).t()
-        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
-        poly_loss = threshold(
-            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
-
-        # applying weights to partial losses
-        poly_loss = poly_loss * poly_weight
-        lower_loss = lower_loss * lower_weight
-        upper_loss = upper_loss * upper_weight
-        cls_loss = cls_loss * cls_weight
-        conf_loss = bce(pred_confs, target_confs) * conf_weight
-
-        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
-
-        return loss, {
-            'conf': conf_loss,
-            'lower': lower_loss,
-            'upper': upper_loss,
-            'poly': poly_loss,
-            'cls_loss': cls_loss
-        }
+import torch
+import torch.nn as nn
+from torchvision.models import resnet34, resnet50, resnet101
+from efficientnet_pytorch import EfficientNet
+
+
+class OutputLayer(nn.Module):
+    def __init__(self, fc, num_extra):
+        super(OutputLayer, self).__init__()
+        self.regular_outputs_layer = fc
+        self.num_extra = num_extra
+        if num_extra > 0:
+            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
+
+    def forward(self, x):
+        regular_outputs = self.regular_outputs_layer(x)
+        if self.num_extra > 0:
+            extra_outputs = self.extra_outputs_layer(x)
+        else:
+            extra_outputs = None
+
+        return regular_outputs, extra_outputs
+
+
+class PolyRegression(nn.Module):
+    def __init__(self,
+                 num_outputs,
+                 backbone,
+                 pretrained,
+                 curriculum_steps=None,
+                 extra_outputs=0,
+                 share_top_y=True,
+                 pred_category=False):
+        super(PolyRegression, self).__init__()
+        if 'efficientnet' in backbone:
+            if pretrained:
+                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
+            else:
+                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
+            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
+        elif backbone == 'resnet34':
+            self.model = resnet34(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet50':
+            self.model = resnet50(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet101':
+            self.model = resnet101(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        else:
+            raise NotImplementedError()
+
+        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
+        self.share_top_y = share_top_y
+        self.extra_outputs = extra_outputs
+        self.pred_category = pred_category
+        self.sigmoid = nn.Sigmoid()
+
+    def forward(self, x, epoch=None, **kwargs):
+        output, extra_outputs = self.model(x, **kwargs)
+        for i in range(len(self.curriculum_steps)):
+            if epoch is not None and epoch < self.curriculum_steps[i]:
+                output[:, -len(self.curriculum_steps) + i] = 0
+        return output, extra_outputs
+
+    def decode(self, all_outputs, labels, conf_threshold=0.5):
+        outputs, extra_outputs = all_outputs
+        if extra_outputs is not None:
+            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
+            extra_outputs = extra_outputs.argmax(dim=2)
+        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
+        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
+        outputs[outputs[:, :, 0] < conf_threshold] = 0
+
+        if False and self.share_top_y:
+            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
+
+        return outputs, extra_outputs
+
+    def loss(self,
+             outputs,
+             target,
+             conf_weight=1,
+             lower_weight=1,
+             upper_weight=1,
+             cls_weight=1,
+             poly_weight=300,
+             threshold=15 / 720.):
+        pred, extra_outputs = outputs
+        bce = nn.BCELoss()
+        mse = nn.MSELoss()
+        s = nn.Sigmoid()
+        threshold = nn.Threshold(threshold**2, 0.)
+        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
+        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
+        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
+        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
+        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
+
+        if self.share_top_y:
+            # inexistent lanes have -1e-5 as lower
+            # i'm just setting it to a high value here so that the .min below works fine
+            target_lowers[target_lowers < 0] = 1
+            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
+            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
+
+        target_lowers = target_lowers.reshape((-1, 1))
+        pred_lowers = pred_lowers.reshape((-1, 1))
+
+        target_confs = (target_categories > 0).float()
+        valid_lanes_idx = target_confs == 1
+        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
+        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
+        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
+
+        # classification loss
+        if self.pred_category and self.extra_outputs > 0:
+            ce = nn.CrossEntropyLoss()
+            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
+            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
+            pred_categories = pred_categories[target_categories > 0]
+            target_categories = target_categories[target_categories > 0]
+            cls_loss = ce(pred_categories, target_categories - 1)
+        else:
+            cls_loss = 0
+
+        # poly loss calc
+        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
+        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
+        valid_xs = target_xs >= 0
+        pred_polys = pred_polys[valid_lanes_idx_flat]
+        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
+        pred_xs.t_()
+        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
+        pred_xs = (pred_xs.t_() *
+                   weights).t()  # without this, lanes with more points would have more weight on the cost function
+        target_xs = (target_xs.t_() * weights).t()
+        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
+        poly_loss = threshold(
+            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
+
+        # applying weights to partial losses
+        poly_loss = poly_loss * poly_weight
+        lower_loss = lower_loss * lower_weight
+        upper_loss = upper_loss * upper_weight
+        cls_loss = cls_loss * cls_weight
+        conf_loss = bce(pred_confs, target_confs) * conf_weight
+
+        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
+
+        return loss, {
+            'conf': conf_loss,
+            'lower': lower_loss,
+            'upper': upper_loss,
+            'poly': poly_loss,
+            'cls_loss': cls_loss
+        }
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..3ba5b3a 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,16 +1,15 @@
-lxml==4.6.2
-torchvision==0.5.0
-xmljson==0.2.0
-scipy==1.4.1
-tabulate==0.8.6
-numpy==1.18.1
-ujson==1.35
-matplotlib==3.1.3
-imgaug==0.4.0
-tqdm==4.43.0
-opencv_python==4.2.0.32
-efficientnet_pytorch==0.6.3
-torch==1.4.0
-progressbar33==2.4
-PyYAML==5.3.1
-scikit-learn==0.21.3
+lxml==4.6.2
+torchvision==0.5.0
+xmljson==0.2.0
+scipy==1.4.1
+tabulate==0.8.6
+numpy==1.18.1
+ujson==1.35
+matplotlib==3.1.3
+imgaug==0.4.0
+tqdm==4.43.0
+opencv_python==4.2.0.32
+efficientnet_pytorch==0.6.3
+progressbar33==2.4
+PyYAML==5.3.1
+scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..ed3e216 100644
--- a/test.py
+++ b/test.py
@@ -1,166 +1,166 @@
-import os
-import sys
-import random
-import logging
-import argparse
-import subprocess
-from time import time
-
-import cv2
-import numpy as np
-import torch
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
-    if verbose:
-        logging.info("Starting testing.")
-
-    # Test the model
-    if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
-
-    model.eval()
-    criterion_parameters = cfg.get_loss_parameters()
-    test_parameters = cfg.get_test_parameters()
-    criterion = model.loss
-    loss = 0
-    total_iters = 0
-    test_t0 = time()
-    loss_dict = {}
-    with torch.no_grad():
-        for idx, (images, labels, img_idxs) in enumerate(test_loader):
-            if max_batches is not None and idx >= max_batches:
-                break
-            if idx % 1 == 0 and verbose:
-                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
-            images = images.to(device)
-            labels = labels.to(device)
-
-            t0 = time()
-            outputs = model(images)
-            t = time() - t0
-            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            loss += loss_i.item()
-            total_iters += 1
-            for key in loss_dict_i:
-                if key not in loss_dict:
-                    loss_dict[key] = 0
-                loss_dict[key] += loss_dict_i[key]
-
-            outputs = model.decode(outputs, labels, **test_parameters)
-
-            if evaluator is not None:
-                lane_outputs, _ = outputs
-                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
-            if view:
-                outputs, extra_outputs = outputs
-                preds = test_loader.dataset.draw_annotation(
-                    idx,
-                    pred=outputs[0].cpu().numpy(),
-                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
-                cv2.imshow('pred', preds)
-                cv2.waitKey(0)
-
-    if verbose:
-        logging.info("Testing time: {:.4f}".format(time() - test_t0))
-    out_line = []
-    for key in loss_dict:
-        loss_dict[key] /= total_iters
-        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
-    if verbose:
-        logging.info(', '.join(out_line))
-
-    return evaluator, loss / total_iters
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Lane regression")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
-    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
-    parser.add_argument("--view", action="store_true", help="Show predictions")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    # Set up logging
-    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
-
-    # Model
-    model = cfg.get_model().to(device)
-    test_epoch = args.epoch
-
-    # Get data set
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size if args.view is False else 1,
-                                              shuffle=False,
-                                              num_workers=8)
-    # Eval results
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import logging
+import argparse
+import subprocess
+from time import time
+
+import cv2
+import numpy as np
+import torch
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
+    if verbose:
+        logging.info("Starting testing.")
+
+    # Test the model
+    if epoch > 0:
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
+
+    model.eval()
+    criterion_parameters = cfg.get_loss_parameters()
+    test_parameters = cfg.get_test_parameters()
+    criterion = model.loss
+    loss = 0
+    total_iters = 0
+    test_t0 = time()
+    loss_dict = {}
+    with torch.no_grad():
+        for idx, (images, labels, img_idxs) in enumerate(test_loader):
+            if max_batches is not None and idx >= max_batches:
+                break
+            if idx % 1 == 0 and verbose:
+                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
+            images = images.to(device)
+            labels = labels.to(device)
+
+            t0 = time()
+            outputs = model(images)
+            t = time() - t0
+            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            loss += loss_i.item()
+            total_iters += 1
+            for key in loss_dict_i:
+                if key not in loss_dict:
+                    loss_dict[key] = 0
+                loss_dict[key] += loss_dict_i[key]
+
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            if evaluator is not None:
+                lane_outputs, _ = outputs
+                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
+            if view:
+                outputs, extra_outputs = outputs
+                preds = test_loader.dataset.draw_annotation(
+                    idx,
+                    pred=outputs[0].cpu().numpy(),
+                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+                cv2.imshow('pred', preds)
+                cv2.waitKey(0)
+
+    if verbose:
+        logging.info("Testing time: {:.4f}".format(time() - test_t0))
+    out_line = []
+    for key in loss_dict:
+        loss_dict[key] /= total_iters
+        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
+    if verbose:
+        logging.info(', '.join(out_line))
+
+    return evaluator, loss / total_iters
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
+    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
+    parser.add_argument("--view", action="store_true", help="Show predictions")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    # Set up logging
+    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
+
+    # Model
+    model = cfg.get_model().to(device)
+    test_epoch = args.epoch
+
+    # Get data set
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size if args.view is False else 1,
+                                              shuffle=False,
+                                              num_workers=8)
+    # Eval results
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/train.py b/train.py
index 3753aed..d066d7e 100644
--- a/train.py
+++ b/train.py
@@ -1,271 +1,271 @@
-import os
-import sys
-import random
-import shutil
-import logging
-import argparse
-import subprocess
-from time import time
-
-import numpy as np
-import torch
-
-from test import test
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
-    # Get initial train state
-    optimizer = cfg.get_optimizer(model.parameters())
-    scheduler = cfg.get_lr_scheduler(optimizer)
-    starting_epoch = 1
-
-    if train_state is not None:
-        model.load_state_dict(train_state['model'])
-        optimizer.load_state_dict(train_state['optimizer'])
-        scheduler.load_state_dict(train_state['lr_scheduler'])
-        starting_epoch = train_state['epoch'] + 1
-        scheduler.step(starting_epoch)
-
-    # Train the model
-    criterion_parameters = cfg.get_loss_parameters()
-    criterion = model.loss
-    total_step = len(train_loader)
-    ITER_LOG_INTERVAL = cfg['iter_log_interval']
-    ITER_TIME_WINDOW = cfg['iter_time_window']
-    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
-    t0 = time()
-    total_iter = 0
-    iter_times = []
-    logging.info("Starting training.")
-    for epoch in range(starting_epoch, num_epochs + 1):
-        epoch_t0 = time()
-        logging.info("Beginning epoch {}".format(epoch))
-        accum_loss = 0
-        for i, (images, labels, img_idxs) in enumerate(train_loader):
-            total_iter += 1
-            iter_t0 = time()
-            images = images.to(device)
-            labels = labels.to(device)
-
-            # Forward pass
-            outputs = model(images, epoch=epoch)
-            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            accum_loss += loss.item()
-
-            # Backward and optimize
-            optimizer.zero_grad()
-            loss.backward()
-            optimizer.step()
-
-            iter_times.append(time() - iter_t0)
-            if len(iter_times) > 100:
-                iter_times = iter_times[-ITER_TIME_WINDOW:]
-            if (i + 1) % ITER_LOG_INTERVAL == 0:
-                loss_str = ', '.join(
-                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
-                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
-                    epoch,
-                    num_epochs,
-                    i + 1,
-                    total_step,
-                    accum_loss / (i + 1),
-                    loss_str,
-                    np.mean(iter_times),
-                    optimizer.param_groups[0]["lr"],
-                ))
-        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
-        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
-            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
-            save_train_state(model_path, model, optimizer, scheduler, epoch)
-        if val_loader is not None:
-            evaluator = Evaluator(val_loader.dataset, exp_root)
-            evaluator, val_loss = test(
-                model,
-                val_loader,
-                evaluator,
-                None,
-                cfg,
-                view=False,
-                epoch=-1,
-                verbose=False,
-            )
-            _, results = evaluator.eval(label=None, only_metrics=True)
-            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
-            model.train()
-        scheduler.step()
-    logging.info("Training time: {:.4f}".format(time() - t0))
-
-    return model
-
-
-def save_train_state(path, model, optimizer, lr_scheduler, epoch):
-    train_state = {
-        'model': model.state_dict(),
-        'optimizer': optimizer.state_dict(),
-        'lr_scheduler': lr_scheduler.state_dict(),
-        'epoch': epoch
-    }
-
-    torch.save(train_state, path)
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--resume", action="store_true", help="Resume training")
-    parser.add_argument("--validate", action="store_true", help="Validate model during training")
-    parser.add_argument("--deterministic",
-                        action="store_true",
-                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def setup_exp_dir(exps_dir, exp_name, cfg_path):
-    dirs = ["models"]
-    exp_root = os.path.join(exps_dir, exp_name)
-
-    for dirname in dirs:
-        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
-
-    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
-    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
-        file.write(get_code_state())
-
-    return exp_root
-
-
-def get_exp_train_state(exp_root):
-    models_dir = os.path.join(exp_root, "models")
-    models = os.listdir(models_dir)
-    last_epoch, last_modelname = sorted(
-        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
-        key=lambda x: x[0],
-    )[-1]
-    train_state = torch.load(os.path.join(models_dir, last_modelname))
-
-    return train_state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    if args.deterministic:
-        torch.backends.cudnn.deterministic = True
-        torch.backends.cudnn.benchmark = False
-
-    # Set up experiment
-    if not args.resume:
-        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
-    else:
-        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Get data sets
-    train_dataset = cfg.get_dataset("train")
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"]
-
-    # Model
-    model = cfg.get_model().to(device)
-
-    train_state = None
-    if args.resume:
-        train_state = get_exp_train_state(exp_root)
-
-    # Data loader
-    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
-                                               batch_size=batch_size,
-                                               shuffle=True,
-                                               num_workers=8)
-
-    if args.validate:
-        val_dataset = cfg.get_dataset("val")
-        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
-                                                 batch_size=batch_size,
-                                                 shuffle=False,
-                                                 num_workers=8)
-    # Train regressor
-    try:
-        model = train(
-            model,
-            train_loader,
-            exp_root,
-            cfg,
-            val_loader=val_loader if args.validate else None,
-            train_state=train_state,
-        )
-    except KeyboardInterrupt:
-        logging.info("Training session terminated.")
-    test_epoch = -1
-    if cfg['backup'] is not None:
-        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
-
-    # Eval model after training
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size,
-                                              shuffle=False,
-                                              num_workers=8)
-
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import shutil
+import logging
+import argparse
+import subprocess
+from time import time
+
+import numpy as np
+import torch
+
+from test import test
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
+    # Get initial train state
+    optimizer = cfg.get_optimizer(model.parameters())
+    scheduler = cfg.get_lr_scheduler(optimizer)
+    starting_epoch = 1
+
+    if train_state is not None:
+        model.load_state_dict(train_state['model'])
+        optimizer.load_state_dict(train_state['optimizer'])
+        scheduler.load_state_dict(train_state['lr_scheduler'])
+        starting_epoch = train_state['epoch'] + 1
+        scheduler.step(starting_epoch)
+
+    # Train the model
+    criterion_parameters = cfg.get_loss_parameters()
+    criterion = model.loss
+    total_step = len(train_loader)
+    ITER_LOG_INTERVAL = cfg['iter_log_interval']
+    ITER_TIME_WINDOW = cfg['iter_time_window']
+    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
+    t0 = time()
+    total_iter = 0
+    iter_times = []
+    logging.info("Starting training.")
+    for epoch in range(starting_epoch, num_epochs + 1):
+        epoch_t0 = time()
+        logging.info("Beginning epoch {}".format(epoch))
+        accum_loss = 0
+        for i, (images, labels, img_idxs) in enumerate(train_loader):
+            total_iter += 1
+            iter_t0 = time()
+            images = images.to(device)
+            labels = labels.to(device)
+
+            # Forward pass
+            outputs = model(images, epoch=epoch)
+            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            accum_loss += loss.item()
+
+            # Backward and optimize
+            optimizer.zero_grad()
+            loss.backward()
+            optimizer.step()
+
+            iter_times.append(time() - iter_t0)
+            if len(iter_times) > 100:
+                iter_times = iter_times[-ITER_TIME_WINDOW:]
+            if (i + 1) % ITER_LOG_INTERVAL == 0:
+                loss_str = ', '.join(
+                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
+                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
+                    epoch,
+                    num_epochs,
+                    i + 1,
+                    total_step,
+                    accum_loss / (i + 1),
+                    loss_str,
+                    np.mean(iter_times),
+                    optimizer.param_groups[0]["lr"],
+                ))
+        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
+        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
+            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
+            save_train_state(model_path, model, optimizer, scheduler, epoch)
+        if val_loader is not None:
+            evaluator = Evaluator(val_loader.dataset, exp_root)
+            evaluator, val_loss = test(
+                model,
+                val_loader,
+                evaluator,
+                None,
+                cfg,
+                view=False,
+                epoch=-1,
+                verbose=False,
+            )
+            _, results = evaluator.eval(label=None, only_metrics=True)
+            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
+            model.train()
+        scheduler.step()
+    logging.info("Training time: {:.4f}".format(time() - t0))
+
+    return model
+
+
+def save_train_state(path, model, optimizer, lr_scheduler, epoch):
+    train_state = {
+        'model': model.state_dict(),
+        'optimizer': optimizer.state_dict(),
+        'lr_scheduler': lr_scheduler.state_dict(),
+        'epoch': epoch
+    }
+
+    torch.save(train_state, path)
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--resume", action="store_true", help="Resume training")
+    parser.add_argument("--validate", action="store_true", help="Validate model during training")
+    parser.add_argument("--deterministic",
+                        action="store_true",
+                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def setup_exp_dir(exps_dir, exp_name, cfg_path):
+    dirs = ["models"]
+    exp_root = os.path.join(exps_dir, exp_name)
+
+    for dirname in dirs:
+        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
+
+    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
+    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
+        file.write(get_code_state())
+
+    return exp_root
+
+
+def get_exp_train_state(exp_root):
+    models_dir = os.path.join(exp_root, "models")
+    models = os.listdir(models_dir)
+    last_epoch, last_modelname = sorted(
+        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
+        key=lambda x: x[0],
+    )[-1]
+    train_state = torch.load(os.path.join(models_dir, last_modelname))
+
+    return train_state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    if args.deterministic:
+        torch.backends.cudnn.deterministic = True
+        torch.backends.cudnn.benchmark = False
+
+    # Set up experiment
+    if not args.resume:
+        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
+    else:
+        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Get data sets
+    train_dataset = cfg.get_dataset("train")
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    # Model
+    model = cfg.get_model().to(device)
+
+    train_state = None
+    if args.resume:
+        train_state = get_exp_train_state(exp_root)
+
+    # Data loader
+    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
+                                               batch_size=batch_size,
+                                               shuffle=True,
+                                               num_workers=8)
+
+    if args.validate:
+        val_dataset = cfg.get_dataset("val")
+        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
+                                                 batch_size=batch_size,
+                                                 shuffle=False,
+                                                 num_workers=8)
+    # Train regressor
+    try:
+        model = train(
+            model,
+            train_loader,
+            exp_root,
+            cfg,
+            val_loader=val_loader if args.validate else None,
+            train_state=train_state,
+        )
+    except KeyboardInterrupt:
+        logging.info("Training session terminated.")
+    test_epoch = -1
+    if cfg['backup'] is not None:
+        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
+
+    # Eval model after training
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size,
+                                              shuffle=False,
+                                              num_workers=8)
+
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/utils/evaluator.py b/utils/evaluator.py
index b4d51a1..9793857 100644
--- a/utils/evaluator.py
+++ b/utils/evaluator.py
@@ -1,33 +1,33 @@
-import sys
-
-import numpy as np
-
-from lib.datasets.lane_dataset import LaneDataset
-
-EXPS_DIR = 'experiments'
-
-
-class Evaluator(object):
-    def __init__(self, dataset, exp_dir, poly_degree=3):
-        self.dataset = dataset
-        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
-        self.predictions = None
-        self.runtimes = np.zeros(len(dataset))
-        self.loss = np.zeros(len(dataset))
-        self.exp_dir = exp_dir
-        self.new_preds = False
-
-    def add_prediction(self, idx, pred, runtime):
-        if self.predictions is None:
-            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
-        self.predictions[idx, :pred.shape[1], :] = pred
-        self.runtimes[idx] = runtime
-        self.new_preds = True
-
-    def eval(self, **kwargs):
-        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
-
-
-if __name__ == "__main__":
-    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
-    evaluator.tusimple_eval()
+import sys
+
+import numpy as np
+
+from lib.datasets.lane_dataset import LaneDataset
+
+EXPS_DIR = 'experiments'
+
+
+class Evaluator(object):
+    def __init__(self, dataset, exp_dir, poly_degree=3):
+        self.dataset = dataset
+        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
+        self.predictions = None
+        self.runtimes = np.zeros(len(dataset))
+        self.loss = np.zeros(len(dataset))
+        self.exp_dir = exp_dir
+        self.new_preds = False
+
+    def add_prediction(self, idx, pred, runtime):
+        if self.predictions is None:
+            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
+        self.predictions[idx, :pred.shape[1], :] = pred
+        self.runtimes[idx] = runtime
+        self.new_preds = True
+
+    def eval(self, **kwargs):
+        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
+
+
+if __name__ == "__main__":
+    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
+    evaluator.tusimple_eval()
diff --git a/utils/gen_video.py b/utils/gen_video.py
index b4a3b4d..8dff9a8 100644
--- a/utils/gen_video.py
+++ b/utils/gen_video.py
@@ -1,67 +1,67 @@
-import pickle
-import argparse
-
-import cv2
-from tqdm import tqdm
-
-from lib.config import Config
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
-    parser.add_argument("--pred", help=".pkl file to load predictions from")
-    parser.add_argument("--cfg", default="config.yaml", help="Config file")
-    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
-    parser.add_argument("--out", default="video.avi", help="Output filename")
-    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
-
-    return parser.parse_args()
-
-
-def add_cover_img(video, cover_path, frames=90):
-    cover = cv2.imread(cover_path)
-    for _ in range(frames):
-        video.write(cover)
-
-
-def create_video(filename, width, height, fps=30):
-    fourcc = cv2.VideoWriter_fourcc(*'MP42')
-    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
-
-    return video
-
-
-def main():
-    args = parse_args()
-    cfg = Config(args.cfg)
-    dataset = cfg.get_dataset('test')
-    height, width = cfg['datasets']['test']['parameters']['img_size']
-    print('Using resolution {}x{}'.format(width, height))
-    if not args.view:
-        video = create_video(args.out, width, height)
-    # add_cover_img(video, args.cover)
-    with open(args.pred, "rb") as pred_file:
-        predictions = pickle.load(pred_file)
-
-    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
-        if idx < 2200: continue
-        if idx > 3000: break
-        det_pred, cls_pred = pred
-        assert det_pred.shape[0] == 1  # batch size == 1
-        frame = dataset.draw_annotation(idx,
-                                        pred=det_pred[0].cpu().numpy(),
-                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
-        assert frame.shape[:2] == (height, width)
-        if args.view:
-            cv2.imshow('frame', frame)
-            cv2.waitKey(0)
-        else:
-            video.write(frame)
-
-    if not args.view:
-        video.release()
-        print('Video saved as {}'.format(args.out))
-
-
-if __name__ == '__main__':
-    main()
+import pickle
+import argparse
+
+import cv2
+from tqdm import tqdm
+
+from lib.config import Config
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
+    parser.add_argument("--pred", help=".pkl file to load predictions from")
+    parser.add_argument("--cfg", default="config.yaml", help="Config file")
+    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
+    parser.add_argument("--out", default="video.avi", help="Output filename")
+    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
+
+    return parser.parse_args()
+
+
+def add_cover_img(video, cover_path, frames=90):
+    cover = cv2.imread(cover_path)
+    for _ in range(frames):
+        video.write(cover)
+
+
+def create_video(filename, width, height, fps=30):
+    fourcc = cv2.VideoWriter_fourcc(*'MP42')
+    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
+
+    return video
+
+
+def main():
+    args = parse_args()
+    cfg = Config(args.cfg)
+    dataset = cfg.get_dataset('test')
+    height, width = cfg['datasets']['test']['parameters']['img_size']
+    print('Using resolution {}x{}'.format(width, height))
+    if not args.view:
+        video = create_video(args.out, width, height)
+    # add_cover_img(video, args.cover)
+    with open(args.pred, "rb") as pred_file:
+        predictions = pickle.load(pred_file)
+
+    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
+        if idx < 2200: continue
+        if idx > 3000: break
+        det_pred, cls_pred = pred
+        assert det_pred.shape[0] == 1  # batch size == 1
+        frame = dataset.draw_annotation(idx,
+                                        pred=det_pred[0].cpu().numpy(),
+                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
+        assert frame.shape[:2] == (height, width)
+        if args.view:
+            cv2.imshow('frame', frame)
+            cv2.waitKey(0)
+        else:
+            video.write(frame)
+
+    if not args.view:
+        video.release()
+        print('Video saved as {}'.format(args.out))
+
+
+if __name__ == '__main__':
+    main()
diff --git a/utils/lane.py b/utils/lane.py
index 863a92a..6fd2a7d 100644
--- a/utils/lane.py
+++ b/utils/lane.py
@@ -1,133 +1,133 @@
-import numpy as np
-import ujson as json
-from sklearn.linear_model import LinearRegression
-
-
-class LaneEval(object):
-    lr = LinearRegression()
-    pixel_thresh = 20
-    pt_thresh = 0.85
-
-    @staticmethod
-    def get_angle(xs, y_samples):
-        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
-        if len(xs) > 1:
-            LaneEval.lr.fit(ys[:, None], xs)
-            k = LaneEval.lr.coef_[0]
-            theta = np.arctan(k)
-        else:
-            theta = 0
-        return theta
-
-    @staticmethod
-    def line_accuracy(pred, gt, thresh):
-        pred = np.array([p if p >= 0 else -100 for p in pred])
-        gt = np.array([g if g >= 0 else -100 for g in gt])
-        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
-
-    @staticmethod
-    def distances(pred, gt):
-        return np.abs(pred - gt)
-
-    @staticmethod
-    def bench(pred, gt, y_samples, running_time, get_matches=False):
-        if any(len(p) != len(y_samples) for p in pred):
-            raise Exception('Format of lanes error.')
-        if running_time > 20000 or len(gt) + 2 < len(pred):
-            return 0., 0., 1.
-        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
-        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
-        line_accs = []
-        fp, fn = 0., 0.
-        matched = 0.
-        my_matches = [False] * len(pred)
-        my_accs = [0] * len(pred)
-        my_dists = [None] * len(pred)
-        for x_gts, thresh in zip(gt, threshs):
-            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
-            my_accs = np.maximum(my_accs, accs)
-            max_acc = np.max(accs) if len(accs) > 0 else 0.
-            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
-            if len(accs) > 0:
-                my_dists[np.argmax(accs)] = {
-                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
-                    'dists': list(my_dist[np.argmax(accs)])
-                }
-
-            if max_acc < LaneEval.pt_thresh:
-                fn += 1
-            else:
-                my_matches[np.argmax(accs)] = True
-                matched += 1
-            line_accs.append(max_acc)
-        fp = len(pred) - matched
-        if len(gt) > 4 and fn > 0:
-            fn -= 1
-        s = sum(line_accs)
-        if len(gt) > 4:
-            s -= min(line_accs)
-        if get_matches:
-            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
-                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
-        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
-
-    @staticmethod
-    def bench_one_submit(pred_file, gt_file):
-        try:
-            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-        except BaseException as e:
-            raise Exception('Fail to load json file of the prediction.')
-        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-        if len(json_gt) != len(json_pred):
-            raise Exception('We do not get the predictions of all the test tasks')
-        gts = {l['raw_file']: l for l in json_gt}
-        accuracy, fp, fn = 0., 0., 0.
-        run_times = []
-        for pred in json_pred:
-            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
-                raise Exception('raw_file or lanes or run_time not in some predictions.')
-            raw_file = pred['raw_file']
-            pred_lanes = pred['lanes']
-            run_time = pred['run_time']
-            run_times.append(run_time)
-            if raw_file not in gts:
-                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-            gt = gts[raw_file]
-            gt_lanes = gt['lanes']
-            y_samples = gt['h_samples']
-            try:
-                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
-            except BaseException as e:
-                raise Exception('Format of lanes error.')
-            accuracy += a
-            fp += p
-            fn += n
-        num = len(gts)
-        # the first return parameter is the default ranking parameter
-        return json.dumps([{
-            'name': 'Accuracy',
-            'value': accuracy / num,
-            'order': 'desc'
-        }, {
-            'name': 'FP',
-            'value': fp / num,
-            'order': 'asc'
-        }, {
-            'name': 'FN',
-            'value': fn / num,
-            'order': 'asc'
-        }, {
-            'name': 'FPS',
-            'value': 1000. / np.mean(run_times)
-        }])
-
-
-if __name__ == '__main__':
-    import sys
-    try:
-        if len(sys.argv) != 3:
-            raise Exception('Invalid input arguments')
-        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
-    except Exception as e:
-        print(e)
-        # sys.exit(e.message)
+import numpy as np
+import ujson as json
+from sklearn.linear_model import LinearRegression
+
+
+class LaneEval(object):
+    lr = LinearRegression()
+    pixel_thresh = 20
+    pt_thresh = 0.85
+
+    @staticmethod
+    def get_angle(xs, y_samples):
+        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
+        if len(xs) > 1:
+            LaneEval.lr.fit(ys[:, None], xs)
+            k = LaneEval.lr.coef_[0]
+            theta = np.arctan(k)
+        else:
+            theta = 0
+        return theta
+
+    @staticmethod
+    def line_accuracy(pred, gt, thresh):
+        pred = np.array([p if p >= 0 else -100 for p in pred])
+        gt = np.array([g if g >= 0 else -100 for g in gt])
+        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
+
+    @staticmethod
+    def distances(pred, gt):
+        return np.abs(pred - gt)
+
+    @staticmethod
+    def bench(pred, gt, y_samples, running_time, get_matches=False):
+        if any(len(p) != len(y_samples) for p in pred):
+            raise Exception('Format of lanes error.')
+        if running_time > 20000 or len(gt) + 2 < len(pred):
+            return 0., 0., 1.
+        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
+        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
+        line_accs = []
+        fp, fn = 0., 0.
+        matched = 0.
+        my_matches = [False] * len(pred)
+        my_accs = [0] * len(pred)
+        my_dists = [None] * len(pred)
+        for x_gts, thresh in zip(gt, threshs):
+            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
+            my_accs = np.maximum(my_accs, accs)
+            max_acc = np.max(accs) if len(accs) > 0 else 0.
+            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
+            if len(accs) > 0:
+                my_dists[np.argmax(accs)] = {
+                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
+                    'dists': list(my_dist[np.argmax(accs)])
+                }
+
+            if max_acc < LaneEval.pt_thresh:
+                fn += 1
+            else:
+                my_matches[np.argmax(accs)] = True
+                matched += 1
+            line_accs.append(max_acc)
+        fp = len(pred) - matched
+        if len(gt) > 4 and fn > 0:
+            fn -= 1
+        s = sum(line_accs)
+        if len(gt) > 4:
+            s -= min(line_accs)
+        if get_matches:
+            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
+                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
+        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
+
+    @staticmethod
+    def bench_one_submit(pred_file, gt_file):
+        try:
+            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+        except BaseException as e:
+            raise Exception('Fail to load json file of the prediction.')
+        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+        if len(json_gt) != len(json_pred):
+            raise Exception('We do not get the predictions of all the test tasks')
+        gts = {l['raw_file']: l for l in json_gt}
+        accuracy, fp, fn = 0., 0., 0.
+        run_times = []
+        for pred in json_pred:
+            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
+                raise Exception('raw_file or lanes or run_time not in some predictions.')
+            raw_file = pred['raw_file']
+            pred_lanes = pred['lanes']
+            run_time = pred['run_time']
+            run_times.append(run_time)
+            if raw_file not in gts:
+                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+            gt = gts[raw_file]
+            gt_lanes = gt['lanes']
+            y_samples = gt['h_samples']
+            try:
+                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
+            except BaseException as e:
+                raise Exception('Format of lanes error.')
+            accuracy += a
+            fp += p
+            fn += n
+        num = len(gts)
+        # the first return parameter is the default ranking parameter
+        return json.dumps([{
+            'name': 'Accuracy',
+            'value': accuracy / num,
+            'order': 'desc'
+        }, {
+            'name': 'FP',
+            'value': fp / num,
+            'order': 'asc'
+        }, {
+            'name': 'FN',
+            'value': fn / num,
+            'order': 'asc'
+        }, {
+            'name': 'FPS',
+            'value': 1000. / np.mean(run_times)
+        }])
+
+
+if __name__ == '__main__':
+    import sys
+    try:
+        if len(sys.argv) != 3:
+            raise Exception('Invalid input arguments')
+        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
+    except Exception as e:
+        print(e)
+        # sys.exit(e.message)
diff --git a/utils/metric.py b/utils/metric.py
index f2c066d..9fe866e 100644
--- a/utils/metric.py
+++ b/utils/metric.py
@@ -1,177 +1,177 @@
-import argparse
-from pprint import pprint
-
-import cv2
-import numpy as np
-import ujson as json
-from tqdm import tqdm
-from tabulate import tabulate
-from scipy.spatial import distance
-
-
-def show_preds(pred, gt):
-    img = np.zeros((720, 1280, 3), dtype=np.uint8)
-    print(len(gt), 'gts and', len(pred), 'preds')
-    for lane in gt:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
-    for lane in pred:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
-    cv2.imshow('img', img)
-    cv2.waitKey(0)
-
-
-def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
-    pred = np.vstack([pred_x, pred_y]).T
-    gt = np.vstack([gt_x, gt_y]).T
-
-    # pred = pred[pred[:, 0] > 0][:3, :]
-    # gt = gt[gt[:, 0] > 0][:5, :]
-
-    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
-
-    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
-    dist /= np.max(gt_y) - np.min(gt_y)
-    return dist
-
-
-def area_metric(pred, gt, debug=None):
-    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    if len(pred) == 0:
-        return 0., 0., len(gt)
-    line_dists = []
-    fp = 0.
-    matched = 0.
-    gt_matches = [False] * len(gt)
-    pred_matches = [False] * len(pred)
-    pred_dists = [None] * len(pred)
-
-    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
-    for i_gt, gt_points in enumerate(gt):
-        x_gts = [x for x, _ in gt_points]
-        y_gts = [y for _, y in gt_points]
-        for i_pred, pred_points in enumerate(pred):
-            x_preds = [x for x, _ in pred_points]
-            y_preds = [y for _, y in pred_points]
-            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
-
-    best_preds = np.argmin(distances, axis=1)
-    best_gts = np.argmin(distances, axis=0)
-    fp = 0.
-    fn = 0.
-    dist = 0.
-    is_fp = []
-    is_fn = []
-    for i_pred, best_gt in enumerate(best_gts):
-        if best_preds[best_gt] == i_pred:
-            dist += distances[best_gt, i_pred]
-            is_fp.append(False)
-        else:
-            fp += 1
-            is_fp.append(True)
-    for i_gt, best_pred in enumerate(best_preds):
-        if best_gts[best_pred] != i_gt:
-            fn += 1
-            is_fn.append(True)
-        else:
-            is_fn.append(False)
-    if debug:
-        print('is fp')
-        print(is_fp)
-        print('is fn')
-        print(is_fn)
-        print('distances')
-        dists = np.min(distances, axis=0)
-        dists[np.array(is_fp)] = 0
-        print(dists)
-        show_preds(pred, gt)
-
-    return dist, fp, fn
-
-
-def convert_tusimple_format(json_gt):
-    output = []
-    for data in json_gt:
-        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
-                 if any(x > 0 for x in lane)]
-        output.append({
-            'raw_file': data['raw_file'],
-            'run_time': data['run_time'] if 'run_time' in data else None,
-            'lanes': lanes
-        })
-    return output
-
-
-def eval_json(pred_file, gt_file, json_type=None, debug=False):
-    try:
-        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-    except BaseException as e:
-        raise Exception('Fail to load json file of the prediction.')
-    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-    if len(json_gt) != len(json_pred):
-        raise Exception('We do not get the predictions of all the test tasks')
-
-    if json_type == 'tusimple':
-        for gt, pred in zip(json_gt, json_pred):
-            pred['h_samples'] = gt['h_samples']
-        json_gt = convert_tusimple_format(json_gt)
-        json_pred = convert_tusimple_format(json_pred)
-    gts = {l['raw_file']: l for l in json_gt}
-
-    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
-    for pred in tqdm(json_pred):
-        if 'raw_file' not in pred or 'lanes' not in pred:
-            raise Exception('raw_file or lanes not in some predictions.')
-        raw_file = pred['raw_file']
-        pred_lanes = pred['lanes']
-        run_time += pred['run_time'] if 'run_time' in pred else 1.
-
-        if raw_file not in gts:
-            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-        gt = gts[raw_file]
-        gt_lanes = gt['lanes']
-
-        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
-
-        total_distance += distance
-        total_fp += fp
-        total_fn += fn
-
-    num = len(gts)
-    return json.dumps([{
-        'name': 'Distance',
-        'value': total_distance / num,
-        'order': 'desc'
-    }, {
-        'name': 'FP',
-        'value': total_fp,
-        'order': 'asc'
-    }, {
-        'name': 'FN',
-        'value': total_fn,
-        'order': 'asc'
-    }, {
-        'name': 'FPS',
-        'value': 1000. * num / run_time
-    }])
-
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(description="Compute the metrics")
-    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
-    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
-    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
-    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
-    argv = vars(parser.parse_args())
-
-    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
-
-    # pretty-print
-    table = {}
-    for metric in result:
-        if metric['name'] not in table.keys():
-            table[metric['name']] = []
-        table[metric['name']].append(metric['value'])
-    print(tabulate(table, headers='keys'))
+import argparse
+from pprint import pprint
+
+import cv2
+import numpy as np
+import ujson as json
+from tqdm import tqdm
+from tabulate import tabulate
+from scipy.spatial import distance
+
+
+def show_preds(pred, gt):
+    img = np.zeros((720, 1280, 3), dtype=np.uint8)
+    print(len(gt), 'gts and', len(pred), 'preds')
+    for lane in gt:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
+    for lane in pred:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
+    cv2.imshow('img', img)
+    cv2.waitKey(0)
+
+
+def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
+    pred = np.vstack([pred_x, pred_y]).T
+    gt = np.vstack([gt_x, gt_y]).T
+
+    # pred = pred[pred[:, 0] > 0][:3, :]
+    # gt = gt[gt[:, 0] > 0][:5, :]
+
+    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
+
+    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
+    dist /= np.max(gt_y) - np.min(gt_y)
+    return dist
+
+
+def area_metric(pred, gt, debug=None):
+    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    if len(pred) == 0:
+        return 0., 0., len(gt)
+    line_dists = []
+    fp = 0.
+    matched = 0.
+    gt_matches = [False] * len(gt)
+    pred_matches = [False] * len(pred)
+    pred_dists = [None] * len(pred)
+
+    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
+    for i_gt, gt_points in enumerate(gt):
+        x_gts = [x for x, _ in gt_points]
+        y_gts = [y for _, y in gt_points]
+        for i_pred, pred_points in enumerate(pred):
+            x_preds = [x for x, _ in pred_points]
+            y_preds = [y for _, y in pred_points]
+            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
+
+    best_preds = np.argmin(distances, axis=1)
+    best_gts = np.argmin(distances, axis=0)
+    fp = 0.
+    fn = 0.
+    dist = 0.
+    is_fp = []
+    is_fn = []
+    for i_pred, best_gt in enumerate(best_gts):
+        if best_preds[best_gt] == i_pred:
+            dist += distances[best_gt, i_pred]
+            is_fp.append(False)
+        else:
+            fp += 1
+            is_fp.append(True)
+    for i_gt, best_pred in enumerate(best_preds):
+        if best_gts[best_pred] != i_gt:
+            fn += 1
+            is_fn.append(True)
+        else:
+            is_fn.append(False)
+    if debug:
+        print('is fp')
+        print(is_fp)
+        print('is fn')
+        print(is_fn)
+        print('distances')
+        dists = np.min(distances, axis=0)
+        dists[np.array(is_fp)] = 0
+        print(dists)
+        show_preds(pred, gt)
+
+    return dist, fp, fn
+
+
+def convert_tusimple_format(json_gt):
+    output = []
+    for data in json_gt:
+        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
+                 if any(x > 0 for x in lane)]
+        output.append({
+            'raw_file': data['raw_file'],
+            'run_time': data['run_time'] if 'run_time' in data else None,
+            'lanes': lanes
+        })
+    return output
+
+
+def eval_json(pred_file, gt_file, json_type=None, debug=False):
+    try:
+        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+    except BaseException as e:
+        raise Exception('Fail to load json file of the prediction.')
+    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+    if len(json_gt) != len(json_pred):
+        raise Exception('We do not get the predictions of all the test tasks')
+
+    if json_type == 'tusimple':
+        for gt, pred in zip(json_gt, json_pred):
+            pred['h_samples'] = gt['h_samples']
+        json_gt = convert_tusimple_format(json_gt)
+        json_pred = convert_tusimple_format(json_pred)
+    gts = {l['raw_file']: l for l in json_gt}
+
+    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
+    for pred in tqdm(json_pred):
+        if 'raw_file' not in pred or 'lanes' not in pred:
+            raise Exception('raw_file or lanes not in some predictions.')
+        raw_file = pred['raw_file']
+        pred_lanes = pred['lanes']
+        run_time += pred['run_time'] if 'run_time' in pred else 1.
+
+        if raw_file not in gts:
+            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+        gt = gts[raw_file]
+        gt_lanes = gt['lanes']
+
+        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
+
+        total_distance += distance
+        total_fp += fp
+        total_fn += fn
+
+    num = len(gts)
+    return json.dumps([{
+        'name': 'Distance',
+        'value': total_distance / num,
+        'order': 'desc'
+    }, {
+        'name': 'FP',
+        'value': total_fp,
+        'order': 'asc'
+    }, {
+        'name': 'FN',
+        'value': total_fn,
+        'order': 'asc'
+    }, {
+        'name': 'FPS',
+        'value': 1000. * num / run_time
+    }])
+
+
+if __name__ == '__main__':
+    parser = argparse.ArgumentParser(description="Compute the metrics")
+    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
+    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
+    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
+    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
+    argv = vars(parser.parse_args())
+
+    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
+
+    # pretty-print
+    table = {}
+    for metric in result:
+        if metric['name'] not in table.keys():
+            table[metric['name']] = []
+        table[metric['name']].append(metric['value'])
+    print(tabulate(table, headers='keys'))
diff --git a/utils/plot_log.py b/utils/plot_log.py
index ee18cf1..aaba69a 100644
--- a/utils/plot_log.py
+++ b/utils/plot_log.py
@@ -1,161 +1,161 @@
-import os
-import re
-import argparse
-import datetime
-
-import numpy as np
-import matplotlib.dates as mdates
-import matplotlib.colors as colors
-import matplotlib.pyplot as plt
-
-ITER_PATTERN = re.compile(
-    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
-)
-LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
-EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
-EXPS_DIR = '../data_lane-regression/experiments'
-
-# TODO: refactor this file
-
-
-def smooth_curve(xs, factor):
-    smoothed = [None] * len(xs)
-    smoothed[0] = xs[0]
-    for i in range(1, len(xs)):
-        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
-
-    return smoothed
-
-
-def plot_loss(data,
-              fig,
-              ax,
-              label,
-              plot_lr=True,
-              smoothing=0,
-              xaxis='time',
-              only_epoch_end=False,
-              plot_val=False,
-              plot_loss_comps=False):
-    iter_data = data['iter_update']
-    epoch_data = data['epoch_update']
-    now = datetime.datetime.today()
-    if xaxis == 'epoch':
-        if only_epoch_end:
-            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
-        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
-    elif xaxis == 'time':
-        d0 = iter_data[0]['date']
-        x = [now + (d['date'] - d0) for d in iter_data]
-    elif xaxis == 'iter':
-        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
-    loss = [d['loss'] for d in iter_data]
-    if plot_loss_comps:
-        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
-    if plot_val:
-        val_loss = [d['val_loss'] for d in epoch_data]
-        if xaxis == 'epoch':
-            val_loss_x = [d['epoch'] for d in epoch_data]
-        else:
-            val_loss_d0 = epoch_data[0]['date']
-            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
-    loss_smooth = smooth_curve(loss, factor=smoothing)
-    if plot_lr:
-        lr = [d['lr'] for d in iter_data]
-        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
-                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
-        if len(lr_decays) < 10:
-            for epoch, old, new in lr_decays:
-                ax.axvline(x=epoch, linestyle='--')
-        ax.plot(x, lr, label='LR: {}'.format(label))
-    ax.set_yscale('log')
-    ax.set_title('Loss')
-    ax.set_xlabel('Epoch')
-    ax.set_ylabel('Loss')
-    loss_line = ax.plot(x, loss_smooth)[0]
-    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
-    loss_line_color[-1] = 0.5
-    if plot_loss_comps:
-        for loss_comp in loss_comps:
-            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
-            line_color = np.array(colors.to_rgba(line.get_color()))
-            line_color[-1] = 0.5
-            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
-    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
-    if plot_val:
-        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
-    if xaxis == 'time':
-        fig.autofmt_xdate()
-        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
-
-
-def parse_line(line):
-    iter_match = re.match(ITER_PATTERN, line)
-    epoch_match = re.match(EPOCH_PATTERN, line)
-    data = {}
-    if iter_match is not None:
-        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
-        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
-            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
-                loss), float(speed), float(lr)
-        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
-        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
-        data['iter_update'] = {
-            'date': date,
-            'epoch': epoch,
-            'total_epochs': total_epochs,
-            'iter_nb': iter_nb,
-            'total_iters': total_iters,
-            'loss': loss,
-            'speed': date,
-            'loss_comps': loss_comps,
-            'lr': lr,
-        }
-    if epoch_match is not None:
-        date, epoch, _, val_loss = epoch_match.groups()
-        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
-        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
-
-    return data
-
-
-def parse_log(log_path):
-    with open(log_path, 'r') as log_file:
-        lines = [line.rstrip() for line in log_file.readlines()]
-    data = {'iter_update': [], 'epoch_update': []}
-    for line in lines:
-        line_data = parse_line(line)
-        for key in line_data:
-            data[key].append(line_data[key])
-    return data
-
-
-def get_logfilepath(exp_name):
-    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description='Visualization')
-    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
-    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
-    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
-
-    return parser.parse_args()
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    fig, ax = plt.subplots(nrows=1, ncols=1)
-    for exp_name in args.exp_name:
-        log_filepath = get_logfilepath(exp_name)
-        data = parse_log(log_filepath)
-        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
-
-    # Show the major grid lines with dark grey lines
-    plt.grid(b=True, which='major', color='#666666', linestyle='-')
-
-    # Show the minor grid lines with very faint and almost transparent grey lines
-    plt.minorticks_on()
-    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
-    plt.legend()
-    plt.show()
+import os
+import re
+import argparse
+import datetime
+
+import numpy as np
+import matplotlib.dates as mdates
+import matplotlib.colors as colors
+import matplotlib.pyplot as plt
+
+ITER_PATTERN = re.compile(
+    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
+)
+LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
+EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
+EXPS_DIR = '../data_lane-regression/experiments'
+
+# TODO: refactor this file
+
+
+def smooth_curve(xs, factor):
+    smoothed = [None] * len(xs)
+    smoothed[0] = xs[0]
+    for i in range(1, len(xs)):
+        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
+
+    return smoothed
+
+
+def plot_loss(data,
+              fig,
+              ax,
+              label,
+              plot_lr=True,
+              smoothing=0,
+              xaxis='time',
+              only_epoch_end=False,
+              plot_val=False,
+              plot_loss_comps=False):
+    iter_data = data['iter_update']
+    epoch_data = data['epoch_update']
+    now = datetime.datetime.today()
+    if xaxis == 'epoch':
+        if only_epoch_end:
+            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
+        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
+    elif xaxis == 'time':
+        d0 = iter_data[0]['date']
+        x = [now + (d['date'] - d0) for d in iter_data]
+    elif xaxis == 'iter':
+        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
+    loss = [d['loss'] for d in iter_data]
+    if plot_loss_comps:
+        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
+    if plot_val:
+        val_loss = [d['val_loss'] for d in epoch_data]
+        if xaxis == 'epoch':
+            val_loss_x = [d['epoch'] for d in epoch_data]
+        else:
+            val_loss_d0 = epoch_data[0]['date']
+            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
+    loss_smooth = smooth_curve(loss, factor=smoothing)
+    if plot_lr:
+        lr = [d['lr'] for d in iter_data]
+        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
+                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
+        if len(lr_decays) < 10:
+            for epoch, old, new in lr_decays:
+                ax.axvline(x=epoch, linestyle='--')
+        ax.plot(x, lr, label='LR: {}'.format(label))
+    ax.set_yscale('log')
+    ax.set_title('Loss')
+    ax.set_xlabel('Epoch')
+    ax.set_ylabel('Loss')
+    loss_line = ax.plot(x, loss_smooth)[0]
+    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
+    loss_line_color[-1] = 0.5
+    if plot_loss_comps:
+        for loss_comp in loss_comps:
+            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
+            line_color = np.array(colors.to_rgba(line.get_color()))
+            line_color[-1] = 0.5
+            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
+    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
+    if plot_val:
+        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
+    if xaxis == 'time':
+        fig.autofmt_xdate()
+        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
+
+
+def parse_line(line):
+    iter_match = re.match(ITER_PATTERN, line)
+    epoch_match = re.match(EPOCH_PATTERN, line)
+    data = {}
+    if iter_match is not None:
+        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
+        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
+            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
+                loss), float(speed), float(lr)
+        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
+        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
+        data['iter_update'] = {
+            'date': date,
+            'epoch': epoch,
+            'total_epochs': total_epochs,
+            'iter_nb': iter_nb,
+            'total_iters': total_iters,
+            'loss': loss,
+            'speed': date,
+            'loss_comps': loss_comps,
+            'lr': lr,
+        }
+    if epoch_match is not None:
+        date, epoch, _, val_loss = epoch_match.groups()
+        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
+        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
+
+    return data
+
+
+def parse_log(log_path):
+    with open(log_path, 'r') as log_file:
+        lines = [line.rstrip() for line in log_file.readlines()]
+    data = {'iter_update': [], 'epoch_update': []}
+    for line in lines:
+        line_data = parse_line(line)
+        for key in line_data:
+            data[key].append(line_data[key])
+    return data
+
+
+def get_logfilepath(exp_name):
+    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description='Visualization')
+    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
+    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
+    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
+
+    return parser.parse_args()
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    fig, ax = plt.subplots(nrows=1, ncols=1)
+    for exp_name in args.exp_name:
+        log_filepath = get_logfilepath(exp_name)
+        data = parse_log(log_filepath)
+        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
+
+    # Show the major grid lines with dark grey lines
+    plt.grid(b=True, which='major', color='#666666', linestyle='-')
+
+    # Show the minor grid lines with very faint and almost transparent grey lines
+    plt.minorticks_on()
+    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
+    plt.legend()
+    plt.show()
diff --git a/utils/upperbound.py b/utils/upperbound.py
index 78af9b3..1fbce9e 100644
--- a/utils/upperbound.py
+++ b/utils/upperbound.py
@@ -1,44 +1,44 @@
-import sys
-import warnings
-
-import numpy as np
-from progressbar import progressbar
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-warnings.simplefilter('ignore', np.RankWarning)
-
-
-def polyfit_upperbound(dataset, degree):
-    evaluator = Evaluator(dataset, '/tmp', degree)
-    print('Predicting with upperbound...')
-    for i, anno in enumerate(progressbar(dataset.annotations)):
-        label = anno['label']
-        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
-        pred[:, :3] = label[:, :3]
-        for j, lane in enumerate(label):
-            if lane[0] == 0:
-                continue
-            xy = lane[3:]
-            x = xy[:(len(xy) // 2)]
-            y = xy[(len(xy) // 2):]
-            ind = x > 0
-            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
-        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
-    _, result = evaluator.eval(label='upperbound', only_metrics=True)
-
-    return result
-
-
-if __name__ == "__main__":
-    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
-    dataset = cfg.get_dataset('test')
-    for n in range(1, 5 + 1):
-        result = polyfit_upperbound(dataset, n)
-        print('Degree {} upperbound:'.format(n))
-        for metric in result:
-            if metric['name'] == 'Accuracy':
-                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
-            else:
-                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))
+import sys
+import warnings
+
+import numpy as np
+from progressbar import progressbar
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+warnings.simplefilter('ignore', np.RankWarning)
+
+
+def polyfit_upperbound(dataset, degree):
+    evaluator = Evaluator(dataset, '/tmp', degree)
+    print('Predicting with upperbound...')
+    for i, anno in enumerate(progressbar(dataset.annotations)):
+        label = anno['label']
+        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
+        pred[:, :3] = label[:, :3]
+        for j, lane in enumerate(label):
+            if lane[0] == 0:
+                continue
+            xy = lane[3:]
+            x = xy[:(len(xy) // 2)]
+            y = xy[(len(xy) // 2):]
+            ind = x > 0
+            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
+        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
+    _, result = evaluator.eval(label='upperbound', only_metrics=True)
+
+    return result
+
+
+if __name__ == "__main__":
+    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
+    dataset = cfg.get_dataset('test')
+    for n in range(1, 5 + 1):
+        result = polyfit_upperbound(dataset, n)
+        print('Degree {} upperbound:'.format(n))
+        for metric in result:
+            if metric['name'] == 'Accuracy':
+                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
+            else:
+                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))

[2021-08-06 23:28:11,157] [INFO] Starting testing.
[2021-08-06 23:28:11,157] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 159, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 22, in test
    if epoch > 0:
TypeError: '>' not supported between instances of 'NoneType' and 'int'
[2021-08-06 23:29:03,455] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-06 23:29:03,456] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-06 23:29:03,458] [INFO] Args:
Namespace(batch_size=1, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-06 23:29:04,470] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/.gitignore b/.gitignore
index e4bcbf2..fdf6f3f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,8 +1,8 @@
-__pycache__
-experiments
-.vscode
-venv
-config.yaml
-/datasets/
-lib/nms/build/
-lib/nms/dist/
+__pycache__
+experiments
+.vscode
+venv
+config.yaml
+/datasets/
+lib/nms/build/
+lib/nms/dist/
diff --git a/LICENSE b/LICENSE
index f8fe53d..33d52bc 100644
--- a/LICENSE
+++ b/LICENSE
@@ -1,21 +1,21 @@
-MIT License
-
-Copyright (c) 2020 Lucas Tabelini Torres
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+MIT License
+
+Copyright (c) 2020 Lucas Tabelini Torres
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
diff --git a/README.md b/README.md
index b4af404..d49fcb0 100644
--- a/README.md
+++ b/README.md
@@ -1,165 +1,166 @@
-<div align="center">
-
-# PolyLaneNet
-![Method overview](figures/method-overview.png "Method overview")
-</div>
-
-## Description
-Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
-[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
-
-**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
-
-## Table of Contents
-1. [Installation](#installation)
-2. [Usage](#usage)
-3. [Reproducing the paper results](#reproducing)
-
-<a name="installation"/>
-
-### Installation
-The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
-
-Install dependencies:
-```
-pip install -r requirements.txt
-```
-
-<a name="usage"/>
-
-### Usage
-#### Training
-Every setting for a training is set through a YAML configuration file.
-Thus, in order to train a model you will have to setup the configuration file.
-An example is shown:
-```yaml
-# Training settings
-exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
-iter_log_interval: 1 # Log training iteration every N iterations
-iter_time_window: 100 # Moving average iterations window for the printed loss metric
-model_save_interval: 1 # Save model every N epochs
-seed: 0 # Seed for randomness
-backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
-
-# Dataset settings
-datasets:
-  train:
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: # ImgAug augmentations
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "datasets/tusimple" # Dataset root
-
-  test: &test
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      img_size: [360, 640]
-      root: "datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
-```
-
-With the config file created, run the training script:
-```bash
-python train.py --exp_name tusimple --cfg config.yaml
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the training (.yaml)
-  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
-  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
-  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
-```
-
-#### Testing
-After training, run the `test.py` script to get the metrics:
-```bash
-python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
-  --epoch EPOCH         Epoch to test the model on
-  --batch_size          Number of images per batch
-  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
-```
-
-If you have any issues with either training or testing feel free to open an issue.
-
-<a name="reproducing"/>
-
-### Reproducing the paper results
-
-#### Models
-All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
-
-#### Datasets
-- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
-- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
-- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
-
-#### How to
-To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
-If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
-If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
-1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
-1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
-1. Move the downloaded experiment to your `exps_dir` folder.
-
-Then, run:
-
-```bash
-python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
-```
-Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
-
-
+<div align="center">
+
+# PolyLaneNet
+![Method overview](figures/method-overview.png "Method overview")
+</div>
+
+## Description
+Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
+[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
+
+**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
+
+## Table of Contents
+1. [Installation](#installation)
+2. [Usage](#usage)
+3. [Reproducing the paper results](#reproducing)
+
+<a name="installation"/>
+
+### Installation
+The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
+
+Install dependencies:
+```
+pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
+```
+
+<a name="usage"/>
+
+### Usage
+#### Training
+Every setting for a training is set through a YAML configuration file.
+Thus, in order to train a model you will have to setup the configuration file.
+An example is shown:
+```yaml
+# Training settings
+exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
+iter_log_interval: 1 # Log training iteration every N iterations
+iter_time_window: 100 # Moving average iterations window for the printed loss metric
+model_save_interval: 1 # Save model every N epochs
+seed: 0 # Seed for randomness
+backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
+
+# Dataset settings
+datasets:
+  train:
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: # ImgAug augmentations
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "datasets/tusimple" # Dataset root
+
+  test: &test
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      img_size: [360, 640]
+      root: "datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
+```
+
+With the config file created, run the training script:
+```bash
+python train.py --exp_name tusimple --cfg config.yaml
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the training (.yaml)
+  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
+  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
+  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
+```
+
+#### Testing
+After training, run the `test.py` script to get the metrics:
+```bash
+python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
+  --epoch EPOCH         Epoch to test the model on
+  --batch_size          Number of images per batch
+  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
+```
+
+If you have any issues with either training or testing feel free to open an issue.
+
+<a name="reproducing"/>
+
+### Reproducing the paper results
+
+#### Models
+All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
+
+#### Datasets
+- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
+- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
+- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
+
+#### How to
+To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
+If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
+If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
+1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
+1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
+1. Move the downloaded experiment to your `exps_dir` folder.
+
+Then, run:
+
+```bash
+python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
+```
+Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
+
+
diff --git a/cfgs/elas.yaml b/cfgs/elas.yaml
index 98a03bd..8d9f910 100644
--- a/cfgs/elas.yaml
+++ b/cfgs/elas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 35
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 35
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 35
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 35
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/elas_cls.yaml b/cfgs/elas_cls.yaml
index a251b94..db6d9c8 100644
--- a/cfgs/elas_cls.yaml
+++ b/cfgs/elas_cls.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: true
-    extra_outputs: 40 # 5 lanes * 8 classes
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 1
-  poly_weight: 300
-batch_size: 16
-epochs: 385
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: true
+    extra_outputs: 40 # 5 lanes * 8 classes
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 1
+  poly_weight: 300
+batch_size: 16
+epochs: 385
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/llamas.yaml b/cfgs/llamas.yaml
index 5806168..1af205d 100644
--- a/cfgs/llamas.yaml
+++ b/cfgs/llamas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 75
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 75
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: llamas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/llamas"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: llamas
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/llamas"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 75
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 75
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: llamas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/llamas"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: llamas
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/llamas"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple.yaml b/cfgs/tusimple.yaml
index 01da72b..2a13cb1 100644
--- a/cfgs/tusimple.yaml
+++ b/cfgs/tusimple.yaml
@@ -1,73 +1,73 @@
-# Training settings
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-seed: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+seed: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_1order.yaml b/cfgs/tusimple_1order.yaml
index 66a8607..3e5f617 100644
--- a/cfgs/tusimple_1order.yaml
+++ b/cfgs/tusimple_1order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 1 
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 9000, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression//datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression//datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 1 
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 9000, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression//datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression//datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_2order.yaml b/cfgs/tusimple_2order.yaml
index 9091dcc..2e3cdca 100644
--- a/cfgs/tusimple_2order.yaml
+++ b/cfgs/tusimple_2order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_320x180.yaml b/cfgs/tusimple_320x180.yaml
index fb61010..32b8f5e 100644
--- a/cfgs/tusimple_320x180.yaml
+++ b/cfgs/tusimple_320x180.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [180, 320]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [180, 320]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [180, 320]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [180, 320]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_480x270.yaml b/cfgs/tusimple_480x270.yaml
index e9077d4..3312074 100644
--- a/cfgs/tusimple_480x270.yaml
+++ b/cfgs/tusimple_480x270.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [270, 480]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [270, 480]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [270, 480]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [270, 480]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_efficientnetb1.yaml b/cfgs/tusimple_efficientnetb1.yaml
index f085635..b1a080a 100644
--- a/cfgs/tusimple_efficientnetb1.yaml
+++ b/cfgs/tusimple_efficientnetb1.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b1'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b1'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_fulltrain.yaml b/cfgs/tusimple_fulltrain.yaml
index 0c0f485..69dfe67 100644
--- a/cfgs/tusimple_fulltrain.yaml
+++ b/cfgs/tusimple_fulltrain.yaml
@@ -1,72 +1,72 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train+val
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple-test"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train+val
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple-test"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_no_share_top_y.yaml b/cfgs/tusimple_no_share_top_y.yaml
index ec81eb2..e1081a5 100644
--- a/cfgs/tusimple_no_share_top_y.yaml
+++ b/cfgs/tusimple_no_share_top_y.yaml
@@ -1,74 +1,74 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    share_top_y: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    share_top_y: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_noaug.yaml b/cfgs/tusimple_noaug.yaml
index 8b4b9db..edd5362 100644
--- a/cfgs/tusimple_noaug.yaml
+++ b/cfgs/tusimple_noaug.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: []
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: []
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_nopretrain.yaml b/cfgs/tusimple_nopretrain.yaml
index 0de222f..ccf039f 100644
--- a/cfgs/tusimple_nopretrain.yaml
+++ b/cfgs/tusimple_nopretrain.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: false 
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: false 
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet34.yaml b/cfgs/tusimple_resnet34.yaml
index 6eafef9..753dc12 100644
--- a/cfgs/tusimple_resnet34.yaml
+++ b/cfgs/tusimple_resnet34.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet34'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet34'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet50.yaml b/cfgs/tusimple_resnet50.yaml
index 58784a8..a32ef90 100644
--- a/cfgs/tusimple_resnet50.yaml
+++ b/cfgs/tusimple_resnet50.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet50'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "/dados/tabelini/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "/dados/tabelini/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet50'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "/dados/tabelini/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "/dados/tabelini/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/lib/config.py b/lib/config.py
index d5d6275..e9405c9 100644
--- a/lib/config.py
+++ b/lib/config.py
@@ -1,45 +1,45 @@
-import yaml
-import torch
-
-import lib.models as models
-import lib.datasets as datasets
-
-
-class Config(object):
-    def __init__(self, config_path):
-        self.config = {}
-        self.load(config_path)
-
-    def load(self, path):
-        with open(path, 'r') as file:
-            self.config_str = file.read()
-        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
-
-    def __repr__(self):
-        return self.config_str
-
-    def get_dataset(self, split):
-        return getattr(datasets,
-                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
-
-    def get_model(self):
-        name = self.config['model']['name']
-        parameters = self.config['model']['parameters']
-        return getattr(models, name)(**parameters)
-
-    def get_optimizer(self, model_parameters):
-        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
-                                                                      **self.config['optimizer']['parameters'])
-
-    def get_lr_scheduler(self, optimizer):
-        return getattr(torch.optim.lr_scheduler,
-                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
-
-    def get_loss_parameters(self):
-        return self.config['loss_parameters']
-
-    def get_test_parameters(self):
-        return self.config['test_parameters']
-
-    def __getitem__(self, item):
-        return self.config[item]
+import yaml
+import torch
+
+import lib.models as models
+import lib.datasets as datasets
+
+
+class Config(object):
+    def __init__(self, config_path):
+        self.config = {}
+        self.load(config_path)
+
+    def load(self, path):
+        with open(path, 'r') as file:
+            self.config_str = file.read()
+        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
+
+    def __repr__(self):
+        return self.config_str
+
+    def get_dataset(self, split):
+        return getattr(datasets,
+                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
+
+    def get_model(self):
+        name = self.config['model']['name']
+        parameters = self.config['model']['parameters']
+        return getattr(models, name)(**parameters)
+
+    def get_optimizer(self, model_parameters):
+        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
+                                                                      **self.config['optimizer']['parameters'])
+
+    def get_lr_scheduler(self, optimizer):
+        return getattr(torch.optim.lr_scheduler,
+                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
+
+    def get_loss_parameters(self):
+        return self.config['loss_parameters']
+
+    def get_test_parameters(self):
+        return self.config['test_parameters']
+
+    def __getitem__(self, item):
+        return self.config[item]
diff --git a/lib/datasets/__init__.py b/lib/datasets/__init__.py
index bc2eb7a..a870757 100644
--- a/lib/datasets/__init__.py
+++ b/lib/datasets/__init__.py
@@ -1,3 +1,3 @@
-from .lane_dataset import LaneDataset
-
-__all__ = ["LaneDataset"]
+from .lane_dataset import LaneDataset
+
+__all__ = ["LaneDataset"]
diff --git a/lib/datasets/elas.py b/lib/datasets/elas.py
index 490f37a..c2a0823 100644
--- a/lib/datasets/elas.py
+++ b/lib/datasets/elas.py
@@ -1,137 +1,137 @@
-import os
-import math
-import random
-
-import cv2
-import numpy as np
-import xmljson
-from scipy import interpolate
-from lxml.etree import fromstring
-
-SPLIT_DIRECTORIES = {
-    'train': [
-        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
-        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
-    ],
-    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
-}
-
-CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
-ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
-
-
-class ELAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.root = root
-        self.split = split
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_directories = SPLIT_DIRECTORIES[split]
-
-        self.img_w, self.img_h = 640, 480
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-        self.class_icons = {
-            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
-            for cls_id in ID_TO_CATEGORY
-        }
-
-    def get_class_icon(self, cls_id):
-        return self.class_icons[cls_id]
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def interp_lane(self, lane, ys, step=10):
-        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
-        if len(pts) <= 1:
-            return None
-        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
-        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
-        interp_xs = interpolate.splev(interp_ys, spline)
-
-        return list(zip(interp_xs, interp_ys))
-
-    def load_dir_annotations(self, dataset_dir):
-        annotations = []
-        max_points = 0
-        max_lanes = 0
-
-        # read config.xml
-        config_fname = os.path.join(dataset_dir, 'config.xml')
-        if not os.path.isfile(config_fname):
-            raise Exception('config.xml not found: {}'.format(config_fname))
-        with open(config_fname, 'r') as hf:
-            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
-
-        # read ground truth
-        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
-        if not os.path.isfile(gt_fname):
-            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
-        with open(gt_fname, 'r') as hf:
-            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
-
-        # read frame annotations
-        for frame in gt['frames']['frame']:
-            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
-
-            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
-            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
-            pts = ['p1', 'p2', 'p3', 'p4']
-            lanes = []
-            categories = []
-            for side in ['Left', 'Right']:
-                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
-                lane = self.interp_lane(lane, ys)
-                if lane is None:
-                    continue
-                max_points = max(max_points, len(lane))
-                lanes.append(lane)
-                category = str(frame['@lmt{}'.format(side)])
-                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
-            max_lanes = max(max_lanes, len(lanes))
-            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
-
-        return annotations, max_points, max_lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        for directory in self.anno_directories:
-            dir_path = os.path.join(self.root, directory)
-            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
-
-            self.annotations.extend(dir_annos)
-            self.max_points = max(self.max_points, dir_max_points)
-            self.max_lanes = max(self.max_lanes, dir_max_lanes)
-
-        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
-                                                                            self.max_lanes))
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import math
+import random
+
+import cv2
+import numpy as np
+import xmljson
+from scipy import interpolate
+from lxml.etree import fromstring
+
+SPLIT_DIRECTORIES = {
+    'train': [
+        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
+        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
+    ],
+    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
+}
+
+CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
+ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
+
+
+class ELAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.root = root
+        self.split = split
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_directories = SPLIT_DIRECTORIES[split]
+
+        self.img_w, self.img_h = 640, 480
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+        self.class_icons = {
+            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
+            for cls_id in ID_TO_CATEGORY
+        }
+
+    def get_class_icon(self, cls_id):
+        return self.class_icons[cls_id]
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def interp_lane(self, lane, ys, step=10):
+        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
+        if len(pts) <= 1:
+            return None
+        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
+        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
+        interp_xs = interpolate.splev(interp_ys, spline)
+
+        return list(zip(interp_xs, interp_ys))
+
+    def load_dir_annotations(self, dataset_dir):
+        annotations = []
+        max_points = 0
+        max_lanes = 0
+
+        # read config.xml
+        config_fname = os.path.join(dataset_dir, 'config.xml')
+        if not os.path.isfile(config_fname):
+            raise Exception('config.xml not found: {}'.format(config_fname))
+        with open(config_fname, 'r') as hf:
+            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
+
+        # read ground truth
+        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
+        if not os.path.isfile(gt_fname):
+            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
+        with open(gt_fname, 'r') as hf:
+            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
+
+        # read frame annotations
+        for frame in gt['frames']['frame']:
+            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
+
+            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
+            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
+            pts = ['p1', 'p2', 'p3', 'p4']
+            lanes = []
+            categories = []
+            for side in ['Left', 'Right']:
+                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
+                lane = self.interp_lane(lane, ys)
+                if lane is None:
+                    continue
+                max_points = max(max_points, len(lane))
+                lanes.append(lane)
+                category = str(frame['@lmt{}'.format(side)])
+                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
+            max_lanes = max(max_lanes, len(lanes))
+            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
+
+        return annotations, max_points, max_lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        for directory in self.anno_directories:
+            dir_path = os.path.join(self.root, directory)
+            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
+
+            self.annotations.extend(dir_annos)
+            self.max_points = max(self.max_points, dir_max_points)
+            self.max_lanes = max(self.max_lanes, dir_max_lanes)
+
+        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
+                                                                            self.max_lanes))
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..1f520dc 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -1,239 +1,239 @@
-import cv2
-import numpy as np
-import imgaug.augmenters as iaa
-from imgaug.augmenters import Resize
-from torchvision.transforms import ToTensor
-from torch.utils.data.dataset import Dataset
-from imgaug.augmentables.lines import LineString, LineStringsOnImage
-
-from .elas import ELAS
-from .llamas import LLAMAS
-from .tusimple import TuSimple
-from .nolabel_dataset import NoLabelDataset
-
-GT_COLOR = (255, 0, 0)
-PRED_HIT_COLOR = (0, 255, 0)
-PRED_MISS_COLOR = (0, 0, 255)
-IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
-IMAGENET_STD = np.array([0.229, 0.224, 0.225])
-
-
-class LaneDataset(Dataset):
-    def __init__(self,
-                 dataset='tusimple',
-                 augmentations=None,
-                 normalize=False,
-                 split='train',
-                 img_size=(360, 640),
-                 aug_chance=1.,
-                 **kwargs):
-        super(LaneDataset, self).__init__()
-        if dataset == 'tusimple':
-            self.dataset = TuSimple(split=split, **kwargs)
-        elif dataset == 'llamas':
-            self.dataset = LLAMAS(split=split, **kwargs)
-        elif dataset == 'elas':
-            self.dataset = ELAS(split=split, **kwargs)
-        elif dataset == 'nolabel_dataset':
-            self.dataset = NoLabelDataset(**kwargs)
-        else:
-            raise NotImplementedError()
-
-        self.transform_annotations()
-        self.img_h, self.img_w = img_size
-
-        if augmentations is not None:
-            # add augmentations
-            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
-                             for aug in augmentations]  # add augmentation
-
-        self.normalize = normalize
-        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
-        self.to_tensor = ToTensor()
-        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
-        self.max_lanes = self.dataset.max_lanes
-
-    def transform_annotation(self, anno, img_wh=None):
-        if img_wh is None:
-            img_h = self.dataset.get_img_heigth(anno['path'])
-            img_w = self.dataset.get_img_width(anno['path'])
-        else:
-            img_w, img_h = img_wh
-
-        old_lanes = anno['lanes']
-        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
-        old_lanes = zip(old_lanes, categories)
-        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
-        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
-        lanes[:, 0] = 0
-        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
-        for lane_pos, (lane, category) in enumerate(old_lanes):
-            lower, upper = lane[0][1], lane[-1][1]
-            xs = np.array([p[0] for p in lane]) / img_w
-            ys = np.array([p[1] for p in lane]) / img_h
-            lanes[lane_pos, 0] = category
-            lanes[lane_pos, 1] = lower / img_h
-            lanes[lane_pos, 2] = upper / img_h
-            lanes[lane_pos, 3:3 + len(xs)] = xs
-            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
-
-        new_anno = {
-            'path': anno['path'],
-            'label': lanes,
-            'old_anno': anno,
-            'categories': [cat for _, cat in old_lanes]
-        }
-
-        return new_anno
-
-    @property
-    def annotations(self):
-        return self.dataset.annotations
-
-    def transform_annotations(self):
-        print('Transforming annotations...')
-        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
-        print('Done.')
-
-    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
-        if img is None:
-            img, label, _ = self.__getitem__(idx, transform=True)
-            # Tensor to opencv image
-            img = img.permute(1, 2, 0).numpy()
-            # Unnormalize
-            if self.normalize:
-                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
-            img = (img * 255).astype(np.uint8)
-        else:
-            _, label, _ = self.__getitem__(idx)
-
-        img_h, img_w, _ = img.shape
-
-        # Draw label
-        for i, lane in enumerate(label):
-            if lane[0] == 0:  # Skip invalid lanes
-                continue
-            lane = lane[3:]  # remove conf, upper and lower positions
-            xs = lane[:len(lane) // 2]
-            ys = lane[len(lane) // 2:]
-            ys = ys[xs >= 0]
-            xs = xs[xs >= 0]
-
-            # draw GT points
-            for p in zip(xs, ys):
-                p = (int(p[0] * img_w), int(p[1] * img_h))
-                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
-
-            # draw GT lane ID
-            cv2.putText(img,
-                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
-                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                        fontScale=1,
-                        color=(0, 255, 0))
-
-        if pred is None:
-            return img
-
-        # Draw predictions
-        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
-        matches, accs, _ = self.dataset.get_metrics(pred, idx)
-        overlay = img.copy()
-        for i, lane in enumerate(pred):
-            if matches[i]:
-                color = PRED_HIT_COLOR
-            else:
-                color = PRED_MISS_COLOR
-            lane = lane[1:]  # remove conf
-            lower, upper = lane[0], lane[1]
-            lane = lane[2:]  # remove upper, lower positions
-
-            # generate points from the polynomial
-            ys = np.linspace(lower, upper, num=100)
-            points = np.zeros((len(ys), 2), dtype=np.int32)
-            points[:, 1] = (ys * img_h).astype(int)
-            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
-            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
-
-            # draw lane with a polyline on the overlay
-            for current_point, next_point in zip(points[:-1], points[1:]):
-                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
-
-            # draw class icon
-            if cls_pred is not None and len(points) > 0:
-                class_icon = self.dataset.get_class_icon(cls_pred[i])
-                class_icon = cv2.resize(class_icon, (32, 32))
-                mid = tuple(points[len(points) // 2] - 60)
-                x, y = mid
-
-                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
-
-            # draw lane ID
-            if len(points) > 0:
-                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
-
-            # draw lane accuracy
-            if len(points) > 0:
-                cv2.putText(img,
-                            '{:.2f}'.format(accs[i] * 100),
-                            tuple(points[len(points) // 2] - 30),
-                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                            fontScale=.75,
-                            color=color)
-        # Add lanes overlay
-        w = 0.6
-        img = ((1. - w) * img + w * overlay).astype(np.uint8)
-
-        return img
-
-    def lane_to_linestrings(self, lanes):
-        lines = []
-        for lane in lanes:
-            lines.append(LineString(lane))
-
-        return lines
-
-    def linestrings_to_lanes(self, lines):
-        lanes = []
-        for line in lines:
-            lanes.append(line.coords)
-
-        return lanes
-
-    def __getitem__(self, idx, transform=True):
-        item = self.dataset[idx]
-        img = cv2.imread(item['path'])
-        label = item['label']
-        if transform:
-            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
-            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
-            img, line_strings = self.transform(image=img, line_strings=line_strings)
-            line_strings.clip_out_of_image_()
-            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
-            new_anno['categories'] = item['categories']
-            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
-
-        img = img / 255.
-        if self.normalize:
-            img = (img - IMAGENET_MEAN) / IMAGENET_STD
-        img = self.to_tensor(img.astype(np.float32))
-        return (img, label, idx)
-
-    def __len__(self):
-        return len(self.dataset)
-
-
-def main():
-    import torch
-    from lib.config import Config
-    np.random.seed(0)
-    torch.manual_seed(0)
-    cfg = Config('config.yaml')
-    train_dataset = cfg.get_dataset('train')
-    for idx in range(len(train_dataset)):
-        img = train_dataset.draw_annotation(idx)
-        cv2.imshow('sample', img)
-        cv2.waitKey(0)
-
-
-if __name__ == "__main__":
-    main()
+import cv2
+import numpy as np
+import imgaug.augmenters as iaa
+from imgaug.augmenters import Resize
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+from imgaug.augmentables.lines import LineString, LineStringsOnImage
+
+from .elas import ELAS
+from .llamas import LLAMAS
+from .tusimple import TuSimple
+from .nolabel_dataset import NoLabelDataset
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+
+class LaneDataset(Dataset):
+    def __init__(self,
+                 dataset='tusimple',
+                 augmentations=None,
+                 normalize=False,
+                 split='train',
+                 img_size=(360, 640),
+                 aug_chance=1.,
+                 **kwargs):
+        super(LaneDataset, self).__init__()
+        if dataset == 'tusimple':
+            self.dataset = TuSimple(split=split, **kwargs)
+        elif dataset == 'llamas':
+            self.dataset = LLAMAS(split=split, **kwargs)
+        elif dataset == 'elas':
+            self.dataset = ELAS(split=split, **kwargs)
+        elif dataset == 'nolabel_dataset':
+            self.dataset = NoLabelDataset(**kwargs)
+        else:
+            raise NotImplementedError()
+
+        self.transform_annotations()
+        self.img_h, self.img_w = img_size
+
+        if augmentations is not None:
+            # add augmentations
+            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
+                             for aug in augmentations]  # add augmentation
+
+        self.normalize = normalize
+        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
+        self.to_tensor = ToTensor()
+        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
+        self.max_lanes = self.dataset.max_lanes
+
+    def transform_annotation(self, anno, img_wh=None):
+        if img_wh is None:
+            img_h = self.dataset.get_img_heigth(anno['path'])
+            img_w = self.dataset.get_img_width(anno['path'])
+        else:
+            img_w, img_h = img_wh
+
+        old_lanes = anno['lanes']
+        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
+        old_lanes = zip(old_lanes, categories)
+        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
+        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
+        lanes[:, 0] = 0
+        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
+        for lane_pos, (lane, category) in enumerate(old_lanes):
+            lower, upper = lane[0][1], lane[-1][1]
+            xs = np.array([p[0] for p in lane]) / img_w
+            ys = np.array([p[1] for p in lane]) / img_h
+            lanes[lane_pos, 0] = category
+            lanes[lane_pos, 1] = lower / img_h
+            lanes[lane_pos, 2] = upper / img_h
+            lanes[lane_pos, 3:3 + len(xs)] = xs
+            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
+
+        new_anno = {
+            'path': anno['path'],
+            'label': lanes,
+            'old_anno': anno,
+            'categories': [cat for _, cat in old_lanes]
+        }
+
+        return new_anno
+
+    @property
+    def annotations(self):
+        return self.dataset.annotations
+
+    def transform_annotations(self):
+        print('Transforming annotations...')
+        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
+        print('Done.')
+
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+        if img is None:
+            img, label, _ = self.__getitem__(idx, transform=True)
+            # Tensor to opencv image
+            img = img.permute(1, 2, 0).numpy()
+            # Unnormalize
+            if self.normalize:
+                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+            img = (img * 255).astype(np.uint8)
+        else:
+            _, label, _ = self.__getitem__(idx)
+
+        img_h, img_w, _ = img.shape
+
+        # Draw label
+        for i, lane in enumerate(label):
+            if lane[0] == 0:  # Skip invalid lanes
+                continue
+            lane = lane[3:]  # remove conf, upper and lower positions
+            xs = lane[:len(lane) // 2]
+            ys = lane[len(lane) // 2:]
+            ys = ys[xs >= 0]
+            xs = xs[xs >= 0]
+
+            # draw GT points
+            for p in zip(xs, ys):
+                p = (int(p[0] * img_w), int(p[1] * img_h))
+                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
+
+            # draw GT lane ID
+            cv2.putText(img,
+                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
+                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                        fontScale=1,
+                        color=(0, 255, 0))
+
+        if pred is None:
+            return img
+
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        matches, accs, _ = self.dataset.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+            if matches[i]:
+                color = PRED_HIT_COLOR
+            else:
+                color = PRED_MISS_COLOR
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(accs[i] * 100),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+    def lane_to_linestrings(self, lanes):
+        lines = []
+        for lane in lanes:
+            lines.append(LineString(lane))
+
+        return lines
+
+    def linestrings_to_lanes(self, lines):
+        lanes = []
+        for line in lines:
+            lanes.append(line.coords)
+
+        return lanes
+
+    def __getitem__(self, idx, transform=True):
+        item = self.dataset[idx]
+        img = cv2.imread(item['path'])
+        label = item['label']
+        if transform:
+            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
+            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
+            img, line_strings = self.transform(image=img, line_strings=line_strings)
+            line_strings.clip_out_of_image_()
+            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
+            new_anno['categories'] = item['categories']
+            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
+
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, label, idx)
+
+    def __len__(self):
+        return len(self.dataset)
+
+
+def main():
+    import torch
+    from lib.config import Config
+    np.random.seed(0)
+    torch.manual_seed(0)
+    cfg = Config('config.yaml')
+    train_dataset = cfg.get_dataset('train')
+    for idx in range(len(train_dataset)):
+        img = train_dataset.draw_annotation(idx)
+        cv2.imshow('sample', img)
+        cv2.waitKey(0)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/lib/datasets/llamas.py b/lib/datasets/llamas.py
index 595e17b..aba4654 100644
--- a/lib/datasets/llamas.py
+++ b/lib/datasets/llamas.py
@@ -1,451 +1,451 @@
-import os
-import json
-import pickle as pkl
-
-import numpy as np
-from progressbar import progressbar
-
-TRAIN_LABELS_DIR = 'labels/train'
-TEST_LABELS_DIR = 'labels/valid'
-SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
-
-
-class LLAMAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.split = split
-        self.root = root
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
-
-        self.img_w, self.img_h = 1276, 717
-        self.offset = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def get_img_path(self, json_path):
-        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
-        base_name = '/'.join(json_path.split('/')[-3:])
-        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
-        return image_path
-
-    def get_json_paths(self):
-        json_paths = []
-        for root, dirs, files in os.walk(self.labels_dir):
-            for file in files:
-                if file.endswith(".json"):
-                    json_paths.append(os.path.join(root, file))
-        return json_paths
-
-    def load_annotations(self):
-        # Waiting for the dataset to load is tedious, let's cache it
-        os.makedirs('cache', exist_ok=True)
-        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
-        if os.path.exists(cache_path):
-            with open(cache_path, 'rb') as cache_file:
-                self.annotations = pkl.load(cache_file)
-                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
-                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
-                return
-
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        print("Searching annotation files...")
-        json_paths = self.get_json_paths()
-        print('{} annotations found.'.format(len(json_paths)))
-
-        for json_path in progressbar(json_paths):
-            lanes = get_horizontal_values_for_four_lanes(json_path)
-            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
-            lanes = [lane for lane in lanes if len(lane) > 0]
-            relative_path = self.get_img_path(json_path)
-            img_path = os.path.join(self.root, relative_path)
-            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
-            self.max_lanes = max(self.max_lanes, len(lanes))
-            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
-
-        with open(cache_path, 'wb') as cache_file:
-            pkl.dump(self.annotations, cache_file)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
-
-
-# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
-# Its license is copied here
-
-# ##### Begin License ######
-# MIT License
-
-# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
-
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-
-# The above copyright notice and this permission notice shall be included in all
-# copies or substantial portions of the Software.
-
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# ##### End License ######
-
-# Start code under the previous license
-
-
-def _extend_lane(lane, projection_matrix):
-    """Extends marker closest to the camera
-
-    Adds an extra marker that reaches the end of the image
-
-    Parameters
-    ----------
-    lane : iterable of markers
-    projection_matrix : 3x3 projection matrix
-    """
-    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
-    # z is the orthongal distance to the car. It's good enough
-
-    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
-    # e.g., horizontal markers which need to be filtered
-    filtered_markers = filter(
-        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
-        lane['markers'])
-    # might be the first marker in the list but not guaranteed
-    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
-
-    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
-        return lane
-
-    # World marker extension approximation
-    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-
-    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
-    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
-
-    # Pixel marker extension approximation
-    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
-        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
-    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
-        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
-
-    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
-    if pixel_zero_x < 0:
-        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
-        new_pixel_point = (0, left_y)
-    elif pixel_zero_x > 1276:
-        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
-        new_pixel_point = (1276, right_y)
-    else:
-        new_pixel_point = (pixel_zero_x, 716)
-
-    new_marker = {
-        'lane_marker_id': 'FAKE',
-        'world_end': {
-            'x': closest_marker['world_start']['x'],
-            'y': closest_marker['world_start']['y'],
-            'z': closest_marker['world_start']['z']
-        },
-        'world_start': {
-            'x': zero_x,
-            'y': zero_y,
-            'z': 1
-        },
-        'pixel_end': {
-            'x': closest_marker['pixel_start']['x'],
-            'y': closest_marker['pixel_start']['y']
-        },
-        'pixel_start': {
-            'x': ir(new_pixel_point[0]),
-            'y': ir(new_pixel_point[1])
-        }
-    }
-    lane['markers'].insert(0, new_marker)
-
-    return lane
-
-
-class SplineCreator():
-    """
-    For each lane divder
-      - all lines are projected
-      - linearly interpolated to limit oscillations
-      - interpolated by a spline
-      - subsampled to receive individual pixel values
-
-    The spline creation can be optimized!
-      - Better spline parameters
-      - Extend lowest marker to reach bottom of image would also help
-      - Extending last marker may in some cases be interesting too
-    Any help is welcome.
-
-    Call create_all_points and get the points in self.sampled_points
-    It has an x coordinate for each value for each lane
-
-    """
-    def __init__(self, json_path):
-        self.json_path = json_path
-        self.json_content = read_json(json_path)
-        self.lanes = self.json_content['lanes']
-        self.lane_marker_points = {}
-        self.sampled_points = {}  # <--- the interesting part
-        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
-
-    def _sample_points(self, lane, ypp=5, between_markers=True):
-        """ Markers are given by start and endpoint. This one adds extra points
-        which need to be considered for the interpolation. Otherwise the spline
-        could arbitrarily oscillate between start and end of the individual markers
-
-        Parameters
-        ----------
-        lane: polyline, in theory but there are artifacts which lead to inconsistencies
-              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
-        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
-        between_markers : bool, interpolates inbetween dashes
-
-        Notes
-        -----
-        Especially, adding points in the lower parts of the image (high y-values) because
-        the start and end points are too sparse.
-        Removing upper lane markers that have starting and end points mapped into the same pixel.
-        """
-
-        # Collect all x values from all markers along a given line. There may be multiple
-        # intersecting markers, i.e., multiple entries for some y values
-        x_values = [[] for i in range(717)]
-        for marker in lane['markers']:
-            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
-
-            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
-            if height > 2:
-                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
-                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
-                for i in range(height + 1):
-                    x = marker['pixel_start']['x'] + slope * step_size * i
-                    y = marker['pixel_start']['y'] - step_size * i
-                    x_values[ir(y)].append(ir(x))
-
-        # Calculate average x values for each y value
-        for y, xs in enumerate(x_values):
-            if not xs:
-                x_values[y] = -1
-            else:
-                x_values[y] = sum(xs) / float(len(xs))
-
-        # In the following, we will only interpolate between markers if needed
-        if not between_markers:
-            return x_values  # TODO ypp
-
-        # # interpolate between markers
-        current_y = 0
-        while x_values[current_y] == -1:  # skip missing first entries
-            current_y += 1
-
-        # Also possible using numpy.interp when accounting for beginning and end
-        next_set_y = 0
-        try:
-            while current_y < 717:
-                if x_values[current_y] != -1:  # set. Nothing to be done
-                    current_y += 1
-                    continue
-
-                # Finds target x value for interpolation
-                while next_set_y <= current_y or x_values[next_set_y] == -1:
-                    next_set_y += 1
-                    if next_set_y >= 717:
-                        raise StopIteration
-
-                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
-                    (next_set_y - current_y + 1)
-                current_y += 1
-
-        except StopIteration:
-            pass  # Done with lane
-
-        return x_values
-
-    def _lane_points_fit(self, lane):
-        # TODO name and docstring
-        """ Fits spline in image space for the markers of a single lane (side)
-
-        Parameters
-        ----------
-        lane: dict as specified in label
-
-        Returns
-        -------
-        Pixel level values for curve along the y-axis
-
-        Notes
-        -----
-        This one can be drastically improved. Probably fairly easy as well.
-        """
-        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
-        lane = _extend_lane(lane, self.json_content['projection_matrix'])
-        sampled_points = self._sample_points(lane, ypp=1)
-        self.sampled_points[lane['lane_id']] = sampled_points
-
-        return sampled_points
-
-    def create_all_points(self, ):
-        """ Creates splines for given label """
-        for lane in self.lanes:
-            self._lane_points_fit(lane)
-
-
-def get_horizontal_values_for_four_lanes(json_path):
-    """ Gets an x value for every y coordinate for l1, l0, r0, r1
-
-    This allows to easily train a direct curve approximation. For each value along
-    the y-axis, the respective x-values can be compared, e.g. squared distance.
-    Missing values are filled with -1. Missing values are values missing from the spline.
-    There is no extrapolation to the image start/end (yet).
-    But values are interpolated between markers. Space between dashed markers is not missing.
-
-    Parameters
-    ----------
-    json_path: str
-               path to label-file
-
-    Returns
-    -------
-    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
-    the number of vertical pixels of the image
-
-    Notes
-    -----
-    The points are currently based on the splines. The splines are interpolated based on the
-    segmentation values. The spline interpolation has lots of room for improvement, e.g.
-    the lines could be interpolated in 3D, a better approach to spline interpolation could
-    be used, there is barely any error checking, sometimes the splines oscillate too much.
-    This was used for a quick poly-line regression training only.
-    """
-
-    sc = SplineCreator(json_path)
-    sc.create_all_points()
-
-    l1 = sc.sampled_points.get('l1', [-1] * 717)
-    l0 = sc.sampled_points.get('l0', [-1] * 717)
-    r0 = sc.sampled_points.get('r0', [-1] * 717)
-    r1 = sc.sampled_points.get('r1', [-1] * 717)
-
-    lanes = [l1, l0, r0, r1]
-    return lanes
-
-
-def _filter_lanes_by_size(label, min_height=40):
-    """ May need some tuning """
-    filtered_lanes = []
-    for lane in label['lanes']:
-        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        if (lane_end - lane_start) < min_height:
-            continue
-        filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _filter_few_markers(label, min_markers=2):
-    """Filter lines that consist of only few markers"""
-    filtered_lanes = []
-    for lane in label['lanes']:
-        if len(lane['markers']) >= min_markers:
-            filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _fix_lane_names(label):
-    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
-
-    # Create mapping
-    l_counter = 0
-    r_counter = 0
-    mapping = {}
-    lane_ids = [lane['lane_id'] for lane in label['lanes']]
-    for key in sorted(lane_ids):
-        if key[0] == 'l':
-            mapping[key] = 'l' + str(l_counter)
-            l_counter += 1
-        if key[0] == 'r':
-            mapping[key] = 'r' + str(r_counter)
-            r_counter += 1
-    for lane in label['lanes']:
-        lane['lane_id'] = mapping[lane['lane_id']]
-
-
-def read_json(json_path, min_lane_height=20):
-    """ Reads and cleans label file information by path"""
-    with open(json_path, 'r') as jf:
-        label_content = json.load(jf)
-
-    _filter_lanes_by_size(label_content, min_height=min_lane_height)
-    _filter_few_markers(label_content, min_markers=2)
-    _fix_lane_names(label_content)
-
-    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
-
-    for lane in content['lanes']:
-        for marker in lane['markers']:
-            for pixel_key in marker['pixel_start'].keys():
-                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
-            for pixel_key in marker['pixel_end'].keys():
-                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
-            for pixel_key in marker['world_start'].keys():
-                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
-            for pixel_key in marker['world_end'].keys():
-                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
-    return content
-
-
-def ir(some_value):
-    """ Rounds and casts to int
-    Useful for pixel values that cannot be floats
-    Parameters
-    ----------
-    some_value : float
-                 numeric value
-    Returns
-    --------
-    Rounded integer
-    Raises
-    ------
-    ValueError for non scalar types
-    """
-    return int(round(some_value))
-
-
-# End code under the previous license
+import os
+import json
+import pickle as pkl
+
+import numpy as np
+from progressbar import progressbar
+
+TRAIN_LABELS_DIR = 'labels/train'
+TEST_LABELS_DIR = 'labels/valid'
+SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
+
+
+class LLAMAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.split = split
+        self.root = root
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
+
+        self.img_w, self.img_h = 1276, 717
+        self.offset = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def get_img_path(self, json_path):
+        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
+        base_name = '/'.join(json_path.split('/')[-3:])
+        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
+        return image_path
+
+    def get_json_paths(self):
+        json_paths = []
+        for root, dirs, files in os.walk(self.labels_dir):
+            for file in files:
+                if file.endswith(".json"):
+                    json_paths.append(os.path.join(root, file))
+        return json_paths
+
+    def load_annotations(self):
+        # Waiting for the dataset to load is tedious, let's cache it
+        os.makedirs('cache', exist_ok=True)
+        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
+        if os.path.exists(cache_path):
+            with open(cache_path, 'rb') as cache_file:
+                self.annotations = pkl.load(cache_file)
+                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
+                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
+                return
+
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        print("Searching annotation files...")
+        json_paths = self.get_json_paths()
+        print('{} annotations found.'.format(len(json_paths)))
+
+        for json_path in progressbar(json_paths):
+            lanes = get_horizontal_values_for_four_lanes(json_path)
+            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
+            lanes = [lane for lane in lanes if len(lane) > 0]
+            relative_path = self.get_img_path(json_path)
+            img_path = os.path.join(self.root, relative_path)
+            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
+            self.max_lanes = max(self.max_lanes, len(lanes))
+            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
+
+        with open(cache_path, 'wb') as cache_file:
+            pkl.dump(self.annotations, cache_file)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
+
+
+# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
+# Its license is copied here
+
+# ##### Begin License ######
+# MIT License
+
+# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# ##### End License ######
+
+# Start code under the previous license
+
+
+def _extend_lane(lane, projection_matrix):
+    """Extends marker closest to the camera
+
+    Adds an extra marker that reaches the end of the image
+
+    Parameters
+    ----------
+    lane : iterable of markers
+    projection_matrix : 3x3 projection matrix
+    """
+    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
+    # z is the orthongal distance to the car. It's good enough
+
+    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
+    # e.g., horizontal markers which need to be filtered
+    filtered_markers = filter(
+        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
+        lane['markers'])
+    # might be the first marker in the list but not guaranteed
+    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
+
+    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
+        return lane
+
+    # World marker extension approximation
+    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+
+    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
+    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
+
+    # Pixel marker extension approximation
+    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
+        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
+    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
+        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
+
+    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
+    if pixel_zero_x < 0:
+        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
+        new_pixel_point = (0, left_y)
+    elif pixel_zero_x > 1276:
+        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
+        new_pixel_point = (1276, right_y)
+    else:
+        new_pixel_point = (pixel_zero_x, 716)
+
+    new_marker = {
+        'lane_marker_id': 'FAKE',
+        'world_end': {
+            'x': closest_marker['world_start']['x'],
+            'y': closest_marker['world_start']['y'],
+            'z': closest_marker['world_start']['z']
+        },
+        'world_start': {
+            'x': zero_x,
+            'y': zero_y,
+            'z': 1
+        },
+        'pixel_end': {
+            'x': closest_marker['pixel_start']['x'],
+            'y': closest_marker['pixel_start']['y']
+        },
+        'pixel_start': {
+            'x': ir(new_pixel_point[0]),
+            'y': ir(new_pixel_point[1])
+        }
+    }
+    lane['markers'].insert(0, new_marker)
+
+    return lane
+
+
+class SplineCreator():
+    """
+    For each lane divder
+      - all lines are projected
+      - linearly interpolated to limit oscillations
+      - interpolated by a spline
+      - subsampled to receive individual pixel values
+
+    The spline creation can be optimized!
+      - Better spline parameters
+      - Extend lowest marker to reach bottom of image would also help
+      - Extending last marker may in some cases be interesting too
+    Any help is welcome.
+
+    Call create_all_points and get the points in self.sampled_points
+    It has an x coordinate for each value for each lane
+
+    """
+    def __init__(self, json_path):
+        self.json_path = json_path
+        self.json_content = read_json(json_path)
+        self.lanes = self.json_content['lanes']
+        self.lane_marker_points = {}
+        self.sampled_points = {}  # <--- the interesting part
+        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
+
+    def _sample_points(self, lane, ypp=5, between_markers=True):
+        """ Markers are given by start and endpoint. This one adds extra points
+        which need to be considered for the interpolation. Otherwise the spline
+        could arbitrarily oscillate between start and end of the individual markers
+
+        Parameters
+        ----------
+        lane: polyline, in theory but there are artifacts which lead to inconsistencies
+              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
+        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
+        between_markers : bool, interpolates inbetween dashes
+
+        Notes
+        -----
+        Especially, adding points in the lower parts of the image (high y-values) because
+        the start and end points are too sparse.
+        Removing upper lane markers that have starting and end points mapped into the same pixel.
+        """
+
+        # Collect all x values from all markers along a given line. There may be multiple
+        # intersecting markers, i.e., multiple entries for some y values
+        x_values = [[] for i in range(717)]
+        for marker in lane['markers']:
+            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
+
+            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
+            if height > 2:
+                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
+                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
+                for i in range(height + 1):
+                    x = marker['pixel_start']['x'] + slope * step_size * i
+                    y = marker['pixel_start']['y'] - step_size * i
+                    x_values[ir(y)].append(ir(x))
+
+        # Calculate average x values for each y value
+        for y, xs in enumerate(x_values):
+            if not xs:
+                x_values[y] = -1
+            else:
+                x_values[y] = sum(xs) / float(len(xs))
+
+        # In the following, we will only interpolate between markers if needed
+        if not between_markers:
+            return x_values  # TODO ypp
+
+        # # interpolate between markers
+        current_y = 0
+        while x_values[current_y] == -1:  # skip missing first entries
+            current_y += 1
+
+        # Also possible using numpy.interp when accounting for beginning and end
+        next_set_y = 0
+        try:
+            while current_y < 717:
+                if x_values[current_y] != -1:  # set. Nothing to be done
+                    current_y += 1
+                    continue
+
+                # Finds target x value for interpolation
+                while next_set_y <= current_y or x_values[next_set_y] == -1:
+                    next_set_y += 1
+                    if next_set_y >= 717:
+                        raise StopIteration
+
+                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
+                    (next_set_y - current_y + 1)
+                current_y += 1
+
+        except StopIteration:
+            pass  # Done with lane
+
+        return x_values
+
+    def _lane_points_fit(self, lane):
+        # TODO name and docstring
+        """ Fits spline in image space for the markers of a single lane (side)
+
+        Parameters
+        ----------
+        lane: dict as specified in label
+
+        Returns
+        -------
+        Pixel level values for curve along the y-axis
+
+        Notes
+        -----
+        This one can be drastically improved. Probably fairly easy as well.
+        """
+        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
+        lane = _extend_lane(lane, self.json_content['projection_matrix'])
+        sampled_points = self._sample_points(lane, ypp=1)
+        self.sampled_points[lane['lane_id']] = sampled_points
+
+        return sampled_points
+
+    def create_all_points(self, ):
+        """ Creates splines for given label """
+        for lane in self.lanes:
+            self._lane_points_fit(lane)
+
+
+def get_horizontal_values_for_four_lanes(json_path):
+    """ Gets an x value for every y coordinate for l1, l0, r0, r1
+
+    This allows to easily train a direct curve approximation. For each value along
+    the y-axis, the respective x-values can be compared, e.g. squared distance.
+    Missing values are filled with -1. Missing values are values missing from the spline.
+    There is no extrapolation to the image start/end (yet).
+    But values are interpolated between markers. Space between dashed markers is not missing.
+
+    Parameters
+    ----------
+    json_path: str
+               path to label-file
+
+    Returns
+    -------
+    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
+    the number of vertical pixels of the image
+
+    Notes
+    -----
+    The points are currently based on the splines. The splines are interpolated based on the
+    segmentation values. The spline interpolation has lots of room for improvement, e.g.
+    the lines could be interpolated in 3D, a better approach to spline interpolation could
+    be used, there is barely any error checking, sometimes the splines oscillate too much.
+    This was used for a quick poly-line regression training only.
+    """
+
+    sc = SplineCreator(json_path)
+    sc.create_all_points()
+
+    l1 = sc.sampled_points.get('l1', [-1] * 717)
+    l0 = sc.sampled_points.get('l0', [-1] * 717)
+    r0 = sc.sampled_points.get('r0', [-1] * 717)
+    r1 = sc.sampled_points.get('r1', [-1] * 717)
+
+    lanes = [l1, l0, r0, r1]
+    return lanes
+
+
+def _filter_lanes_by_size(label, min_height=40):
+    """ May need some tuning """
+    filtered_lanes = []
+    for lane in label['lanes']:
+        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        if (lane_end - lane_start) < min_height:
+            continue
+        filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _filter_few_markers(label, min_markers=2):
+    """Filter lines that consist of only few markers"""
+    filtered_lanes = []
+    for lane in label['lanes']:
+        if len(lane['markers']) >= min_markers:
+            filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _fix_lane_names(label):
+    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
+
+    # Create mapping
+    l_counter = 0
+    r_counter = 0
+    mapping = {}
+    lane_ids = [lane['lane_id'] for lane in label['lanes']]
+    for key in sorted(lane_ids):
+        if key[0] == 'l':
+            mapping[key] = 'l' + str(l_counter)
+            l_counter += 1
+        if key[0] == 'r':
+            mapping[key] = 'r' + str(r_counter)
+            r_counter += 1
+    for lane in label['lanes']:
+        lane['lane_id'] = mapping[lane['lane_id']]
+
+
+def read_json(json_path, min_lane_height=20):
+    """ Reads and cleans label file information by path"""
+    with open(json_path, 'r') as jf:
+        label_content = json.load(jf)
+
+    _filter_lanes_by_size(label_content, min_height=min_lane_height)
+    _filter_few_markers(label_content, min_markers=2)
+    _fix_lane_names(label_content)
+
+    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
+
+    for lane in content['lanes']:
+        for marker in lane['markers']:
+            for pixel_key in marker['pixel_start'].keys():
+                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
+            for pixel_key in marker['pixel_end'].keys():
+                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
+            for pixel_key in marker['world_start'].keys():
+                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
+            for pixel_key in marker['world_end'].keys():
+                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
+    return content
+
+
+def ir(some_value):
+    """ Rounds and casts to int
+    Useful for pixel values that cannot be floats
+    Parameters
+    ----------
+    some_value : float
+                 numeric value
+    Returns
+    --------
+    Rounded integer
+    Raises
+    ------
+    ValueError for non scalar types
+    """
+    return int(round(some_value))
+
+
+# End code under the previous license
diff --git a/lib/datasets/nolabel_dataset.py b/lib/datasets/nolabel_dataset.py
index c8af627..1b3705b 100644
--- a/lib/datasets/nolabel_dataset.py
+++ b/lib/datasets/nolabel_dataset.py
@@ -1,44 +1,44 @@
-import glob
-
-import numpy as np
-
-
-class NoLabelDataset(object):
-    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
-        self.root = root
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = img_w, img_h
-        self.img_ext = img_ext
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        # On NoLabelDataset, always force it
-        self.max_lanes = max_lanes
-        self.max_points = 1
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def load_annotations(self):
-        self.annotations = []
-        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
-        print('Looking for image files with the pattern', pattern)
-        for file in glob.glob(pattern, recursive=True):
-            self.annotations.append({'lanes': [], 'path': file})
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import glob
+
+import numpy as np
+
+
+class NoLabelDataset(object):
+    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
+        self.root = root
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = img_w, img_h
+        self.img_ext = img_ext
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        # On NoLabelDataset, always force it
+        self.max_lanes = max_lanes
+        self.max_points = 1
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def load_annotations(self):
+        self.annotations = []
+        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
+        print('Looking for image files with the pattern', pattern)
+        for file in glob.glob(pattern, recursive=True):
+            self.annotations.append({'lanes': [], 'path': file})
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..55690dc 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -1,137 +1,137 @@
-import os
-import json
-import random
-
-import numpy as np
-from tabulate import tabulate
-
-from utils.lane import LaneEval
-from utils.metric import eval_json
-
-SPLIT_FILES = {
-    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
-    'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
-    'test': ['test_label.json'],
-}
-
-
-class TuSimple(object):
-    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
-        self.split = split
-        self.root = root
-        self.metric = metric
-
-        if split not in SPLIT_FILES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
-
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = 1280, 720
-        self.max_points = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return 720
-
-    def get_img_width(self, path):
-        return 1280
-
-    def get_metrics(self, lanes, idx):
-        label = self.annotations[idx]
-        org_anno = label['old_anno']
-        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
-        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
-
-        return matches, accs, dist
-
-    def pred2lanes(self, path, pred, y_samples):
-        ys = np.array(y_samples) / self.img_h
-        lanes = []
-        for lane in pred:
-            if lane[0] == 0:
-                continue
-            lane_pred = np.polyval(lane[3:], ys) * self.img_w
-            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
-            lanes.append(list(lane_pred))
-
-        return lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        max_lanes = 0
-        for anno_file in self.anno_files:
-            with open(anno_file, 'r') as anno_obj:
-                lines = anno_obj.readlines()
-            for line in lines:
-                data = json.loads(line)
-                y_samples = data['h_samples']
-                gt_lanes = data['lanes']
-                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
-                lanes = [lane for lane in lanes if len(lane) > 0]
-                max_lanes = max(max_lanes, len(lanes))
-                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
-                self.annotations.append({
-                    'path': os.path.join(self.root, data['raw_file']),
-                    'org_path': data['raw_file'],
-                    'org_lanes': gt_lanes,
-                    'lanes': lanes,
-                    'aug': False,
-                    'y_samples': y_samples
-                })
-
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-        print('total annos', len(self.annotations))
-        self.max_lanes = max_lanes
-
-    def transform_annotations(self, transform):
-        self.annotations = list(map(transform, self.annotations))
-
-    def pred2tusimpleformat(self, idx, pred, runtime):
-        runtime *= 1000.  # s to ms
-        img_name = self.annotations[idx]['old_anno']['org_path']
-        h_samples = self.annotations[idx]['old_anno']['y_samples']
-        lanes = self.pred2lanes(img_name, pred, h_samples)
-        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
-        return json.dumps(output)
-
-    def save_tusimple_predictions(self, predictions, runtimes, filename):
-        lines = []
-        for idx in range(len(predictions)):
-            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
-            lines.append(line)
-        with open(filename, 'w') as output_file:
-            output_file.write('\n'.join(lines))
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
-        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
-        if self.metric == 'default':
-            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
-        elif self.metric == 'ours':
-            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
-        table = {}
-        for metric in result:
-            table[metric['name']] = [metric['value']]
-        table = tabulate(table, headers='keys')
-
-        if not only_metrics:
-            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
-            with open(os.path.join(exp_dir, filename), 'w') as out_file:
-                json.dump(result, out_file)
-
-        return table, result
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import json
+import random
+
+import numpy as np
+from tabulate import tabulate
+
+from utils.lane import LaneEval
+from utils.metric import eval_json
+
+SPLIT_FILES = {
+    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
+    'train': ['label_data_0313.json', 'label_data_0601.json'],
+    'val': ['test_label.json'],
+    'test': ['test_label.json'],
+}
+
+
+class TuSimple(object):
+    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
+        self.split = split
+        self.root = root
+        self.metric = metric
+
+        if split not in SPLIT_FILES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
+
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = 1280, 720
+        self.max_points = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return 720
+
+    def get_img_width(self, path):
+        return 1280
+
+    def get_metrics(self, lanes, idx):
+        label = self.annotations[idx]
+        org_anno = label['old_anno']
+        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
+        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
+
+        return matches, accs, dist
+
+    def pred2lanes(self, path, pred, y_samples):
+        ys = np.array(y_samples) / self.img_h
+        lanes = []
+        for lane in pred:
+            if lane[0] == 0:
+                continue
+            lane_pred = np.polyval(lane[3:], ys) * self.img_w
+            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
+            lanes.append(list(lane_pred))
+
+        return lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        max_lanes = 0
+        for anno_file in self.anno_files:
+            with open(anno_file, 'r') as anno_obj:
+                lines = anno_obj.readlines()
+            for line in lines:
+                data = json.loads(line)
+                y_samples = data['h_samples']
+                gt_lanes = data['lanes']
+                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
+                lanes = [lane for lane in lanes if len(lane) > 0]
+                max_lanes = max(max_lanes, len(lanes))
+                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
+                self.annotations.append({
+                    'path': os.path.join(self.root, data['raw_file']),
+                    'org_path': data['raw_file'],
+                    'org_lanes': gt_lanes,
+                    'lanes': lanes,
+                    'aug': False,
+                    'y_samples': y_samples
+                })
+
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+        print('total annos', len(self.annotations))
+        self.max_lanes = max_lanes
+
+    def transform_annotations(self, transform):
+        self.annotations = list(map(transform, self.annotations))
+
+    def pred2tusimpleformat(self, idx, pred, runtime):
+        runtime *= 1000.  # s to ms
+        img_name = self.annotations[idx]['old_anno']['org_path']
+        h_samples = self.annotations[idx]['old_anno']['y_samples']
+        lanes = self.pred2lanes(img_name, pred, h_samples)
+        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
+        return json.dumps(output)
+
+    def save_tusimple_predictions(self, predictions, runtimes, filename):
+        lines = []
+        for idx in range(len(predictions)):
+            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
+            lines.append(line)
+        with open(filename, 'w') as output_file:
+            output_file.write('\n'.join(lines))
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
+        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
+        if self.metric == 'default':
+            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
+        elif self.metric == 'ours':
+            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
+        table = {}
+        for metric in result:
+            table[metric['name']] = [metric['value']]
+        table = tabulate(table, headers='keys')
+
+        if not only_metrics:
+            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
+            with open(os.path.join(exp_dir, filename), 'w') as out_file:
+                json.dump(result, out_file)
+
+        return table, result
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/models.py b/lib/models.py
index 15eb117..ad6e599 100644
--- a/lib/models.py
+++ b/lib/models.py
@@ -1,160 +1,160 @@
-import torch
-import torch.nn as nn
-from torchvision.models import resnet34, resnet50, resnet101
-from efficientnet_pytorch import EfficientNet
-
-
-class OutputLayer(nn.Module):
-    def __init__(self, fc, num_extra):
-        super(OutputLayer, self).__init__()
-        self.regular_outputs_layer = fc
-        self.num_extra = num_extra
-        if num_extra > 0:
-            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
-
-    def forward(self, x):
-        regular_outputs = self.regular_outputs_layer(x)
-        if self.num_extra > 0:
-            extra_outputs = self.extra_outputs_layer(x)
-        else:
-            extra_outputs = None
-
-        return regular_outputs, extra_outputs
-
-
-class PolyRegression(nn.Module):
-    def __init__(self,
-                 num_outputs,
-                 backbone,
-                 pretrained,
-                 curriculum_steps=None,
-                 extra_outputs=0,
-                 share_top_y=True,
-                 pred_category=False):
-        super(PolyRegression, self).__init__()
-        if 'efficientnet' in backbone:
-            if pretrained:
-                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
-            else:
-                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
-            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
-        elif backbone == 'resnet34':
-            self.model = resnet34(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet50':
-            self.model = resnet50(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet101':
-            self.model = resnet101(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        else:
-            raise NotImplementedError()
-
-        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
-        self.share_top_y = share_top_y
-        self.extra_outputs = extra_outputs
-        self.pred_category = pred_category
-        self.sigmoid = nn.Sigmoid()
-
-    def forward(self, x, epoch=None, **kwargs):
-        output, extra_outputs = self.model(x, **kwargs)
-        for i in range(len(self.curriculum_steps)):
-            if epoch is not None and epoch < self.curriculum_steps[i]:
-                output[:, -len(self.curriculum_steps) + i] = 0
-        return output, extra_outputs
-
-    def decode(self, all_outputs, labels, conf_threshold=0.5):
-        outputs, extra_outputs = all_outputs
-        if extra_outputs is not None:
-            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
-            extra_outputs = extra_outputs.argmax(dim=2)
-        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
-        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
-        outputs[outputs[:, :, 0] < conf_threshold] = 0
-
-        if False and self.share_top_y:
-            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
-
-        return outputs, extra_outputs
-
-    def loss(self,
-             outputs,
-             target,
-             conf_weight=1,
-             lower_weight=1,
-             upper_weight=1,
-             cls_weight=1,
-             poly_weight=300,
-             threshold=15 / 720.):
-        pred, extra_outputs = outputs
-        bce = nn.BCELoss()
-        mse = nn.MSELoss()
-        s = nn.Sigmoid()
-        threshold = nn.Threshold(threshold**2, 0.)
-        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
-        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
-        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
-        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
-        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
-
-        if self.share_top_y:
-            # inexistent lanes have -1e-5 as lower
-            # i'm just setting it to a high value here so that the .min below works fine
-            target_lowers[target_lowers < 0] = 1
-            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
-            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
-
-        target_lowers = target_lowers.reshape((-1, 1))
-        pred_lowers = pred_lowers.reshape((-1, 1))
-
-        target_confs = (target_categories > 0).float()
-        valid_lanes_idx = target_confs == 1
-        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
-        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
-        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
-
-        # classification loss
-        if self.pred_category and self.extra_outputs > 0:
-            ce = nn.CrossEntropyLoss()
-            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
-            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
-            pred_categories = pred_categories[target_categories > 0]
-            target_categories = target_categories[target_categories > 0]
-            cls_loss = ce(pred_categories, target_categories - 1)
-        else:
-            cls_loss = 0
-
-        # poly loss calc
-        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
-        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
-        valid_xs = target_xs >= 0
-        pred_polys = pred_polys[valid_lanes_idx_flat]
-        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
-        pred_xs.t_()
-        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
-        pred_xs = (pred_xs.t_() *
-                   weights).t()  # without this, lanes with more points would have more weight on the cost function
-        target_xs = (target_xs.t_() * weights).t()
-        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
-        poly_loss = threshold(
-            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
-
-        # applying weights to partial losses
-        poly_loss = poly_loss * poly_weight
-        lower_loss = lower_loss * lower_weight
-        upper_loss = upper_loss * upper_weight
-        cls_loss = cls_loss * cls_weight
-        conf_loss = bce(pred_confs, target_confs) * conf_weight
-
-        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
-
-        return loss, {
-            'conf': conf_loss,
-            'lower': lower_loss,
-            'upper': upper_loss,
-            'poly': poly_loss,
-            'cls_loss': cls_loss
-        }
+import torch
+import torch.nn as nn
+from torchvision.models import resnet34, resnet50, resnet101
+from efficientnet_pytorch import EfficientNet
+
+
+class OutputLayer(nn.Module):
+    def __init__(self, fc, num_extra):
+        super(OutputLayer, self).__init__()
+        self.regular_outputs_layer = fc
+        self.num_extra = num_extra
+        if num_extra > 0:
+            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
+
+    def forward(self, x):
+        regular_outputs = self.regular_outputs_layer(x)
+        if self.num_extra > 0:
+            extra_outputs = self.extra_outputs_layer(x)
+        else:
+            extra_outputs = None
+
+        return regular_outputs, extra_outputs
+
+
+class PolyRegression(nn.Module):
+    def __init__(self,
+                 num_outputs,
+                 backbone,
+                 pretrained,
+                 curriculum_steps=None,
+                 extra_outputs=0,
+                 share_top_y=True,
+                 pred_category=False):
+        super(PolyRegression, self).__init__()
+        if 'efficientnet' in backbone:
+            if pretrained:
+                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
+            else:
+                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
+            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
+        elif backbone == 'resnet34':
+            self.model = resnet34(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet50':
+            self.model = resnet50(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet101':
+            self.model = resnet101(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        else:
+            raise NotImplementedError()
+
+        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
+        self.share_top_y = share_top_y
+        self.extra_outputs = extra_outputs
+        self.pred_category = pred_category
+        self.sigmoid = nn.Sigmoid()
+
+    def forward(self, x, epoch=None, **kwargs):
+        output, extra_outputs = self.model(x, **kwargs)
+        for i in range(len(self.curriculum_steps)):
+            if epoch is not None and epoch < self.curriculum_steps[i]:
+                output[:, -len(self.curriculum_steps) + i] = 0
+        return output, extra_outputs
+
+    def decode(self, all_outputs, labels, conf_threshold=0.5):
+        outputs, extra_outputs = all_outputs
+        if extra_outputs is not None:
+            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
+            extra_outputs = extra_outputs.argmax(dim=2)
+        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
+        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
+        outputs[outputs[:, :, 0] < conf_threshold] = 0
+
+        if False and self.share_top_y:
+            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
+
+        return outputs, extra_outputs
+
+    def loss(self,
+             outputs,
+             target,
+             conf_weight=1,
+             lower_weight=1,
+             upper_weight=1,
+             cls_weight=1,
+             poly_weight=300,
+             threshold=15 / 720.):
+        pred, extra_outputs = outputs
+        bce = nn.BCELoss()
+        mse = nn.MSELoss()
+        s = nn.Sigmoid()
+        threshold = nn.Threshold(threshold**2, 0.)
+        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
+        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
+        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
+        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
+        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
+
+        if self.share_top_y:
+            # inexistent lanes have -1e-5 as lower
+            # i'm just setting it to a high value here so that the .min below works fine
+            target_lowers[target_lowers < 0] = 1
+            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
+            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
+
+        target_lowers = target_lowers.reshape((-1, 1))
+        pred_lowers = pred_lowers.reshape((-1, 1))
+
+        target_confs = (target_categories > 0).float()
+        valid_lanes_idx = target_confs == 1
+        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
+        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
+        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
+
+        # classification loss
+        if self.pred_category and self.extra_outputs > 0:
+            ce = nn.CrossEntropyLoss()
+            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
+            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
+            pred_categories = pred_categories[target_categories > 0]
+            target_categories = target_categories[target_categories > 0]
+            cls_loss = ce(pred_categories, target_categories - 1)
+        else:
+            cls_loss = 0
+
+        # poly loss calc
+        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
+        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
+        valid_xs = target_xs >= 0
+        pred_polys = pred_polys[valid_lanes_idx_flat]
+        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
+        pred_xs.t_()
+        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
+        pred_xs = (pred_xs.t_() *
+                   weights).t()  # without this, lanes with more points would have more weight on the cost function
+        target_xs = (target_xs.t_() * weights).t()
+        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
+        poly_loss = threshold(
+            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
+
+        # applying weights to partial losses
+        poly_loss = poly_loss * poly_weight
+        lower_loss = lower_loss * lower_weight
+        upper_loss = upper_loss * upper_weight
+        cls_loss = cls_loss * cls_weight
+        conf_loss = bce(pred_confs, target_confs) * conf_weight
+
+        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
+
+        return loss, {
+            'conf': conf_loss,
+            'lower': lower_loss,
+            'upper': upper_loss,
+            'poly': poly_loss,
+            'cls_loss': cls_loss
+        }
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..3ba5b3a 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,16 +1,15 @@
-lxml==4.6.2
-torchvision==0.5.0
-xmljson==0.2.0
-scipy==1.4.1
-tabulate==0.8.6
-numpy==1.18.1
-ujson==1.35
-matplotlib==3.1.3
-imgaug==0.4.0
-tqdm==4.43.0
-opencv_python==4.2.0.32
-efficientnet_pytorch==0.6.3
-torch==1.4.0
-progressbar33==2.4
-PyYAML==5.3.1
-scikit-learn==0.21.3
+lxml==4.6.2
+torchvision==0.5.0
+xmljson==0.2.0
+scipy==1.4.1
+tabulate==0.8.6
+numpy==1.18.1
+ujson==1.35
+matplotlib==3.1.3
+imgaug==0.4.0
+tqdm==4.43.0
+opencv_python==4.2.0.32
+efficientnet_pytorch==0.6.3
+progressbar33==2.4
+PyYAML==5.3.1
+scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..ed3e216 100644
--- a/test.py
+++ b/test.py
@@ -1,166 +1,166 @@
-import os
-import sys
-import random
-import logging
-import argparse
-import subprocess
-from time import time
-
-import cv2
-import numpy as np
-import torch
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
-    if verbose:
-        logging.info("Starting testing.")
-
-    # Test the model
-    if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
-
-    model.eval()
-    criterion_parameters = cfg.get_loss_parameters()
-    test_parameters = cfg.get_test_parameters()
-    criterion = model.loss
-    loss = 0
-    total_iters = 0
-    test_t0 = time()
-    loss_dict = {}
-    with torch.no_grad():
-        for idx, (images, labels, img_idxs) in enumerate(test_loader):
-            if max_batches is not None and idx >= max_batches:
-                break
-            if idx % 1 == 0 and verbose:
-                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
-            images = images.to(device)
-            labels = labels.to(device)
-
-            t0 = time()
-            outputs = model(images)
-            t = time() - t0
-            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            loss += loss_i.item()
-            total_iters += 1
-            for key in loss_dict_i:
-                if key not in loss_dict:
-                    loss_dict[key] = 0
-                loss_dict[key] += loss_dict_i[key]
-
-            outputs = model.decode(outputs, labels, **test_parameters)
-
-            if evaluator is not None:
-                lane_outputs, _ = outputs
-                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
-            if view:
-                outputs, extra_outputs = outputs
-                preds = test_loader.dataset.draw_annotation(
-                    idx,
-                    pred=outputs[0].cpu().numpy(),
-                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
-                cv2.imshow('pred', preds)
-                cv2.waitKey(0)
-
-    if verbose:
-        logging.info("Testing time: {:.4f}".format(time() - test_t0))
-    out_line = []
-    for key in loss_dict:
-        loss_dict[key] /= total_iters
-        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
-    if verbose:
-        logging.info(', '.join(out_line))
-
-    return evaluator, loss / total_iters
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Lane regression")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
-    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
-    parser.add_argument("--view", action="store_true", help="Show predictions")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    # Set up logging
-    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
-
-    # Model
-    model = cfg.get_model().to(device)
-    test_epoch = args.epoch
-
-    # Get data set
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size if args.view is False else 1,
-                                              shuffle=False,
-                                              num_workers=8)
-    # Eval results
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import logging
+import argparse
+import subprocess
+from time import time
+
+import cv2
+import numpy as np
+import torch
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
+    if verbose:
+        logging.info("Starting testing.")
+
+    # Test the model
+    if epoch > 0:
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
+
+    model.eval()
+    criterion_parameters = cfg.get_loss_parameters()
+    test_parameters = cfg.get_test_parameters()
+    criterion = model.loss
+    loss = 0
+    total_iters = 0
+    test_t0 = time()
+    loss_dict = {}
+    with torch.no_grad():
+        for idx, (images, labels, img_idxs) in enumerate(test_loader):
+            if max_batches is not None and idx >= max_batches:
+                break
+            if idx % 1 == 0 and verbose:
+                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
+            images = images.to(device)
+            labels = labels.to(device)
+
+            t0 = time()
+            outputs = model(images)
+            t = time() - t0
+            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            loss += loss_i.item()
+            total_iters += 1
+            for key in loss_dict_i:
+                if key not in loss_dict:
+                    loss_dict[key] = 0
+                loss_dict[key] += loss_dict_i[key]
+
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            if evaluator is not None:
+                lane_outputs, _ = outputs
+                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
+            if view:
+                outputs, extra_outputs = outputs
+                preds = test_loader.dataset.draw_annotation(
+                    idx,
+                    pred=outputs[0].cpu().numpy(),
+                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+                cv2.imshow('pred', preds)
+                cv2.waitKey(0)
+
+    if verbose:
+        logging.info("Testing time: {:.4f}".format(time() - test_t0))
+    out_line = []
+    for key in loss_dict:
+        loss_dict[key] /= total_iters
+        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
+    if verbose:
+        logging.info(', '.join(out_line))
+
+    return evaluator, loss / total_iters
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
+    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
+    parser.add_argument("--view", action="store_true", help="Show predictions")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    # Set up logging
+    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
+
+    # Model
+    model = cfg.get_model().to(device)
+    test_epoch = args.epoch
+
+    # Get data set
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size if args.view is False else 1,
+                                              shuffle=False,
+                                              num_workers=8)
+    # Eval results
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/train.py b/train.py
index 3753aed..d066d7e 100644
--- a/train.py
+++ b/train.py
@@ -1,271 +1,271 @@
-import os
-import sys
-import random
-import shutil
-import logging
-import argparse
-import subprocess
-from time import time
-
-import numpy as np
-import torch
-
-from test import test
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
-    # Get initial train state
-    optimizer = cfg.get_optimizer(model.parameters())
-    scheduler = cfg.get_lr_scheduler(optimizer)
-    starting_epoch = 1
-
-    if train_state is not None:
-        model.load_state_dict(train_state['model'])
-        optimizer.load_state_dict(train_state['optimizer'])
-        scheduler.load_state_dict(train_state['lr_scheduler'])
-        starting_epoch = train_state['epoch'] + 1
-        scheduler.step(starting_epoch)
-
-    # Train the model
-    criterion_parameters = cfg.get_loss_parameters()
-    criterion = model.loss
-    total_step = len(train_loader)
-    ITER_LOG_INTERVAL = cfg['iter_log_interval']
-    ITER_TIME_WINDOW = cfg['iter_time_window']
-    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
-    t0 = time()
-    total_iter = 0
-    iter_times = []
-    logging.info("Starting training.")
-    for epoch in range(starting_epoch, num_epochs + 1):
-        epoch_t0 = time()
-        logging.info("Beginning epoch {}".format(epoch))
-        accum_loss = 0
-        for i, (images, labels, img_idxs) in enumerate(train_loader):
-            total_iter += 1
-            iter_t0 = time()
-            images = images.to(device)
-            labels = labels.to(device)
-
-            # Forward pass
-            outputs = model(images, epoch=epoch)
-            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            accum_loss += loss.item()
-
-            # Backward and optimize
-            optimizer.zero_grad()
-            loss.backward()
-            optimizer.step()
-
-            iter_times.append(time() - iter_t0)
-            if len(iter_times) > 100:
-                iter_times = iter_times[-ITER_TIME_WINDOW:]
-            if (i + 1) % ITER_LOG_INTERVAL == 0:
-                loss_str = ', '.join(
-                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
-                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
-                    epoch,
-                    num_epochs,
-                    i + 1,
-                    total_step,
-                    accum_loss / (i + 1),
-                    loss_str,
-                    np.mean(iter_times),
-                    optimizer.param_groups[0]["lr"],
-                ))
-        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
-        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
-            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
-            save_train_state(model_path, model, optimizer, scheduler, epoch)
-        if val_loader is not None:
-            evaluator = Evaluator(val_loader.dataset, exp_root)
-            evaluator, val_loss = test(
-                model,
-                val_loader,
-                evaluator,
-                None,
-                cfg,
-                view=False,
-                epoch=-1,
-                verbose=False,
-            )
-            _, results = evaluator.eval(label=None, only_metrics=True)
-            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
-            model.train()
-        scheduler.step()
-    logging.info("Training time: {:.4f}".format(time() - t0))
-
-    return model
-
-
-def save_train_state(path, model, optimizer, lr_scheduler, epoch):
-    train_state = {
-        'model': model.state_dict(),
-        'optimizer': optimizer.state_dict(),
-        'lr_scheduler': lr_scheduler.state_dict(),
-        'epoch': epoch
-    }
-
-    torch.save(train_state, path)
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--resume", action="store_true", help="Resume training")
-    parser.add_argument("--validate", action="store_true", help="Validate model during training")
-    parser.add_argument("--deterministic",
-                        action="store_true",
-                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def setup_exp_dir(exps_dir, exp_name, cfg_path):
-    dirs = ["models"]
-    exp_root = os.path.join(exps_dir, exp_name)
-
-    for dirname in dirs:
-        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
-
-    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
-    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
-        file.write(get_code_state())
-
-    return exp_root
-
-
-def get_exp_train_state(exp_root):
-    models_dir = os.path.join(exp_root, "models")
-    models = os.listdir(models_dir)
-    last_epoch, last_modelname = sorted(
-        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
-        key=lambda x: x[0],
-    )[-1]
-    train_state = torch.load(os.path.join(models_dir, last_modelname))
-
-    return train_state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    if args.deterministic:
-        torch.backends.cudnn.deterministic = True
-        torch.backends.cudnn.benchmark = False
-
-    # Set up experiment
-    if not args.resume:
-        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
-    else:
-        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Get data sets
-    train_dataset = cfg.get_dataset("train")
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"]
-
-    # Model
-    model = cfg.get_model().to(device)
-
-    train_state = None
-    if args.resume:
-        train_state = get_exp_train_state(exp_root)
-
-    # Data loader
-    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
-                                               batch_size=batch_size,
-                                               shuffle=True,
-                                               num_workers=8)
-
-    if args.validate:
-        val_dataset = cfg.get_dataset("val")
-        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
-                                                 batch_size=batch_size,
-                                                 shuffle=False,
-                                                 num_workers=8)
-    # Train regressor
-    try:
-        model = train(
-            model,
-            train_loader,
-            exp_root,
-            cfg,
-            val_loader=val_loader if args.validate else None,
-            train_state=train_state,
-        )
-    except KeyboardInterrupt:
-        logging.info("Training session terminated.")
-    test_epoch = -1
-    if cfg['backup'] is not None:
-        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
-
-    # Eval model after training
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size,
-                                              shuffle=False,
-                                              num_workers=8)
-
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import shutil
+import logging
+import argparse
+import subprocess
+from time import time
+
+import numpy as np
+import torch
+
+from test import test
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
+    # Get initial train state
+    optimizer = cfg.get_optimizer(model.parameters())
+    scheduler = cfg.get_lr_scheduler(optimizer)
+    starting_epoch = 1
+
+    if train_state is not None:
+        model.load_state_dict(train_state['model'])
+        optimizer.load_state_dict(train_state['optimizer'])
+        scheduler.load_state_dict(train_state['lr_scheduler'])
+        starting_epoch = train_state['epoch'] + 1
+        scheduler.step(starting_epoch)
+
+    # Train the model
+    criterion_parameters = cfg.get_loss_parameters()
+    criterion = model.loss
+    total_step = len(train_loader)
+    ITER_LOG_INTERVAL = cfg['iter_log_interval']
+    ITER_TIME_WINDOW = cfg['iter_time_window']
+    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
+    t0 = time()
+    total_iter = 0
+    iter_times = []
+    logging.info("Starting training.")
+    for epoch in range(starting_epoch, num_epochs + 1):
+        epoch_t0 = time()
+        logging.info("Beginning epoch {}".format(epoch))
+        accum_loss = 0
+        for i, (images, labels, img_idxs) in enumerate(train_loader):
+            total_iter += 1
+            iter_t0 = time()
+            images = images.to(device)
+            labels = labels.to(device)
+
+            # Forward pass
+            outputs = model(images, epoch=epoch)
+            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            accum_loss += loss.item()
+
+            # Backward and optimize
+            optimizer.zero_grad()
+            loss.backward()
+            optimizer.step()
+
+            iter_times.append(time() - iter_t0)
+            if len(iter_times) > 100:
+                iter_times = iter_times[-ITER_TIME_WINDOW:]
+            if (i + 1) % ITER_LOG_INTERVAL == 0:
+                loss_str = ', '.join(
+                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
+                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
+                    epoch,
+                    num_epochs,
+                    i + 1,
+                    total_step,
+                    accum_loss / (i + 1),
+                    loss_str,
+                    np.mean(iter_times),
+                    optimizer.param_groups[0]["lr"],
+                ))
+        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
+        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
+            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
+            save_train_state(model_path, model, optimizer, scheduler, epoch)
+        if val_loader is not None:
+            evaluator = Evaluator(val_loader.dataset, exp_root)
+            evaluator, val_loss = test(
+                model,
+                val_loader,
+                evaluator,
+                None,
+                cfg,
+                view=False,
+                epoch=-1,
+                verbose=False,
+            )
+            _, results = evaluator.eval(label=None, only_metrics=True)
+            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
+            model.train()
+        scheduler.step()
+    logging.info("Training time: {:.4f}".format(time() - t0))
+
+    return model
+
+
+def save_train_state(path, model, optimizer, lr_scheduler, epoch):
+    train_state = {
+        'model': model.state_dict(),
+        'optimizer': optimizer.state_dict(),
+        'lr_scheduler': lr_scheduler.state_dict(),
+        'epoch': epoch
+    }
+
+    torch.save(train_state, path)
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--resume", action="store_true", help="Resume training")
+    parser.add_argument("--validate", action="store_true", help="Validate model during training")
+    parser.add_argument("--deterministic",
+                        action="store_true",
+                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def setup_exp_dir(exps_dir, exp_name, cfg_path):
+    dirs = ["models"]
+    exp_root = os.path.join(exps_dir, exp_name)
+
+    for dirname in dirs:
+        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
+
+    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
+    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
+        file.write(get_code_state())
+
+    return exp_root
+
+
+def get_exp_train_state(exp_root):
+    models_dir = os.path.join(exp_root, "models")
+    models = os.listdir(models_dir)
+    last_epoch, last_modelname = sorted(
+        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
+        key=lambda x: x[0],
+    )[-1]
+    train_state = torch.load(os.path.join(models_dir, last_modelname))
+
+    return train_state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    if args.deterministic:
+        torch.backends.cudnn.deterministic = True
+        torch.backends.cudnn.benchmark = False
+
+    # Set up experiment
+    if not args.resume:
+        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
+    else:
+        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Get data sets
+    train_dataset = cfg.get_dataset("train")
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    # Model
+    model = cfg.get_model().to(device)
+
+    train_state = None
+    if args.resume:
+        train_state = get_exp_train_state(exp_root)
+
+    # Data loader
+    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
+                                               batch_size=batch_size,
+                                               shuffle=True,
+                                               num_workers=8)
+
+    if args.validate:
+        val_dataset = cfg.get_dataset("val")
+        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
+                                                 batch_size=batch_size,
+                                                 shuffle=False,
+                                                 num_workers=8)
+    # Train regressor
+    try:
+        model = train(
+            model,
+            train_loader,
+            exp_root,
+            cfg,
+            val_loader=val_loader if args.validate else None,
+            train_state=train_state,
+        )
+    except KeyboardInterrupt:
+        logging.info("Training session terminated.")
+    test_epoch = -1
+    if cfg['backup'] is not None:
+        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
+
+    # Eval model after training
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size,
+                                              shuffle=False,
+                                              num_workers=8)
+
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/utils/evaluator.py b/utils/evaluator.py
index b4d51a1..9793857 100644
--- a/utils/evaluator.py
+++ b/utils/evaluator.py
@@ -1,33 +1,33 @@
-import sys
-
-import numpy as np
-
-from lib.datasets.lane_dataset import LaneDataset
-
-EXPS_DIR = 'experiments'
-
-
-class Evaluator(object):
-    def __init__(self, dataset, exp_dir, poly_degree=3):
-        self.dataset = dataset
-        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
-        self.predictions = None
-        self.runtimes = np.zeros(len(dataset))
-        self.loss = np.zeros(len(dataset))
-        self.exp_dir = exp_dir
-        self.new_preds = False
-
-    def add_prediction(self, idx, pred, runtime):
-        if self.predictions is None:
-            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
-        self.predictions[idx, :pred.shape[1], :] = pred
-        self.runtimes[idx] = runtime
-        self.new_preds = True
-
-    def eval(self, **kwargs):
-        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
-
-
-if __name__ == "__main__":
-    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
-    evaluator.tusimple_eval()
+import sys
+
+import numpy as np
+
+from lib.datasets.lane_dataset import LaneDataset
+
+EXPS_DIR = 'experiments'
+
+
+class Evaluator(object):
+    def __init__(self, dataset, exp_dir, poly_degree=3):
+        self.dataset = dataset
+        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
+        self.predictions = None
+        self.runtimes = np.zeros(len(dataset))
+        self.loss = np.zeros(len(dataset))
+        self.exp_dir = exp_dir
+        self.new_preds = False
+
+    def add_prediction(self, idx, pred, runtime):
+        if self.predictions is None:
+            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
+        self.predictions[idx, :pred.shape[1], :] = pred
+        self.runtimes[idx] = runtime
+        self.new_preds = True
+
+    def eval(self, **kwargs):
+        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
+
+
+if __name__ == "__main__":
+    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
+    evaluator.tusimple_eval()
diff --git a/utils/gen_video.py b/utils/gen_video.py
index b4a3b4d..8dff9a8 100644
--- a/utils/gen_video.py
+++ b/utils/gen_video.py
@@ -1,67 +1,67 @@
-import pickle
-import argparse
-
-import cv2
-from tqdm import tqdm
-
-from lib.config import Config
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
-    parser.add_argument("--pred", help=".pkl file to load predictions from")
-    parser.add_argument("--cfg", default="config.yaml", help="Config file")
-    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
-    parser.add_argument("--out", default="video.avi", help="Output filename")
-    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
-
-    return parser.parse_args()
-
-
-def add_cover_img(video, cover_path, frames=90):
-    cover = cv2.imread(cover_path)
-    for _ in range(frames):
-        video.write(cover)
-
-
-def create_video(filename, width, height, fps=30):
-    fourcc = cv2.VideoWriter_fourcc(*'MP42')
-    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
-
-    return video
-
-
-def main():
-    args = parse_args()
-    cfg = Config(args.cfg)
-    dataset = cfg.get_dataset('test')
-    height, width = cfg['datasets']['test']['parameters']['img_size']
-    print('Using resolution {}x{}'.format(width, height))
-    if not args.view:
-        video = create_video(args.out, width, height)
-    # add_cover_img(video, args.cover)
-    with open(args.pred, "rb") as pred_file:
-        predictions = pickle.load(pred_file)
-
-    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
-        if idx < 2200: continue
-        if idx > 3000: break
-        det_pred, cls_pred = pred
-        assert det_pred.shape[0] == 1  # batch size == 1
-        frame = dataset.draw_annotation(idx,
-                                        pred=det_pred[0].cpu().numpy(),
-                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
-        assert frame.shape[:2] == (height, width)
-        if args.view:
-            cv2.imshow('frame', frame)
-            cv2.waitKey(0)
-        else:
-            video.write(frame)
-
-    if not args.view:
-        video.release()
-        print('Video saved as {}'.format(args.out))
-
-
-if __name__ == '__main__':
-    main()
+import pickle
+import argparse
+
+import cv2
+from tqdm import tqdm
+
+from lib.config import Config
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
+    parser.add_argument("--pred", help=".pkl file to load predictions from")
+    parser.add_argument("--cfg", default="config.yaml", help="Config file")
+    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
+    parser.add_argument("--out", default="video.avi", help="Output filename")
+    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
+
+    return parser.parse_args()
+
+
+def add_cover_img(video, cover_path, frames=90):
+    cover = cv2.imread(cover_path)
+    for _ in range(frames):
+        video.write(cover)
+
+
+def create_video(filename, width, height, fps=30):
+    fourcc = cv2.VideoWriter_fourcc(*'MP42')
+    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
+
+    return video
+
+
+def main():
+    args = parse_args()
+    cfg = Config(args.cfg)
+    dataset = cfg.get_dataset('test')
+    height, width = cfg['datasets']['test']['parameters']['img_size']
+    print('Using resolution {}x{}'.format(width, height))
+    if not args.view:
+        video = create_video(args.out, width, height)
+    # add_cover_img(video, args.cover)
+    with open(args.pred, "rb") as pred_file:
+        predictions = pickle.load(pred_file)
+
+    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
+        if idx < 2200: continue
+        if idx > 3000: break
+        det_pred, cls_pred = pred
+        assert det_pred.shape[0] == 1  # batch size == 1
+        frame = dataset.draw_annotation(idx,
+                                        pred=det_pred[0].cpu().numpy(),
+                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
+        assert frame.shape[:2] == (height, width)
+        if args.view:
+            cv2.imshow('frame', frame)
+            cv2.waitKey(0)
+        else:
+            video.write(frame)
+
+    if not args.view:
+        video.release()
+        print('Video saved as {}'.format(args.out))
+
+
+if __name__ == '__main__':
+    main()
diff --git a/utils/lane.py b/utils/lane.py
index 863a92a..6fd2a7d 100644
--- a/utils/lane.py
+++ b/utils/lane.py
@@ -1,133 +1,133 @@
-import numpy as np
-import ujson as json
-from sklearn.linear_model import LinearRegression
-
-
-class LaneEval(object):
-    lr = LinearRegression()
-    pixel_thresh = 20
-    pt_thresh = 0.85
-
-    @staticmethod
-    def get_angle(xs, y_samples):
-        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
-        if len(xs) > 1:
-            LaneEval.lr.fit(ys[:, None], xs)
-            k = LaneEval.lr.coef_[0]
-            theta = np.arctan(k)
-        else:
-            theta = 0
-        return theta
-
-    @staticmethod
-    def line_accuracy(pred, gt, thresh):
-        pred = np.array([p if p >= 0 else -100 for p in pred])
-        gt = np.array([g if g >= 0 else -100 for g in gt])
-        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
-
-    @staticmethod
-    def distances(pred, gt):
-        return np.abs(pred - gt)
-
-    @staticmethod
-    def bench(pred, gt, y_samples, running_time, get_matches=False):
-        if any(len(p) != len(y_samples) for p in pred):
-            raise Exception('Format of lanes error.')
-        if running_time > 20000 or len(gt) + 2 < len(pred):
-            return 0., 0., 1.
-        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
-        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
-        line_accs = []
-        fp, fn = 0., 0.
-        matched = 0.
-        my_matches = [False] * len(pred)
-        my_accs = [0] * len(pred)
-        my_dists = [None] * len(pred)
-        for x_gts, thresh in zip(gt, threshs):
-            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
-            my_accs = np.maximum(my_accs, accs)
-            max_acc = np.max(accs) if len(accs) > 0 else 0.
-            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
-            if len(accs) > 0:
-                my_dists[np.argmax(accs)] = {
-                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
-                    'dists': list(my_dist[np.argmax(accs)])
-                }
-
-            if max_acc < LaneEval.pt_thresh:
-                fn += 1
-            else:
-                my_matches[np.argmax(accs)] = True
-                matched += 1
-            line_accs.append(max_acc)
-        fp = len(pred) - matched
-        if len(gt) > 4 and fn > 0:
-            fn -= 1
-        s = sum(line_accs)
-        if len(gt) > 4:
-            s -= min(line_accs)
-        if get_matches:
-            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
-                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
-        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
-
-    @staticmethod
-    def bench_one_submit(pred_file, gt_file):
-        try:
-            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-        except BaseException as e:
-            raise Exception('Fail to load json file of the prediction.')
-        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-        if len(json_gt) != len(json_pred):
-            raise Exception('We do not get the predictions of all the test tasks')
-        gts = {l['raw_file']: l for l in json_gt}
-        accuracy, fp, fn = 0., 0., 0.
-        run_times = []
-        for pred in json_pred:
-            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
-                raise Exception('raw_file or lanes or run_time not in some predictions.')
-            raw_file = pred['raw_file']
-            pred_lanes = pred['lanes']
-            run_time = pred['run_time']
-            run_times.append(run_time)
-            if raw_file not in gts:
-                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-            gt = gts[raw_file]
-            gt_lanes = gt['lanes']
-            y_samples = gt['h_samples']
-            try:
-                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
-            except BaseException as e:
-                raise Exception('Format of lanes error.')
-            accuracy += a
-            fp += p
-            fn += n
-        num = len(gts)
-        # the first return parameter is the default ranking parameter
-        return json.dumps([{
-            'name': 'Accuracy',
-            'value': accuracy / num,
-            'order': 'desc'
-        }, {
-            'name': 'FP',
-            'value': fp / num,
-            'order': 'asc'
-        }, {
-            'name': 'FN',
-            'value': fn / num,
-            'order': 'asc'
-        }, {
-            'name': 'FPS',
-            'value': 1000. / np.mean(run_times)
-        }])
-
-
-if __name__ == '__main__':
-    import sys
-    try:
-        if len(sys.argv) != 3:
-            raise Exception('Invalid input arguments')
-        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
-    except Exception as e:
-        print(e)
-        # sys.exit(e.message)
+import numpy as np
+import ujson as json
+from sklearn.linear_model import LinearRegression
+
+
+class LaneEval(object):
+    lr = LinearRegression()
+    pixel_thresh = 20
+    pt_thresh = 0.85
+
+    @staticmethod
+    def get_angle(xs, y_samples):
+        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
+        if len(xs) > 1:
+            LaneEval.lr.fit(ys[:, None], xs)
+            k = LaneEval.lr.coef_[0]
+            theta = np.arctan(k)
+        else:
+            theta = 0
+        return theta
+
+    @staticmethod
+    def line_accuracy(pred, gt, thresh):
+        pred = np.array([p if p >= 0 else -100 for p in pred])
+        gt = np.array([g if g >= 0 else -100 for g in gt])
+        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
+
+    @staticmethod
+    def distances(pred, gt):
+        return np.abs(pred - gt)
+
+    @staticmethod
+    def bench(pred, gt, y_samples, running_time, get_matches=False):
+        if any(len(p) != len(y_samples) for p in pred):
+            raise Exception('Format of lanes error.')
+        if running_time > 20000 or len(gt) + 2 < len(pred):
+            return 0., 0., 1.
+        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
+        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
+        line_accs = []
+        fp, fn = 0., 0.
+        matched = 0.
+        my_matches = [False] * len(pred)
+        my_accs = [0] * len(pred)
+        my_dists = [None] * len(pred)
+        for x_gts, thresh in zip(gt, threshs):
+            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
+            my_accs = np.maximum(my_accs, accs)
+            max_acc = np.max(accs) if len(accs) > 0 else 0.
+            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
+            if len(accs) > 0:
+                my_dists[np.argmax(accs)] = {
+                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
+                    'dists': list(my_dist[np.argmax(accs)])
+                }
+
+            if max_acc < LaneEval.pt_thresh:
+                fn += 1
+            else:
+                my_matches[np.argmax(accs)] = True
+                matched += 1
+            line_accs.append(max_acc)
+        fp = len(pred) - matched
+        if len(gt) > 4 and fn > 0:
+            fn -= 1
+        s = sum(line_accs)
+        if len(gt) > 4:
+            s -= min(line_accs)
+        if get_matches:
+            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
+                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
+        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
+
+    @staticmethod
+    def bench_one_submit(pred_file, gt_file):
+        try:
+            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+        except BaseException as e:
+            raise Exception('Fail to load json file of the prediction.')
+        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+        if len(json_gt) != len(json_pred):
+            raise Exception('We do not get the predictions of all the test tasks')
+        gts = {l['raw_file']: l for l in json_gt}
+        accuracy, fp, fn = 0., 0., 0.
+        run_times = []
+        for pred in json_pred:
+            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
+                raise Exception('raw_file or lanes or run_time not in some predictions.')
+            raw_file = pred['raw_file']
+            pred_lanes = pred['lanes']
+            run_time = pred['run_time']
+            run_times.append(run_time)
+            if raw_file not in gts:
+                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+            gt = gts[raw_file]
+            gt_lanes = gt['lanes']
+            y_samples = gt['h_samples']
+            try:
+                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
+            except BaseException as e:
+                raise Exception('Format of lanes error.')
+            accuracy += a
+            fp += p
+            fn += n
+        num = len(gts)
+        # the first return parameter is the default ranking parameter
+        return json.dumps([{
+            'name': 'Accuracy',
+            'value': accuracy / num,
+            'order': 'desc'
+        }, {
+            'name': 'FP',
+            'value': fp / num,
+            'order': 'asc'
+        }, {
+            'name': 'FN',
+            'value': fn / num,
+            'order': 'asc'
+        }, {
+            'name': 'FPS',
+            'value': 1000. / np.mean(run_times)
+        }])
+
+
+if __name__ == '__main__':
+    import sys
+    try:
+        if len(sys.argv) != 3:
+            raise Exception('Invalid input arguments')
+        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
+    except Exception as e:
+        print(e)
+        # sys.exit(e.message)
diff --git a/utils/metric.py b/utils/metric.py
index f2c066d..9fe866e 100644
--- a/utils/metric.py
+++ b/utils/metric.py
@@ -1,177 +1,177 @@
-import argparse
-from pprint import pprint
-
-import cv2
-import numpy as np
-import ujson as json
-from tqdm import tqdm
-from tabulate import tabulate
-from scipy.spatial import distance
-
-
-def show_preds(pred, gt):
-    img = np.zeros((720, 1280, 3), dtype=np.uint8)
-    print(len(gt), 'gts and', len(pred), 'preds')
-    for lane in gt:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
-    for lane in pred:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
-    cv2.imshow('img', img)
-    cv2.waitKey(0)
-
-
-def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
-    pred = np.vstack([pred_x, pred_y]).T
-    gt = np.vstack([gt_x, gt_y]).T
-
-    # pred = pred[pred[:, 0] > 0][:3, :]
-    # gt = gt[gt[:, 0] > 0][:5, :]
-
-    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
-
-    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
-    dist /= np.max(gt_y) - np.min(gt_y)
-    return dist
-
-
-def area_metric(pred, gt, debug=None):
-    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    if len(pred) == 0:
-        return 0., 0., len(gt)
-    line_dists = []
-    fp = 0.
-    matched = 0.
-    gt_matches = [False] * len(gt)
-    pred_matches = [False] * len(pred)
-    pred_dists = [None] * len(pred)
-
-    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
-    for i_gt, gt_points in enumerate(gt):
-        x_gts = [x for x, _ in gt_points]
-        y_gts = [y for _, y in gt_points]
-        for i_pred, pred_points in enumerate(pred):
-            x_preds = [x for x, _ in pred_points]
-            y_preds = [y for _, y in pred_points]
-            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
-
-    best_preds = np.argmin(distances, axis=1)
-    best_gts = np.argmin(distances, axis=0)
-    fp = 0.
-    fn = 0.
-    dist = 0.
-    is_fp = []
-    is_fn = []
-    for i_pred, best_gt in enumerate(best_gts):
-        if best_preds[best_gt] == i_pred:
-            dist += distances[best_gt, i_pred]
-            is_fp.append(False)
-        else:
-            fp += 1
-            is_fp.append(True)
-    for i_gt, best_pred in enumerate(best_preds):
-        if best_gts[best_pred] != i_gt:
-            fn += 1
-            is_fn.append(True)
-        else:
-            is_fn.append(False)
-    if debug:
-        print('is fp')
-        print(is_fp)
-        print('is fn')
-        print(is_fn)
-        print('distances')
-        dists = np.min(distances, axis=0)
-        dists[np.array(is_fp)] = 0
-        print(dists)
-        show_preds(pred, gt)
-
-    return dist, fp, fn
-
-
-def convert_tusimple_format(json_gt):
-    output = []
-    for data in json_gt:
-        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
-                 if any(x > 0 for x in lane)]
-        output.append({
-            'raw_file': data['raw_file'],
-            'run_time': data['run_time'] if 'run_time' in data else None,
-            'lanes': lanes
-        })
-    return output
-
-
-def eval_json(pred_file, gt_file, json_type=None, debug=False):
-    try:
-        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-    except BaseException as e:
-        raise Exception('Fail to load json file of the prediction.')
-    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-    if len(json_gt) != len(json_pred):
-        raise Exception('We do not get the predictions of all the test tasks')
-
-    if json_type == 'tusimple':
-        for gt, pred in zip(json_gt, json_pred):
-            pred['h_samples'] = gt['h_samples']
-        json_gt = convert_tusimple_format(json_gt)
-        json_pred = convert_tusimple_format(json_pred)
-    gts = {l['raw_file']: l for l in json_gt}
-
-    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
-    for pred in tqdm(json_pred):
-        if 'raw_file' not in pred or 'lanes' not in pred:
-            raise Exception('raw_file or lanes not in some predictions.')
-        raw_file = pred['raw_file']
-        pred_lanes = pred['lanes']
-        run_time += pred['run_time'] if 'run_time' in pred else 1.
-
-        if raw_file not in gts:
-            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-        gt = gts[raw_file]
-        gt_lanes = gt['lanes']
-
-        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
-
-        total_distance += distance
-        total_fp += fp
-        total_fn += fn
-
-    num = len(gts)
-    return json.dumps([{
-        'name': 'Distance',
-        'value': total_distance / num,
-        'order': 'desc'
-    }, {
-        'name': 'FP',
-        'value': total_fp,
-        'order': 'asc'
-    }, {
-        'name': 'FN',
-        'value': total_fn,
-        'order': 'asc'
-    }, {
-        'name': 'FPS',
-        'value': 1000. * num / run_time
-    }])
-
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(description="Compute the metrics")
-    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
-    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
-    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
-    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
-    argv = vars(parser.parse_args())
-
-    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
-
-    # pretty-print
-    table = {}
-    for metric in result:
-        if metric['name'] not in table.keys():
-            table[metric['name']] = []
-        table[metric['name']].append(metric['value'])
-    print(tabulate(table, headers='keys'))
+import argparse
+from pprint import pprint
+
+import cv2
+import numpy as np
+import ujson as json
+from tqdm import tqdm
+from tabulate import tabulate
+from scipy.spatial import distance
+
+
+def show_preds(pred, gt):
+    img = np.zeros((720, 1280, 3), dtype=np.uint8)
+    print(len(gt), 'gts and', len(pred), 'preds')
+    for lane in gt:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
+    for lane in pred:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
+    cv2.imshow('img', img)
+    cv2.waitKey(0)
+
+
+def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
+    pred = np.vstack([pred_x, pred_y]).T
+    gt = np.vstack([gt_x, gt_y]).T
+
+    # pred = pred[pred[:, 0] > 0][:3, :]
+    # gt = gt[gt[:, 0] > 0][:5, :]
+
+    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
+
+    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
+    dist /= np.max(gt_y) - np.min(gt_y)
+    return dist
+
+
+def area_metric(pred, gt, debug=None):
+    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    if len(pred) == 0:
+        return 0., 0., len(gt)
+    line_dists = []
+    fp = 0.
+    matched = 0.
+    gt_matches = [False] * len(gt)
+    pred_matches = [False] * len(pred)
+    pred_dists = [None] * len(pred)
+
+    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
+    for i_gt, gt_points in enumerate(gt):
+        x_gts = [x for x, _ in gt_points]
+        y_gts = [y for _, y in gt_points]
+        for i_pred, pred_points in enumerate(pred):
+            x_preds = [x for x, _ in pred_points]
+            y_preds = [y for _, y in pred_points]
+            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
+
+    best_preds = np.argmin(distances, axis=1)
+    best_gts = np.argmin(distances, axis=0)
+    fp = 0.
+    fn = 0.
+    dist = 0.
+    is_fp = []
+    is_fn = []
+    for i_pred, best_gt in enumerate(best_gts):
+        if best_preds[best_gt] == i_pred:
+            dist += distances[best_gt, i_pred]
+            is_fp.append(False)
+        else:
+            fp += 1
+            is_fp.append(True)
+    for i_gt, best_pred in enumerate(best_preds):
+        if best_gts[best_pred] != i_gt:
+            fn += 1
+            is_fn.append(True)
+        else:
+            is_fn.append(False)
+    if debug:
+        print('is fp')
+        print(is_fp)
+        print('is fn')
+        print(is_fn)
+        print('distances')
+        dists = np.min(distances, axis=0)
+        dists[np.array(is_fp)] = 0
+        print(dists)
+        show_preds(pred, gt)
+
+    return dist, fp, fn
+
+
+def convert_tusimple_format(json_gt):
+    output = []
+    for data in json_gt:
+        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
+                 if any(x > 0 for x in lane)]
+        output.append({
+            'raw_file': data['raw_file'],
+            'run_time': data['run_time'] if 'run_time' in data else None,
+            'lanes': lanes
+        })
+    return output
+
+
+def eval_json(pred_file, gt_file, json_type=None, debug=False):
+    try:
+        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+    except BaseException as e:
+        raise Exception('Fail to load json file of the prediction.')
+    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+    if len(json_gt) != len(json_pred):
+        raise Exception('We do not get the predictions of all the test tasks')
+
+    if json_type == 'tusimple':
+        for gt, pred in zip(json_gt, json_pred):
+            pred['h_samples'] = gt['h_samples']
+        json_gt = convert_tusimple_format(json_gt)
+        json_pred = convert_tusimple_format(json_pred)
+    gts = {l['raw_file']: l for l in json_gt}
+
+    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
+    for pred in tqdm(json_pred):
+        if 'raw_file' not in pred or 'lanes' not in pred:
+            raise Exception('raw_file or lanes not in some predictions.')
+        raw_file = pred['raw_file']
+        pred_lanes = pred['lanes']
+        run_time += pred['run_time'] if 'run_time' in pred else 1.
+
+        if raw_file not in gts:
+            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+        gt = gts[raw_file]
+        gt_lanes = gt['lanes']
+
+        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
+
+        total_distance += distance
+        total_fp += fp
+        total_fn += fn
+
+    num = len(gts)
+    return json.dumps([{
+        'name': 'Distance',
+        'value': total_distance / num,
+        'order': 'desc'
+    }, {
+        'name': 'FP',
+        'value': total_fp,
+        'order': 'asc'
+    }, {
+        'name': 'FN',
+        'value': total_fn,
+        'order': 'asc'
+    }, {
+        'name': 'FPS',
+        'value': 1000. * num / run_time
+    }])
+
+
+if __name__ == '__main__':
+    parser = argparse.ArgumentParser(description="Compute the metrics")
+    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
+    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
+    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
+    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
+    argv = vars(parser.parse_args())
+
+    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
+
+    # pretty-print
+    table = {}
+    for metric in result:
+        if metric['name'] not in table.keys():
+            table[metric['name']] = []
+        table[metric['name']].append(metric['value'])
+    print(tabulate(table, headers='keys'))
diff --git a/utils/plot_log.py b/utils/plot_log.py
index ee18cf1..aaba69a 100644
--- a/utils/plot_log.py
+++ b/utils/plot_log.py
@@ -1,161 +1,161 @@
-import os
-import re
-import argparse
-import datetime
-
-import numpy as np
-import matplotlib.dates as mdates
-import matplotlib.colors as colors
-import matplotlib.pyplot as plt
-
-ITER_PATTERN = re.compile(
-    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
-)
-LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
-EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
-EXPS_DIR = '../data_lane-regression/experiments'
-
-# TODO: refactor this file
-
-
-def smooth_curve(xs, factor):
-    smoothed = [None] * len(xs)
-    smoothed[0] = xs[0]
-    for i in range(1, len(xs)):
-        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
-
-    return smoothed
-
-
-def plot_loss(data,
-              fig,
-              ax,
-              label,
-              plot_lr=True,
-              smoothing=0,
-              xaxis='time',
-              only_epoch_end=False,
-              plot_val=False,
-              plot_loss_comps=False):
-    iter_data = data['iter_update']
-    epoch_data = data['epoch_update']
-    now = datetime.datetime.today()
-    if xaxis == 'epoch':
-        if only_epoch_end:
-            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
-        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
-    elif xaxis == 'time':
-        d0 = iter_data[0]['date']
-        x = [now + (d['date'] - d0) for d in iter_data]
-    elif xaxis == 'iter':
-        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
-    loss = [d['loss'] for d in iter_data]
-    if plot_loss_comps:
-        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
-    if plot_val:
-        val_loss = [d['val_loss'] for d in epoch_data]
-        if xaxis == 'epoch':
-            val_loss_x = [d['epoch'] for d in epoch_data]
-        else:
-            val_loss_d0 = epoch_data[0]['date']
-            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
-    loss_smooth = smooth_curve(loss, factor=smoothing)
-    if plot_lr:
-        lr = [d['lr'] for d in iter_data]
-        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
-                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
-        if len(lr_decays) < 10:
-            for epoch, old, new in lr_decays:
-                ax.axvline(x=epoch, linestyle='--')
-        ax.plot(x, lr, label='LR: {}'.format(label))
-    ax.set_yscale('log')
-    ax.set_title('Loss')
-    ax.set_xlabel('Epoch')
-    ax.set_ylabel('Loss')
-    loss_line = ax.plot(x, loss_smooth)[0]
-    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
-    loss_line_color[-1] = 0.5
-    if plot_loss_comps:
-        for loss_comp in loss_comps:
-            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
-            line_color = np.array(colors.to_rgba(line.get_color()))
-            line_color[-1] = 0.5
-            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
-    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
-    if plot_val:
-        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
-    if xaxis == 'time':
-        fig.autofmt_xdate()
-        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
-
-
-def parse_line(line):
-    iter_match = re.match(ITER_PATTERN, line)
-    epoch_match = re.match(EPOCH_PATTERN, line)
-    data = {}
-    if iter_match is not None:
-        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
-        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
-            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
-                loss), float(speed), float(lr)
-        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
-        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
-        data['iter_update'] = {
-            'date': date,
-            'epoch': epoch,
-            'total_epochs': total_epochs,
-            'iter_nb': iter_nb,
-            'total_iters': total_iters,
-            'loss': loss,
-            'speed': date,
-            'loss_comps': loss_comps,
-            'lr': lr,
-        }
-    if epoch_match is not None:
-        date, epoch, _, val_loss = epoch_match.groups()
-        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
-        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
-
-    return data
-
-
-def parse_log(log_path):
-    with open(log_path, 'r') as log_file:
-        lines = [line.rstrip() for line in log_file.readlines()]
-    data = {'iter_update': [], 'epoch_update': []}
-    for line in lines:
-        line_data = parse_line(line)
-        for key in line_data:
-            data[key].append(line_data[key])
-    return data
-
-
-def get_logfilepath(exp_name):
-    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description='Visualization')
-    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
-    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
-    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
-
-    return parser.parse_args()
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    fig, ax = plt.subplots(nrows=1, ncols=1)
-    for exp_name in args.exp_name:
-        log_filepath = get_logfilepath(exp_name)
-        data = parse_log(log_filepath)
-        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
-
-    # Show the major grid lines with dark grey lines
-    plt.grid(b=True, which='major', color='#666666', linestyle='-')
-
-    # Show the minor grid lines with very faint and almost transparent grey lines
-    plt.minorticks_on()
-    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
-    plt.legend()
-    plt.show()
+import os
+import re
+import argparse
+import datetime
+
+import numpy as np
+import matplotlib.dates as mdates
+import matplotlib.colors as colors
+import matplotlib.pyplot as plt
+
+ITER_PATTERN = re.compile(
+    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
+)
+LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
+EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
+EXPS_DIR = '../data_lane-regression/experiments'
+
+# TODO: refactor this file
+
+
+def smooth_curve(xs, factor):
+    smoothed = [None] * len(xs)
+    smoothed[0] = xs[0]
+    for i in range(1, len(xs)):
+        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
+
+    return smoothed
+
+
+def plot_loss(data,
+              fig,
+              ax,
+              label,
+              plot_lr=True,
+              smoothing=0,
+              xaxis='time',
+              only_epoch_end=False,
+              plot_val=False,
+              plot_loss_comps=False):
+    iter_data = data['iter_update']
+    epoch_data = data['epoch_update']
+    now = datetime.datetime.today()
+    if xaxis == 'epoch':
+        if only_epoch_end:
+            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
+        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
+    elif xaxis == 'time':
+        d0 = iter_data[0]['date']
+        x = [now + (d['date'] - d0) for d in iter_data]
+    elif xaxis == 'iter':
+        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
+    loss = [d['loss'] for d in iter_data]
+    if plot_loss_comps:
+        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
+    if plot_val:
+        val_loss = [d['val_loss'] for d in epoch_data]
+        if xaxis == 'epoch':
+            val_loss_x = [d['epoch'] for d in epoch_data]
+        else:
+            val_loss_d0 = epoch_data[0]['date']
+            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
+    loss_smooth = smooth_curve(loss, factor=smoothing)
+    if plot_lr:
+        lr = [d['lr'] for d in iter_data]
+        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
+                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
+        if len(lr_decays) < 10:
+            for epoch, old, new in lr_decays:
+                ax.axvline(x=epoch, linestyle='--')
+        ax.plot(x, lr, label='LR: {}'.format(label))
+    ax.set_yscale('log')
+    ax.set_title('Loss')
+    ax.set_xlabel('Epoch')
+    ax.set_ylabel('Loss')
+    loss_line = ax.plot(x, loss_smooth)[0]
+    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
+    loss_line_color[-1] = 0.5
+    if plot_loss_comps:
+        for loss_comp in loss_comps:
+            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
+            line_color = np.array(colors.to_rgba(line.get_color()))
+            line_color[-1] = 0.5
+            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
+    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
+    if plot_val:
+        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
+    if xaxis == 'time':
+        fig.autofmt_xdate()
+        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
+
+
+def parse_line(line):
+    iter_match = re.match(ITER_PATTERN, line)
+    epoch_match = re.match(EPOCH_PATTERN, line)
+    data = {}
+    if iter_match is not None:
+        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
+        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
+            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
+                loss), float(speed), float(lr)
+        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
+        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
+        data['iter_update'] = {
+            'date': date,
+            'epoch': epoch,
+            'total_epochs': total_epochs,
+            'iter_nb': iter_nb,
+            'total_iters': total_iters,
+            'loss': loss,
+            'speed': date,
+            'loss_comps': loss_comps,
+            'lr': lr,
+        }
+    if epoch_match is not None:
+        date, epoch, _, val_loss = epoch_match.groups()
+        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
+        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
+
+    return data
+
+
+def parse_log(log_path):
+    with open(log_path, 'r') as log_file:
+        lines = [line.rstrip() for line in log_file.readlines()]
+    data = {'iter_update': [], 'epoch_update': []}
+    for line in lines:
+        line_data = parse_line(line)
+        for key in line_data:
+            data[key].append(line_data[key])
+    return data
+
+
+def get_logfilepath(exp_name):
+    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description='Visualization')
+    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
+    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
+    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
+
+    return parser.parse_args()
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    fig, ax = plt.subplots(nrows=1, ncols=1)
+    for exp_name in args.exp_name:
+        log_filepath = get_logfilepath(exp_name)
+        data = parse_log(log_filepath)
+        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
+
+    # Show the major grid lines with dark grey lines
+    plt.grid(b=True, which='major', color='#666666', linestyle='-')
+
+    # Show the minor grid lines with very faint and almost transparent grey lines
+    plt.minorticks_on()
+    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
+    plt.legend()
+    plt.show()
diff --git a/utils/upperbound.py b/utils/upperbound.py
index 78af9b3..1fbce9e 100644
--- a/utils/upperbound.py
+++ b/utils/upperbound.py
@@ -1,44 +1,44 @@
-import sys
-import warnings
-
-import numpy as np
-from progressbar import progressbar
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-warnings.simplefilter('ignore', np.RankWarning)
-
-
-def polyfit_upperbound(dataset, degree):
-    evaluator = Evaluator(dataset, '/tmp', degree)
-    print('Predicting with upperbound...')
-    for i, anno in enumerate(progressbar(dataset.annotations)):
-        label = anno['label']
-        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
-        pred[:, :3] = label[:, :3]
-        for j, lane in enumerate(label):
-            if lane[0] == 0:
-                continue
-            xy = lane[3:]
-            x = xy[:(len(xy) // 2)]
-            y = xy[(len(xy) // 2):]
-            ind = x > 0
-            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
-        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
-    _, result = evaluator.eval(label='upperbound', only_metrics=True)
-
-    return result
-
-
-if __name__ == "__main__":
-    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
-    dataset = cfg.get_dataset('test')
-    for n in range(1, 5 + 1):
-        result = polyfit_upperbound(dataset, n)
-        print('Degree {} upperbound:'.format(n))
-        for metric in result:
-            if metric['name'] == 'Accuracy':
-                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
-            else:
-                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))
+import sys
+import warnings
+
+import numpy as np
+from progressbar import progressbar
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+warnings.simplefilter('ignore', np.RankWarning)
+
+
+def polyfit_upperbound(dataset, degree):
+    evaluator = Evaluator(dataset, '/tmp', degree)
+    print('Predicting with upperbound...')
+    for i, anno in enumerate(progressbar(dataset.annotations)):
+        label = anno['label']
+        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
+        pred[:, :3] = label[:, :3]
+        for j, lane in enumerate(label):
+            if lane[0] == 0:
+                continue
+            xy = lane[3:]
+            x = xy[:(len(xy) // 2)]
+            y = xy[(len(xy) // 2):]
+            ind = x > 0
+            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
+        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
+    _, result = evaluator.eval(label='upperbound', only_metrics=True)
+
+    return result
+
+
+if __name__ == "__main__":
+    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
+    dataset = cfg.get_dataset('test')
+    for n in range(1, 5 + 1):
+        result = polyfit_upperbound(dataset, n)
+        print('Degree {} upperbound:'.format(n))
+        for metric in result:
+            if metric['name'] == 'Accuracy':
+                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
+            else:
+                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))

[2021-08-06 23:29:04,938] [INFO] Starting testing.
[2021-08-06 23:29:06,661] [INFO] Testing iteration: 1/2782
[2021-08-06 23:31:54,041] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-06 23:31:54,041] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-06 23:31:54,041] [INFO] Args:
Namespace(batch_size=1, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-06 23:31:54,853] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..2f03159 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()

[2021-08-06 23:31:54,853] [INFO] Starting testing.
[2021-08-06 23:32:11,538] [INFO] Testing iteration: 1/2782
[2021-08-06 23:32:21,184] [INFO] Testing iteration: 2/2782
[2021-08-06 23:32:22,574] [INFO] Testing iteration: 3/2782
[2021-08-06 23:32:23,886] [INFO] Testing iteration: 4/2782
[2021-08-06 23:32:25,177] [INFO] Testing iteration: 5/2782
[2021-08-06 23:32:26,451] [INFO] Testing iteration: 6/2782
[2021-08-06 23:32:27,768] [INFO] Testing iteration: 7/2782
[2021-08-06 23:32:29,069] [INFO] Testing iteration: 8/2782
[2021-08-06 23:32:30,423] [INFO] Testing iteration: 9/2782
[2021-08-06 23:32:32,279] [INFO] Testing iteration: 10/2782
[2021-08-06 23:32:52,309] [INFO] Testing iteration: 11/2782
[2021-08-06 23:32:53,590] [INFO] Testing iteration: 12/2782
[2021-08-06 23:32:55,335] [INFO] Testing iteration: 13/2782
[2021-08-06 23:32:56,587] [INFO] Testing iteration: 14/2782
[2021-08-06 23:32:57,954] [INFO] Testing iteration: 15/2782
[2021-08-06 23:32:59,560] [INFO] Testing iteration: 16/2782
[2021-08-06 23:33:26,079] [INFO] Testing iteration: 17/2782
[2021-08-06 23:33:27,282] [INFO] Testing iteration: 18/2782
[2021-08-06 23:33:28,483] [INFO] Testing iteration: 19/2782
[2021-08-06 23:33:29,693] [INFO] Testing iteration: 20/2782
[2021-08-06 23:33:30,896] [INFO] Testing iteration: 21/2782
[2021-08-06 23:33:32,262] [INFO] Testing iteration: 22/2782
[2021-08-06 23:33:33,748] [INFO] Testing iteration: 23/2782
[2021-08-06 23:33:35,191] [INFO] Testing iteration: 24/2782
[2021-08-06 23:33:36,359] [INFO] Testing iteration: 25/2782
[2021-08-06 23:33:37,969] [INFO] Testing iteration: 26/2782
[2021-08-06 23:33:39,479] [INFO] Testing iteration: 27/2782
[2021-08-06 23:33:40,672] [INFO] Testing iteration: 28/2782
[2021-08-06 23:33:42,046] [INFO] Testing iteration: 29/2782
[2021-08-06 23:33:43,801] [INFO] Testing iteration: 30/2782
[2021-08-06 23:33:45,484] [INFO] Testing iteration: 31/2782
[2021-08-06 23:33:47,077] [INFO] Testing iteration: 32/2782
[2021-08-06 23:33:48,935] [INFO] Testing iteration: 33/2782
[2021-08-06 23:33:50,214] [INFO] Testing iteration: 34/2782
[2021-08-06 23:33:52,185] [INFO] Testing iteration: 35/2782
[2021-08-06 23:34:30,892] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 159, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 65, in test
    cv2.waitKey(0)
KeyboardInterrupt
[2021-08-06 23:36:16,780] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-06 23:36:16,781] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-06 23:36:16,782] [INFO] Args:
Namespace(batch_size=1, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-06 23:36:17,508] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..f214522 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,9 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+        print("*"*50)
+        print(pred.shape)
+        print("*" * 50)
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..2f03159 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()

[2021-08-06 23:36:17,510] [INFO] Starting testing.
[2021-08-06 23:36:32,505] [INFO] Testing iteration: 1/2782
[2021-08-06 23:38:00,503] [INFO] Testing iteration: 2/2782
[2021-08-06 23:38:02,749] [INFO] Testing iteration: 3/2782
[2021-08-06 23:39:09,722] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 159, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 65, in test
    cv2.waitKey(0)
KeyboardInterrupt
[2021-08-06 23:55:34,980] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-06 23:55:34,980] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-06 23:55:34,981] [INFO] Args:
Namespace(batch_size=1, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-06 23:55:35,543] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..f214522 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,9 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+        print("*"*50)
+        print(pred.shape)
+        print("*" * 50)
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..faadf7e 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),

[2021-08-06 23:55:35,544] [INFO] Starting testing.
[2021-08-06 23:55:50,636] [INFO] Testing iteration: 1/2782
[2021-08-06 23:56:37,279] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 160, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 66, in test
    cv2.waitKey(0)
KeyboardInterrupt
[2021-08-06 23:56:41,189] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-06 23:56:41,190] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-06 23:56:41,192] [INFO] Args:
Namespace(batch_size=1, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-06 23:56:41,754] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..f214522 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,9 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+        print("*"*50)
+        print(pred.shape)
+        print("*" * 50)
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..c72e6b5 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),

[2021-08-06 23:56:41,756] [INFO] Starting testing.
[2021-08-06 23:56:56,072] [INFO] Testing iteration: 1/2782
[2021-08-06 23:59:41,249] [INFO] Testing iteration: 2/2782
[2021-08-07 00:03:45,872] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 160, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 66, in test
    cv2.waitKey(0)
KeyboardInterrupt
[2021-08-07 00:05:17,399] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-07 00:05:17,400] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-07 00:05:17,401] [INFO] Args:
Namespace(batch_size=1, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-07 00:05:17,973] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..f214522 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,9 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+        print("*"*50)
+        print(pred.shape)
+        print("*" * 50)
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/lib/models.py b/lib/models.py
index 15eb117..cf9b8f6 100644
--- a/lib/models.py
+++ b/lib/models.py
@@ -67,6 +67,9 @@ class PolyRegression(nn.Module):
         return output, extra_outputs
 
     def decode(self, all_outputs, labels, conf_threshold=0.5):
+        print("*"*50)
+        print(labels.shape[0])
+        print("*" * 50)
         outputs, extra_outputs = all_outputs
         if extra_outputs is not None:
             extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..c72e6b5 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),

[2021-08-07 00:05:17,974] [INFO] Starting testing.
[2021-08-07 00:05:32,519] [INFO] Testing iteration: 1/2782
[2021-08-07 00:07:07,841] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 160, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 66, in test
    cv2.waitKey(0)
KeyboardInterrupt
[2021-08-08 22:25:39,846] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-08 22:25:39,871] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-08 22:25:39,890] [INFO] Args:
Namespace(batch_size=1, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-08 22:25:44,336] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/.gitignore b/.gitignore
index e4bcbf2..fdf6f3f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,8 +1,8 @@
-__pycache__
-experiments
-.vscode
-venv
-config.yaml
-/datasets/
-lib/nms/build/
-lib/nms/dist/
+__pycache__
+experiments
+.vscode
+venv
+config.yaml
+/datasets/
+lib/nms/build/
+lib/nms/dist/
diff --git a/LICENSE b/LICENSE
index f8fe53d..33d52bc 100644
--- a/LICENSE
+++ b/LICENSE
@@ -1,21 +1,21 @@
-MIT License
-
-Copyright (c) 2020 Lucas Tabelini Torres
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+MIT License
+
+Copyright (c) 2020 Lucas Tabelini Torres
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
diff --git a/README.md b/README.md
index b4af404..d49fcb0 100644
--- a/README.md
+++ b/README.md
@@ -1,165 +1,166 @@
-<div align="center">
-
-# PolyLaneNet
-![Method overview](figures/method-overview.png "Method overview")
-</div>
-
-## Description
-Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
-[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
-
-**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
-
-## Table of Contents
-1. [Installation](#installation)
-2. [Usage](#usage)
-3. [Reproducing the paper results](#reproducing)
-
-<a name="installation"/>
-
-### Installation
-The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
-
-Install dependencies:
-```
-pip install -r requirements.txt
-```
-
-<a name="usage"/>
-
-### Usage
-#### Training
-Every setting for a training is set through a YAML configuration file.
-Thus, in order to train a model you will have to setup the configuration file.
-An example is shown:
-```yaml
-# Training settings
-exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
-iter_log_interval: 1 # Log training iteration every N iterations
-iter_time_window: 100 # Moving average iterations window for the printed loss metric
-model_save_interval: 1 # Save model every N epochs
-seed: 0 # Seed for randomness
-backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
-
-# Dataset settings
-datasets:
-  train:
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: # ImgAug augmentations
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "datasets/tusimple" # Dataset root
-
-  test: &test
-    type: PointsDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      img_size: [360, 640]
-      root: "datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
-```
-
-With the config file created, run the training script:
-```bash
-python train.py --exp_name tusimple --cfg config.yaml
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the training (.yaml)
-  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
-  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
-  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
-```
-
-#### Testing
-After training, run the `test.py` script to get the metrics:
-```bash
-python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
-```
-This script's options are:
-```
-  --exp_name            Experiment name.
-  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
-  --epoch EPOCH         Epoch to test the model on
-  --batch_size          Number of images per batch
-  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
-```
-
-If you have any issues with either training or testing feel free to open an issue.
-
-<a name="reproducing"/>
-
-### Reproducing the paper results
-
-#### Models
-All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
-
-#### Datasets
-- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
-- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
-- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
-
-#### How to
-To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
-If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
-If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
-1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
-1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
-1. Move the downloaded experiment to your `exps_dir` folder.
-
-Then, run:
-
-```bash
-python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
-```
-Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
-
-
+<div align="center">
+
+# PolyLaneNet
+![Method overview](figures/method-overview.png "Method overview")
+</div>
+
+## Description
+Code for the [PolyLaneNet paper](https://arxiv.org/abs/2004.10924 "PolyLaneNet paper"), accepted to ICPR 2020, by [Lucas Tabelini](https://github.com/lucastabelini), [Thiago M. Paixão](https://sites.google.com/view/thiagopx), [Rodrigo F. Berriel](http://rodrigoberriel.com), [Claudine Badue](https://www.inf.ufes.br/~claudine/),
+[Alberto F. De Souza](https://inf.ufes.br/~alberto), and [Thiago Oliveira-Santos](https://www.inf.ufes.br/~todsantos/home).
+
+**News**: The source code for our new state-of-the-art lane detection method, LaneATT, has been released. Check it out [here](https://github.com/lucastabelini/LaneATT/).
+
+## Table of Contents
+1. [Installation](#installation)
+2. [Usage](#usage)
+3. [Reproducing the paper results](#reproducing)
+
+<a name="installation"/>
+
+### Installation
+The code requires Python 3, and has been tested on Python 3.5.2, but should work on newer versions of Python too.
+
+Install dependencies:
+```
+pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
+```
+
+<a name="usage"/>
+
+### Usage
+#### Training
+Every setting for a training is set through a YAML configuration file.
+Thus, in order to train a model you will have to setup the configuration file.
+An example is shown:
+```yaml
+# Training settings
+exps_dir: 'experiments' # Path to the root for the experiments directory (not only the one you will run)
+iter_log_interval: 1 # Log training iteration every N iterations
+iter_time_window: 100 # Moving average iterations window for the printed loss metric
+model_save_interval: 1 # Save model every N epochs
+seed: 0 # Seed for randomness
+backup: drive:polylanenet-experiments # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)
+
+# Dataset settings
+datasets:
+  train:
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: # ImgAug augmentations
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "datasets/tusimple" # Dataset root
+
+  test: &test
+    type: PointsDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      img_size: [360, 640]
+      root: "datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
+```
+
+With the config file created, run the training script:
+```bash
+python train.py --exp_name tusimple --cfg config.yaml
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the training (.yaml)
+  --resume              Resume training. If a training session was interrupted, run it again with the same arguments and this option to resume the training from the last checkpoint.
+  --validate            Wheter to validate during the training session. Was not in our experiments, which means it has not been thoroughly tested.
+  --deterministic       set cudnn.deterministic = True and cudnn.benchmark = False
+```
+
+#### Testing
+After training, run the `test.py` script to get the metrics:
+```bash
+python test.py --exp_name tusimple --cfg config.yaml --epoch 2695
+```
+This script's options are:
+```
+  --exp_name            Experiment name.
+  --cfg                 Config file for the test (.yaml). (probably the same one used in the training)
+  --epoch EPOCH         Epoch to test the model on
+  --batch_size          Number of images per batch
+  --view                Show predictions. Will draw the predictions in an image and then show it (cv.imshow)
+```
+
+If you have any issues with either training or testing feel free to open an issue.
+
+<a name="reproducing"/>
+
+### Reproducing the paper results
+
+#### Models
+All models trained for the paper can be found [here](https://drive.google.com/open?id=1oyZncVnUB1GRJl5L4oXz50RkcNFM_FFC "Models on Google Drive").
+
+#### Datasets
+- [TuSimple](https://github.com/TuSimple/tusimple-benchmark "TuSimple")
+- [ELAS](https://github.com/rodrigoberriel/ego-lane-analysis-system/tree/master/datasets "ELAS")
+- [LLAMAS](https://unsupervised-llamas.com/llamas/ "LLAMAS")
+
+#### How to
+To reproduce the results, you can either retrain a model with the same settings (which should yield results pretty close to the reported ones) or just test the model.
+If you want to retrain, you only need the appropriate YAML settings file, which you can find in the `cfgs` directory.
+If you just want to reproduce the exact reported metrics by testing the model, you'll have to:
+1. Download the experiment directory. You don't need to download all model checkpoints if you want, you'll only need the last one (`model_2695.pt`, with the exception of the experiments on ELAS and LLAMAS).
+1. Modify all path related fields (i.e., dataset paths and `exps_dir`) in the `config.yaml` file inside the experiment directory.
+1. Move the downloaded experiment to your `exps_dir` folder.
+
+Then, run:
+
+```bash
+python test.py --exp_name $exp_name --cfg $exps_dir/$exp_name/config.yaml --epoch 2695
+```
+Replacing `$exp_name` with the name of the directory you downloaded (the name of the experiment) and `$exps_dir` with the `exps_dir` value you defined inside the `config.yaml` file. The script will look for a directory named `$exps_dir/$exp_name/models` to load the model.
+
+
diff --git a/cfgs/elas.yaml b/cfgs/elas.yaml
index 98a03bd..8d9f910 100644
--- a/cfgs/elas.yaml
+++ b/cfgs/elas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 35
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 35
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 35
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 35
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/elas_cls.yaml b/cfgs/elas_cls.yaml
index a251b94..db6d9c8 100644
--- a/cfgs/elas_cls.yaml
+++ b/cfgs/elas_cls.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: true
-    extra_outputs: 40 # 5 lanes * 8 classes
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 1
-  poly_weight: 300
-batch_size: 16
-epochs: 385
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/ELAS"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: elas 
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/ELAS"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: true
+    extra_outputs: 40 # 5 lanes * 8 classes
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 1
+  poly_weight: 300
+batch_size: 16
+epochs: 385
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/ELAS"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: elas 
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/ELAS"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/llamas.yaml b/cfgs/llamas.yaml
index 5806168..1af205d 100644
--- a/cfgs/llamas.yaml
+++ b/cfgs/llamas.yaml
@@ -1,62 +1,62 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 75
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 75
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: llamas 
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.
-      augmentations: []
-      root: "../data_lane-regression/datasets/llamas"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: llamas
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/llamas"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 75
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 75
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: llamas 
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.
+      augmentations: []
+      root: "../data_lane-regression/datasets/llamas"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: llamas
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/llamas"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple.yaml b/cfgs/tusimple.yaml
index 01da72b..2a13cb1 100644
--- a/cfgs/tusimple.yaml
+++ b/cfgs/tusimple.yaml
@@ -1,73 +1,73 @@
-# Training settings
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-seed: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+seed: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_1order.yaml b/cfgs/tusimple_1order.yaml
index 66a8607..3e5f617 100644
--- a/cfgs/tusimple_1order.yaml
+++ b/cfgs/tusimple_1order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 1 
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 9000, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression//datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression//datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 1 
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 9000, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression//datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression//datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_2order.yaml b/cfgs/tusimple_2order.yaml
index 9091dcc..2e3cdca 100644
--- a/cfgs/tusimple_2order.yaml
+++ b/cfgs/tusimple_2order.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [9000, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [9000, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_320x180.yaml b/cfgs/tusimple_320x180.yaml
index fb61010..32b8f5e 100644
--- a/cfgs/tusimple_320x180.yaml
+++ b/cfgs/tusimple_320x180.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [180, 320]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [180, 320]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [180, 320]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [180, 320]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_480x270.yaml b/cfgs/tusimple_480x270.yaml
index e9077d4..3312074 100644
--- a/cfgs/tusimple_480x270.yaml
+++ b/cfgs/tusimple_480x270.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [270, 480]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [270, 480]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [270, 480]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [270, 480]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_efficientnetb1.yaml b/cfgs/tusimple_efficientnetb1.yaml
index f085635..b1a080a 100644
--- a/cfgs/tusimple_efficientnetb1.yaml
+++ b/cfgs/tusimple_efficientnetb1.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b1'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b1'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_fulltrain.yaml b/cfgs/tusimple_fulltrain.yaml
index 0c0f485..69dfe67 100644
--- a/cfgs/tusimple_fulltrain.yaml
+++ b/cfgs/tusimple_fulltrain.yaml
@@ -1,72 +1,72 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train+val
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: test
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple-test"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train+val
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: test
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple-test"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_no_share_top_y.yaml b/cfgs/tusimple_no_share_top_y.yaml
index ec81eb2..e1081a5 100644
--- a/cfgs/tusimple_no_share_top_y.yaml
+++ b/cfgs/tusimple_no_share_top_y.yaml
@@ -1,74 +1,74 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    share_top_y: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    share_top_y: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_noaug.yaml b/cfgs/tusimple_noaug.yaml
index 8b4b9db..edd5362 100644
--- a/cfgs/tusimple_noaug.yaml
+++ b/cfgs/tusimple_noaug.yaml
@@ -1,63 +1,63 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations: []
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations: []
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_nopretrain.yaml b/cfgs/tusimple_nopretrain.yaml
index 0de222f..ccf039f 100644
--- a/cfgs/tusimple_nopretrain.yaml
+++ b/cfgs/tusimple_nopretrain.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: false 
-    backbone: 'efficientnet-b0'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: false 
+    backbone: 'efficientnet-b0'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet34.yaml b/cfgs/tusimple_resnet34.yaml
index 6eafef9..753dc12 100644
--- a/cfgs/tusimple_resnet34.yaml
+++ b/cfgs/tusimple_resnet34.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet34'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "../data_lane-regression/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "../data_lane-regression/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet34'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "../data_lane-regression/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "../data_lane-regression/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/cfgs/tusimple_resnet50.yaml b/cfgs/tusimple_resnet50.yaml
index 58784a8..a32ef90 100644
--- a/cfgs/tusimple_resnet50.yaml
+++ b/cfgs/tusimple_resnet50.yaml
@@ -1,73 +1,73 @@
-# Training settings
-seed: 0
-exps_dir: 'experiments'
-iter_log_interval: 1
-iter_time_window: 100
-model_save_interval: 1
-backup:
-model:
-  name: PolyRegression
-  parameters:
-    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
-    pretrained: true
-    backbone: 'resnet50'
-    pred_category: false
-    curriculum_steps: [0, 0, 0, 0]
-loss_parameters:
-  conf_weight: 1
-  lower_weight: 1
-  upper_weight: 1
-  cls_weight: 0
-  poly_weight: 300
-batch_size: 16
-epochs: 2695
-optimizer:
-  name: Adam
-  parameters:
-    lr: 3.0e-4
-lr_scheduler:
-  name: CosineAnnealingLR
-  parameters:
-    T_max: 385
-
-# Testing settings
-test_parameters:
-  conf_threshold: 0.5
-
-# Dataset settings
-datasets:
-  train:
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: train
-      img_size: [360, 640]
-      normalize: true
-      aug_chance: 0.9090909090909091 # 10/11
-      augmentations:
-       - name: Affine
-         parameters:
-           rotate: !!python/tuple [-10, 10]
-       - name: HorizontalFlip
-         parameters:
-           p: 0.5
-       - name: CropToFixedSize
-         parameters:
-           width: 1152
-           height: 648
-      root: "/dados/tabelini/datasets/tusimple"
-
-  test: &test
-    type: LaneDataset
-    parameters:
-      dataset: tusimple
-      split: val
-      max_lanes: 5
-      img_size: [360, 640]
-      root: "/dados/tabelini/datasets/tusimple"
-      normalize: true
-      augmentations: []
-
-  # val = test
-  val:
-    <<: *test
+# Training settings
+seed: 0
+exps_dir: 'experiments'
+iter_log_interval: 1
+iter_time_window: 100
+model_save_interval: 1
+backup:
+model:
+  name: PolyRegression
+  parameters:
+    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
+    pretrained: true
+    backbone: 'resnet50'
+    pred_category: false
+    curriculum_steps: [0, 0, 0, 0]
+loss_parameters:
+  conf_weight: 1
+  lower_weight: 1
+  upper_weight: 1
+  cls_weight: 0
+  poly_weight: 300
+batch_size: 16
+epochs: 2695
+optimizer:
+  name: Adam
+  parameters:
+    lr: 3.0e-4
+lr_scheduler:
+  name: CosineAnnealingLR
+  parameters:
+    T_max: 385
+
+# Testing settings
+test_parameters:
+  conf_threshold: 0.5
+
+# Dataset settings
+datasets:
+  train:
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: train
+      img_size: [360, 640]
+      normalize: true
+      aug_chance: 0.9090909090909091 # 10/11
+      augmentations:
+       - name: Affine
+         parameters:
+           rotate: !!python/tuple [-10, 10]
+       - name: HorizontalFlip
+         parameters:
+           p: 0.5
+       - name: CropToFixedSize
+         parameters:
+           width: 1152
+           height: 648
+      root: "/dados/tabelini/datasets/tusimple"
+
+  test: &test
+    type: LaneDataset
+    parameters:
+      dataset: tusimple
+      split: val
+      max_lanes: 5
+      img_size: [360, 640]
+      root: "/dados/tabelini/datasets/tusimple"
+      normalize: true
+      augmentations: []
+
+  # val = test
+  val:
+    <<: *test
diff --git a/lib/config.py b/lib/config.py
index d5d6275..e9405c9 100644
--- a/lib/config.py
+++ b/lib/config.py
@@ -1,45 +1,45 @@
-import yaml
-import torch
-
-import lib.models as models
-import lib.datasets as datasets
-
-
-class Config(object):
-    def __init__(self, config_path):
-        self.config = {}
-        self.load(config_path)
-
-    def load(self, path):
-        with open(path, 'r') as file:
-            self.config_str = file.read()
-        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
-
-    def __repr__(self):
-        return self.config_str
-
-    def get_dataset(self, split):
-        return getattr(datasets,
-                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
-
-    def get_model(self):
-        name = self.config['model']['name']
-        parameters = self.config['model']['parameters']
-        return getattr(models, name)(**parameters)
-
-    def get_optimizer(self, model_parameters):
-        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
-                                                                      **self.config['optimizer']['parameters'])
-
-    def get_lr_scheduler(self, optimizer):
-        return getattr(torch.optim.lr_scheduler,
-                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
-
-    def get_loss_parameters(self):
-        return self.config['loss_parameters']
-
-    def get_test_parameters(self):
-        return self.config['test_parameters']
-
-    def __getitem__(self, item):
-        return self.config[item]
+import yaml
+import torch
+
+import lib.models as models
+import lib.datasets as datasets
+
+
+class Config(object):
+    def __init__(self, config_path):
+        self.config = {}
+        self.load(config_path)
+
+    def load(self, path):
+        with open(path, 'r') as file:
+            self.config_str = file.read()
+        self.config = yaml.load(self.config_str, Loader=yaml.FullLoader)
+
+    def __repr__(self):
+        return self.config_str
+
+    def get_dataset(self, split):
+        return getattr(datasets,
+                       self.config['datasets'][split]['type'])(**self.config['datasets'][split]['parameters'])
+
+    def get_model(self):
+        name = self.config['model']['name']
+        parameters = self.config['model']['parameters']
+        return getattr(models, name)(**parameters)
+
+    def get_optimizer(self, model_parameters):
+        return getattr(torch.optim, self.config['optimizer']['name'])(model_parameters,
+                                                                      **self.config['optimizer']['parameters'])
+
+    def get_lr_scheduler(self, optimizer):
+        return getattr(torch.optim.lr_scheduler,
+                       self.config['lr_scheduler']['name'])(optimizer, **self.config['lr_scheduler']['parameters'])
+
+    def get_loss_parameters(self):
+        return self.config['loss_parameters']
+
+    def get_test_parameters(self):
+        return self.config['test_parameters']
+
+    def __getitem__(self, item):
+        return self.config[item]
diff --git a/lib/datasets/__init__.py b/lib/datasets/__init__.py
index bc2eb7a..a870757 100644
--- a/lib/datasets/__init__.py
+++ b/lib/datasets/__init__.py
@@ -1,3 +1,3 @@
-from .lane_dataset import LaneDataset
-
-__all__ = ["LaneDataset"]
+from .lane_dataset import LaneDataset
+
+__all__ = ["LaneDataset"]
diff --git a/lib/datasets/elas.py b/lib/datasets/elas.py
index 490f37a..c2a0823 100644
--- a/lib/datasets/elas.py
+++ b/lib/datasets/elas.py
@@ -1,137 +1,137 @@
-import os
-import math
-import random
-
-import cv2
-import numpy as np
-import xmljson
-from scipy import interpolate
-from lxml.etree import fromstring
-
-SPLIT_DIRECTORIES = {
-    'train': [
-        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
-        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
-    ],
-    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
-}
-
-CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
-ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
-
-
-class ELAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.root = root
-        self.split = split
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_directories = SPLIT_DIRECTORIES[split]
-
-        self.img_w, self.img_h = 640, 480
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-        self.class_icons = {
-            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
-            for cls_id in ID_TO_CATEGORY
-        }
-
-    def get_class_icon(self, cls_id):
-        return self.class_icons[cls_id]
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def interp_lane(self, lane, ys, step=10):
-        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
-        if len(pts) <= 1:
-            return None
-        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
-        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
-        interp_xs = interpolate.splev(interp_ys, spline)
-
-        return list(zip(interp_xs, interp_ys))
-
-    def load_dir_annotations(self, dataset_dir):
-        annotations = []
-        max_points = 0
-        max_lanes = 0
-
-        # read config.xml
-        config_fname = os.path.join(dataset_dir, 'config.xml')
-        if not os.path.isfile(config_fname):
-            raise Exception('config.xml not found: {}'.format(config_fname))
-        with open(config_fname, 'r') as hf:
-            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
-
-        # read ground truth
-        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
-        if not os.path.isfile(gt_fname):
-            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
-        with open(gt_fname, 'r') as hf:
-            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
-
-        # read frame annotations
-        for frame in gt['frames']['frame']:
-            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
-
-            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
-            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
-            pts = ['p1', 'p2', 'p3', 'p4']
-            lanes = []
-            categories = []
-            for side in ['Left', 'Right']:
-                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
-                lane = self.interp_lane(lane, ys)
-                if lane is None:
-                    continue
-                max_points = max(max_points, len(lane))
-                lanes.append(lane)
-                category = str(frame['@lmt{}'.format(side)])
-                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
-            max_lanes = max(max_lanes, len(lanes))
-            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
-
-        return annotations, max_points, max_lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        for directory in self.anno_directories:
-            dir_path = os.path.join(self.root, directory)
-            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
-
-            self.annotations.extend(dir_annos)
-            self.max_points = max(self.max_points, dir_max_points)
-            self.max_lanes = max(self.max_lanes, dir_max_lanes)
-
-        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
-                                                                            self.max_lanes))
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import math
+import random
+
+import cv2
+import numpy as np
+import xmljson
+from scipy import interpolate
+from lxml.etree import fromstring
+
+SPLIT_DIRECTORIES = {
+    'train': [
+        "BR_S02", "GRI_S02", "ROD_S01", "ROD_S03", "VIX_S01", "VIX_S03", "VIX_S04", "VIX_S05", "VIX_S06", "VIX_S07",
+        "VIX_S08", "VIX_S09", "VIX_S10", "VV_S01", "VV_S03"
+    ],
+    'test': ["ROD_S02", "VV_S02", "VV_S04", "BR_S01", "GRI_S01", "VIX_S02", "VIX_S11"],
+}
+
+CATEGORY_TO_ID = {str(i): i + 1 for i in range(8)}
+ID_TO_CATEGORY = {i + 1: str(i) for i in range(8)}
+
+
+class ELAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.root = root
+        self.split = split
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_directories = SPLIT_DIRECTORIES[split]
+
+        self.img_w, self.img_h = 640, 480
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+        self.class_icons = {
+            cls_id: cv2.imread(os.path.join(self.root, 'lmt', 'type_{}.png'.format(cls_id)))
+            for cls_id in ID_TO_CATEGORY
+        }
+
+    def get_class_icon(self, cls_id):
+        return self.class_icons[cls_id]
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def interp_lane(self, lane, ys, step=10):
+        pts = [[x, ys[i]] for i, x in enumerate(lane) if not math.isnan(float(x))]
+        if len(pts) <= 1:
+            return None
+        spline = interpolate.splrep([pt[1] for pt in pts], [pt[0] for pt in pts], k=len(pts) - 1)
+        interp_ys = list(range(min([pt[1] for pt in pts]), max([pt[1] for pt in pts]), step))
+        interp_xs = interpolate.splev(interp_ys, spline)
+
+        return list(zip(interp_xs, interp_ys))
+
+    def load_dir_annotations(self, dataset_dir):
+        annotations = []
+        max_points = 0
+        max_lanes = 0
+
+        # read config.xml
+        config_fname = os.path.join(dataset_dir, 'config.xml')
+        if not os.path.isfile(config_fname):
+            raise Exception('config.xml not found: {}'.format(config_fname))
+        with open(config_fname, 'r') as hf:
+            config = xmljson.badgerfish.data(fromstring(hf.read()))['config']
+
+        # read ground truth
+        gt_fname = os.path.join(dataset_dir, 'groundtruth.xml')
+        if not os.path.isfile(gt_fname):
+            raise Exception('groundtruth.xml not found: {}'.format(gt_fname))
+        with open(gt_fname, 'r') as hf:
+            gt = xmljson.badgerfish.data(fromstring(hf.read()))['groundtruth']
+
+        # read frame annotations
+        for frame in gt['frames']['frame']:
+            img_fname = os.path.join(dataset_dir, 'images/lane_{}.png'.format(frame['@id']))
+
+            y, h = config['dataset']['region_of_interest']['@y'], config['dataset']['region_of_interest']['@height']
+            ys = [y, math.ceil(y + h / 4.), math.ceil(y + h / 2.), y + h - 1]
+            pts = ['p1', 'p2', 'p3', 'p4']
+            lanes = []
+            categories = []
+            for side in ['Left', 'Right']:
+                lane = [frame['position'][side.lower()][pt]['$'] for pt in pts]
+                lane = self.interp_lane(lane, ys)
+                if lane is None:
+                    continue
+                max_points = max(max_points, len(lane))
+                lanes.append(lane)
+                category = str(frame['@lmt{}'.format(side)])
+                categories.append(CATEGORY_TO_ID[category.split(';')[0]])
+            max_lanes = max(max_lanes, len(lanes))
+            annotations.append({'lanes': lanes, 'path': img_fname, 'categories': categories})
+
+        return annotations, max_points, max_lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        for directory in self.anno_directories:
+            dir_path = os.path.join(self.root, directory)
+            dir_annos, dir_max_points, dir_max_lanes = self.load_dir_annotations(dir_path)
+
+            self.annotations.extend(dir_annos)
+            self.max_points = max(self.max_points, dir_max_points)
+            self.max_lanes = max(self.max_lanes, dir_max_lanes)
+
+        print('{} annotations found. max_points: {} | max_lanes: {}'.format(len(self.annotations), self.max_points,
+                                                                            self.max_lanes))
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..5253419 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -1,239 +1,240 @@
-import cv2
-import numpy as np
-import imgaug.augmenters as iaa
-from imgaug.augmenters import Resize
-from torchvision.transforms import ToTensor
-from torch.utils.data.dataset import Dataset
-from imgaug.augmentables.lines import LineString, LineStringsOnImage
-
-from .elas import ELAS
-from .llamas import LLAMAS
-from .tusimple import TuSimple
-from .nolabel_dataset import NoLabelDataset
-
-GT_COLOR = (255, 0, 0)
-PRED_HIT_COLOR = (0, 255, 0)
-PRED_MISS_COLOR = (0, 0, 255)
-IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
-IMAGENET_STD = np.array([0.229, 0.224, 0.225])
-
-
-class LaneDataset(Dataset):
-    def __init__(self,
-                 dataset='tusimple',
-                 augmentations=None,
-                 normalize=False,
-                 split='train',
-                 img_size=(360, 640),
-                 aug_chance=1.,
-                 **kwargs):
-        super(LaneDataset, self).__init__()
-        if dataset == 'tusimple':
-            self.dataset = TuSimple(split=split, **kwargs)
-        elif dataset == 'llamas':
-            self.dataset = LLAMAS(split=split, **kwargs)
-        elif dataset == 'elas':
-            self.dataset = ELAS(split=split, **kwargs)
-        elif dataset == 'nolabel_dataset':
-            self.dataset = NoLabelDataset(**kwargs)
-        else:
-            raise NotImplementedError()
-
-        self.transform_annotations()
-        self.img_h, self.img_w = img_size
-
-        if augmentations is not None:
-            # add augmentations
-            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
-                             for aug in augmentations]  # add augmentation
-
-        self.normalize = normalize
-        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
-        self.to_tensor = ToTensor()
-        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
-        self.max_lanes = self.dataset.max_lanes
-
-    def transform_annotation(self, anno, img_wh=None):
-        if img_wh is None:
-            img_h = self.dataset.get_img_heigth(anno['path'])
-            img_w = self.dataset.get_img_width(anno['path'])
-        else:
-            img_w, img_h = img_wh
-
-        old_lanes = anno['lanes']
-        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
-        old_lanes = zip(old_lanes, categories)
-        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
-        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
-        lanes[:, 0] = 0
-        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
-        for lane_pos, (lane, category) in enumerate(old_lanes):
-            lower, upper = lane[0][1], lane[-1][1]
-            xs = np.array([p[0] for p in lane]) / img_w
-            ys = np.array([p[1] for p in lane]) / img_h
-            lanes[lane_pos, 0] = category
-            lanes[lane_pos, 1] = lower / img_h
-            lanes[lane_pos, 2] = upper / img_h
-            lanes[lane_pos, 3:3 + len(xs)] = xs
-            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
-
-        new_anno = {
-            'path': anno['path'],
-            'label': lanes,
-            'old_anno': anno,
-            'categories': [cat for _, cat in old_lanes]
-        }
-
-        return new_anno
-
-    @property
-    def annotations(self):
-        return self.dataset.annotations
-
-    def transform_annotations(self):
-        print('Transforming annotations...')
-        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
-        print('Done.')
-
-    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
-        if img is None:
-            img, label, _ = self.__getitem__(idx, transform=True)
-            # Tensor to opencv image
-            img = img.permute(1, 2, 0).numpy()
-            # Unnormalize
-            if self.normalize:
-                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
-            img = (img * 255).astype(np.uint8)
-        else:
-            _, label, _ = self.__getitem__(idx)
-
-        img_h, img_w, _ = img.shape
-
-        # Draw label
-        for i, lane in enumerate(label):
-            if lane[0] == 0:  # Skip invalid lanes
-                continue
-            lane = lane[3:]  # remove conf, upper and lower positions
-            xs = lane[:len(lane) // 2]
-            ys = lane[len(lane) // 2:]
-            ys = ys[xs >= 0]
-            xs = xs[xs >= 0]
-
-            # draw GT points
-            for p in zip(xs, ys):
-                p = (int(p[0] * img_w), int(p[1] * img_h))
-                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
-
-            # draw GT lane ID
-            cv2.putText(img,
-                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
-                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                        fontScale=1,
-                        color=(0, 255, 0))
-
-        if pred is None:
-            return img
-
-        # Draw predictions
-        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
-        matches, accs, _ = self.dataset.get_metrics(pred, idx)
-        overlay = img.copy()
-        for i, lane in enumerate(pred):
-            if matches[i]:
-                color = PRED_HIT_COLOR
-            else:
-                color = PRED_MISS_COLOR
-            lane = lane[1:]  # remove conf
-            lower, upper = lane[0], lane[1]
-            lane = lane[2:]  # remove upper, lower positions
-
-            # generate points from the polynomial
-            ys = np.linspace(lower, upper, num=100)
-            points = np.zeros((len(ys), 2), dtype=np.int32)
-            points[:, 1] = (ys * img_h).astype(int)
-            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
-            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
-
-            # draw lane with a polyline on the overlay
-            for current_point, next_point in zip(points[:-1], points[1:]):
-                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
-
-            # draw class icon
-            if cls_pred is not None and len(points) > 0:
-                class_icon = self.dataset.get_class_icon(cls_pred[i])
-                class_icon = cv2.resize(class_icon, (32, 32))
-                mid = tuple(points[len(points) // 2] - 60)
-                x, y = mid
-
-                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
-
-            # draw lane ID
-            if len(points) > 0:
-                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
-
-            # draw lane accuracy
-            if len(points) > 0:
-                cv2.putText(img,
-                            '{:.2f}'.format(accs[i] * 100),
-                            tuple(points[len(points) // 2] - 30),
-                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
-                            fontScale=.75,
-                            color=color)
-        # Add lanes overlay
-        w = 0.6
-        img = ((1. - w) * img + w * overlay).astype(np.uint8)
-
-        return img
-
-    def lane_to_linestrings(self, lanes):
-        lines = []
-        for lane in lanes:
-            lines.append(LineString(lane))
-
-        return lines
-
-    def linestrings_to_lanes(self, lines):
-        lanes = []
-        for line in lines:
-            lanes.append(line.coords)
-
-        return lanes
-
-    def __getitem__(self, idx, transform=True):
-        item = self.dataset[idx]
-        img = cv2.imread(item['path'])
-        label = item['label']
-        if transform:
-            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
-            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
-            img, line_strings = self.transform(image=img, line_strings=line_strings)
-            line_strings.clip_out_of_image_()
-            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
-            new_anno['categories'] = item['categories']
-            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
-
-        img = img / 255.
-        if self.normalize:
-            img = (img - IMAGENET_MEAN) / IMAGENET_STD
-        img = self.to_tensor(img.astype(np.float32))
-        return (img, label, idx)
-
-    def __len__(self):
-        return len(self.dataset)
-
-
-def main():
-    import torch
-    from lib.config import Config
-    np.random.seed(0)
-    torch.manual_seed(0)
-    cfg = Config('config.yaml')
-    train_dataset = cfg.get_dataset('train')
-    for idx in range(len(train_dataset)):
-        img = train_dataset.draw_annotation(idx)
-        cv2.imshow('sample', img)
-        cv2.waitKey(0)
-
-
-if __name__ == "__main__":
-    main()
+import cv2
+import numpy as np
+import imgaug.augmenters as iaa
+from imgaug.augmenters import Resize
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+from imgaug.augmentables.lines import LineString, LineStringsOnImage
+
+from .elas import ELAS
+from .llamas import LLAMAS
+from .tusimple import TuSimple
+from .nolabel_dataset import NoLabelDataset
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+
+class LaneDataset(Dataset):
+    def __init__(self,
+                 dataset='tusimple',
+                 augmentations=None,
+                 normalize=False,
+                 split='train',
+                 img_size=(360, 640),
+                 aug_chance=1.,
+                 **kwargs):
+        super(LaneDataset, self).__init__()
+        if dataset == 'tusimple':
+            self.dataset = TuSimple(split=split, **kwargs)
+        elif dataset == 'llamas':
+            self.dataset = LLAMAS(split=split, **kwargs)
+        elif dataset == 'elas':
+            self.dataset = ELAS(split=split, **kwargs)
+        elif dataset == 'nolabel_dataset':
+            self.dataset = NoLabelDataset(**kwargs)
+        else:
+            raise NotImplementedError()
+
+        self.transform_annotations()
+        self.img_h, self.img_w = img_size
+
+        if augmentations is not None:
+            # add augmentations
+            augmentations = [getattr(iaa, aug['name'])(**aug['parameters'])
+                             for aug in augmentations]  # add augmentation
+
+        self.normalize = normalize
+        transformations = iaa.Sequential([Resize({'height': self.img_h, 'width': self.img_w})])
+        self.to_tensor = ToTensor()
+        self.transform = iaa.Sequential([iaa.Sometimes(then_list=augmentations, p=aug_chance), transformations])
+        self.max_lanes = self.dataset.max_lanes
+
+    def transform_annotation(self, anno, img_wh=None):
+        if img_wh is None:
+            img_h = self.dataset.get_img_heigth(anno['path'])
+            img_w = self.dataset.get_img_width(anno['path'])
+        else:
+            img_w, img_h = img_wh
+
+        old_lanes = anno['lanes']
+        categories = anno['categories'] if 'categories' in anno else [1] * len(old_lanes)
+        old_lanes = zip(old_lanes, categories)
+        old_lanes = filter(lambda x: len(x[0]) > 0, old_lanes)
+        lanes = np.ones((self.dataset.max_lanes, 1 + 2 + 2 * self.dataset.max_points), dtype=np.float32) * -1e5
+        lanes[:, 0] = 0
+        old_lanes = sorted(old_lanes, key=lambda x: x[0][0][0])
+        for lane_pos, (lane, category) in enumerate(old_lanes):
+            lower, upper = lane[0][1], lane[-1][1]
+            xs = np.array([p[0] for p in lane]) / img_w
+            ys = np.array([p[1] for p in lane]) / img_h
+            lanes[lane_pos, 0] = category
+            lanes[lane_pos, 1] = lower / img_h
+            lanes[lane_pos, 2] = upper / img_h
+            lanes[lane_pos, 3:3 + len(xs)] = xs
+            lanes[lane_pos, (3 + self.dataset.max_points):(3 + self.dataset.max_points + len(ys))] = ys
+
+        new_anno = {
+            'path': anno['path'],
+            'label': lanes,
+            'old_anno': anno,
+            'categories': [cat for _, cat in old_lanes]
+        }
+
+        return new_anno
+
+    @property
+    def annotations(self):
+        return self.dataset.annotations
+
+    def transform_annotations(self):
+        print('Transforming annotations...')
+        self.dataset.annotations = np.array(list(map(self.transform_annotation, self.dataset.annotations)))
+        print('Done.')
+
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+        if img is None:
+            img, label, _ = self.__getitem__(idx, transform=True)
+            # Tensor to opencv image
+            img = img.permute(1, 2, 0).numpy()
+            # Unnormalize
+            if self.normalize:
+                img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+            img = (img * 255).astype(np.uint8)
+        else:
+            _, label, _ = self.__getitem__(idx)
+
+        img_h, img_w, _ = img.shape
+
+        # Draw label
+        for i, lane in enumerate(label):
+            if lane[0] == 0:  # Skip invalid lanes
+                continue
+            lane = lane[3:]  # remove conf, upper and lower positions
+            xs = lane[:len(lane) // 2]
+            ys = lane[len(lane) // 2:]
+            ys = ys[xs >= 0]
+            xs = xs[xs >= 0]
+
+            # draw GT points
+            for p in zip(xs, ys):
+                p = (int(p[0] * img_w), int(p[1] * img_h))
+                img = cv2.circle(img, p, 5, color=GT_COLOR, thickness=-1)
+
+            # draw GT lane ID
+            cv2.putText(img,
+                        str(i), (int(xs[0] * img_w), int(ys[0] * img_h)),
+                        fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                        fontScale=1,
+                        color=(0, 255, 0))
+
+        if pred is None:
+            return img
+
+
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        matches, accs, _ = self.dataset.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+            if matches[i]:
+                color = PRED_HIT_COLOR
+            else:
+                color = PRED_MISS_COLOR
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(accs[i] * 100),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+    def lane_to_linestrings(self, lanes):
+        lines = []
+        for lane in lanes:
+            lines.append(LineString(lane))
+
+        return lines
+
+    def linestrings_to_lanes(self, lines):
+        lanes = []
+        for line in lines:
+            lanes.append(line.coords)
+
+        return lanes
+
+    def __getitem__(self, idx, transform=True):
+        item = self.dataset[idx]
+        img = cv2.imread(item['path'])
+        label = item['label']
+        if transform:
+            line_strings = self.lane_to_linestrings(item['old_anno']['lanes'])
+            line_strings = LineStringsOnImage(line_strings, shape=img.shape)
+            img, line_strings = self.transform(image=img, line_strings=line_strings)
+            line_strings.clip_out_of_image_()
+            new_anno = {'path': item['path'], 'lanes': self.linestrings_to_lanes(line_strings)}
+            new_anno['categories'] = item['categories']
+            label = self.transform_annotation(new_anno, img_wh=(self.img_w, self.img_h))['label']
+
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, label, idx)
+
+    def __len__(self):
+        return len(self.dataset)
+
+
+def main():
+    import torch
+    from lib.config import Config
+    np.random.seed(0)
+    torch.manual_seed(0)
+    cfg = Config('config.yaml')
+    train_dataset = cfg.get_dataset('train')
+    for idx in range(len(train_dataset)):
+        img = train_dataset.draw_annotation(idx)
+        cv2.imshow('sample', img)
+        cv2.waitKey(0)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/lib/datasets/llamas.py b/lib/datasets/llamas.py
index 595e17b..aba4654 100644
--- a/lib/datasets/llamas.py
+++ b/lib/datasets/llamas.py
@@ -1,451 +1,451 @@
-import os
-import json
-import pickle as pkl
-
-import numpy as np
-from progressbar import progressbar
-
-TRAIN_LABELS_DIR = 'labels/train'
-TEST_LABELS_DIR = 'labels/valid'
-SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
-
-
-class LLAMAS(object):
-    def __init__(self, split='train', max_lanes=None, root=None):
-        self.split = split
-        self.root = root
-        if split not in SPLIT_DIRECTORIES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
-
-        self.img_w, self.img_h = 1276, 717
-        self.offset = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        # Placeholders
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def get_img_path(self, json_path):
-        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
-        base_name = '/'.join(json_path.split('/')[-3:])
-        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
-        return image_path
-
-    def get_json_paths(self):
-        json_paths = []
-        for root, dirs, files in os.walk(self.labels_dir):
-            for file in files:
-                if file.endswith(".json"):
-                    json_paths.append(os.path.join(root, file))
-        return json_paths
-
-    def load_annotations(self):
-        # Waiting for the dataset to load is tedious, let's cache it
-        os.makedirs('cache', exist_ok=True)
-        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
-        if os.path.exists(cache_path):
-            with open(cache_path, 'rb') as cache_file:
-                self.annotations = pkl.load(cache_file)
-                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
-                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
-                return
-
-        self.annotations = []
-        self.max_points = 0
-        self.max_lanes = 0
-        print("Searching annotation files...")
-        json_paths = self.get_json_paths()
-        print('{} annotations found.'.format(len(json_paths)))
-
-        for json_path in progressbar(json_paths):
-            lanes = get_horizontal_values_for_four_lanes(json_path)
-            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
-            lanes = [lane for lane in lanes if len(lane) > 0]
-            relative_path = self.get_img_path(json_path)
-            img_path = os.path.join(self.root, relative_path)
-            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
-            self.max_lanes = max(self.max_lanes, len(lanes))
-            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
-
-        with open(cache_path, 'wb') as cache_file:
-            pkl.dump(self.annotations, cache_file)
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        # Placeholder
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
-
-
-# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
-# Its license is copied here
-
-# ##### Begin License ######
-# MIT License
-
-# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
-
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-
-# The above copyright notice and this permission notice shall be included in all
-# copies or substantial portions of the Software.
-
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# ##### End License ######
-
-# Start code under the previous license
-
-
-def _extend_lane(lane, projection_matrix):
-    """Extends marker closest to the camera
-
-    Adds an extra marker that reaches the end of the image
-
-    Parameters
-    ----------
-    lane : iterable of markers
-    projection_matrix : 3x3 projection matrix
-    """
-    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
-    # z is the orthongal distance to the car. It's good enough
-
-    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
-    # e.g., horizontal markers which need to be filtered
-    filtered_markers = filter(
-        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
-        lane['markers'])
-    # might be the first marker in the list but not guaranteed
-    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
-
-    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
-        return lane
-
-    # World marker extension approximation
-    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
-        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
-
-    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
-    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
-
-    # Pixel marker extension approximation
-    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
-        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
-    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
-        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
-
-    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
-    if pixel_zero_x < 0:
-        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
-        new_pixel_point = (0, left_y)
-    elif pixel_zero_x > 1276:
-        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
-        new_pixel_point = (1276, right_y)
-    else:
-        new_pixel_point = (pixel_zero_x, 716)
-
-    new_marker = {
-        'lane_marker_id': 'FAKE',
-        'world_end': {
-            'x': closest_marker['world_start']['x'],
-            'y': closest_marker['world_start']['y'],
-            'z': closest_marker['world_start']['z']
-        },
-        'world_start': {
-            'x': zero_x,
-            'y': zero_y,
-            'z': 1
-        },
-        'pixel_end': {
-            'x': closest_marker['pixel_start']['x'],
-            'y': closest_marker['pixel_start']['y']
-        },
-        'pixel_start': {
-            'x': ir(new_pixel_point[0]),
-            'y': ir(new_pixel_point[1])
-        }
-    }
-    lane['markers'].insert(0, new_marker)
-
-    return lane
-
-
-class SplineCreator():
-    """
-    For each lane divder
-      - all lines are projected
-      - linearly interpolated to limit oscillations
-      - interpolated by a spline
-      - subsampled to receive individual pixel values
-
-    The spline creation can be optimized!
-      - Better spline parameters
-      - Extend lowest marker to reach bottom of image would also help
-      - Extending last marker may in some cases be interesting too
-    Any help is welcome.
-
-    Call create_all_points and get the points in self.sampled_points
-    It has an x coordinate for each value for each lane
-
-    """
-    def __init__(self, json_path):
-        self.json_path = json_path
-        self.json_content = read_json(json_path)
-        self.lanes = self.json_content['lanes']
-        self.lane_marker_points = {}
-        self.sampled_points = {}  # <--- the interesting part
-        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
-
-    def _sample_points(self, lane, ypp=5, between_markers=True):
-        """ Markers are given by start and endpoint. This one adds extra points
-        which need to be considered for the interpolation. Otherwise the spline
-        could arbitrarily oscillate between start and end of the individual markers
-
-        Parameters
-        ----------
-        lane: polyline, in theory but there are artifacts which lead to inconsistencies
-              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
-        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
-        between_markers : bool, interpolates inbetween dashes
-
-        Notes
-        -----
-        Especially, adding points in the lower parts of the image (high y-values) because
-        the start and end points are too sparse.
-        Removing upper lane markers that have starting and end points mapped into the same pixel.
-        """
-
-        # Collect all x values from all markers along a given line. There may be multiple
-        # intersecting markers, i.e., multiple entries for some y values
-        x_values = [[] for i in range(717)]
-        for marker in lane['markers']:
-            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
-
-            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
-            if height > 2:
-                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
-                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
-                for i in range(height + 1):
-                    x = marker['pixel_start']['x'] + slope * step_size * i
-                    y = marker['pixel_start']['y'] - step_size * i
-                    x_values[ir(y)].append(ir(x))
-
-        # Calculate average x values for each y value
-        for y, xs in enumerate(x_values):
-            if not xs:
-                x_values[y] = -1
-            else:
-                x_values[y] = sum(xs) / float(len(xs))
-
-        # In the following, we will only interpolate between markers if needed
-        if not between_markers:
-            return x_values  # TODO ypp
-
-        # # interpolate between markers
-        current_y = 0
-        while x_values[current_y] == -1:  # skip missing first entries
-            current_y += 1
-
-        # Also possible using numpy.interp when accounting for beginning and end
-        next_set_y = 0
-        try:
-            while current_y < 717:
-                if x_values[current_y] != -1:  # set. Nothing to be done
-                    current_y += 1
-                    continue
-
-                # Finds target x value for interpolation
-                while next_set_y <= current_y or x_values[next_set_y] == -1:
-                    next_set_y += 1
-                    if next_set_y >= 717:
-                        raise StopIteration
-
-                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
-                    (next_set_y - current_y + 1)
-                current_y += 1
-
-        except StopIteration:
-            pass  # Done with lane
-
-        return x_values
-
-    def _lane_points_fit(self, lane):
-        # TODO name and docstring
-        """ Fits spline in image space for the markers of a single lane (side)
-
-        Parameters
-        ----------
-        lane: dict as specified in label
-
-        Returns
-        -------
-        Pixel level values for curve along the y-axis
-
-        Notes
-        -----
-        This one can be drastically improved. Probably fairly easy as well.
-        """
-        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
-        lane = _extend_lane(lane, self.json_content['projection_matrix'])
-        sampled_points = self._sample_points(lane, ypp=1)
-        self.sampled_points[lane['lane_id']] = sampled_points
-
-        return sampled_points
-
-    def create_all_points(self, ):
-        """ Creates splines for given label """
-        for lane in self.lanes:
-            self._lane_points_fit(lane)
-
-
-def get_horizontal_values_for_four_lanes(json_path):
-    """ Gets an x value for every y coordinate for l1, l0, r0, r1
-
-    This allows to easily train a direct curve approximation. For each value along
-    the y-axis, the respective x-values can be compared, e.g. squared distance.
-    Missing values are filled with -1. Missing values are values missing from the spline.
-    There is no extrapolation to the image start/end (yet).
-    But values are interpolated between markers. Space between dashed markers is not missing.
-
-    Parameters
-    ----------
-    json_path: str
-               path to label-file
-
-    Returns
-    -------
-    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
-    the number of vertical pixels of the image
-
-    Notes
-    -----
-    The points are currently based on the splines. The splines are interpolated based on the
-    segmentation values. The spline interpolation has lots of room for improvement, e.g.
-    the lines could be interpolated in 3D, a better approach to spline interpolation could
-    be used, there is barely any error checking, sometimes the splines oscillate too much.
-    This was used for a quick poly-line regression training only.
-    """
-
-    sc = SplineCreator(json_path)
-    sc.create_all_points()
-
-    l1 = sc.sampled_points.get('l1', [-1] * 717)
-    l0 = sc.sampled_points.get('l0', [-1] * 717)
-    r0 = sc.sampled_points.get('r0', [-1] * 717)
-    r1 = sc.sampled_points.get('r1', [-1] * 717)
-
-    lanes = [l1, l0, r0, r1]
-    return lanes
-
-
-def _filter_lanes_by_size(label, min_height=40):
-    """ May need some tuning """
-    filtered_lanes = []
-    for lane in label['lanes']:
-        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
-        if (lane_end - lane_start) < min_height:
-            continue
-        filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _filter_few_markers(label, min_markers=2):
-    """Filter lines that consist of only few markers"""
-    filtered_lanes = []
-    for lane in label['lanes']:
-        if len(lane['markers']) >= min_markers:
-            filtered_lanes.append(lane)
-    label['lanes'] = filtered_lanes
-
-
-def _fix_lane_names(label):
-    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
-
-    # Create mapping
-    l_counter = 0
-    r_counter = 0
-    mapping = {}
-    lane_ids = [lane['lane_id'] for lane in label['lanes']]
-    for key in sorted(lane_ids):
-        if key[0] == 'l':
-            mapping[key] = 'l' + str(l_counter)
-            l_counter += 1
-        if key[0] == 'r':
-            mapping[key] = 'r' + str(r_counter)
-            r_counter += 1
-    for lane in label['lanes']:
-        lane['lane_id'] = mapping[lane['lane_id']]
-
-
-def read_json(json_path, min_lane_height=20):
-    """ Reads and cleans label file information by path"""
-    with open(json_path, 'r') as jf:
-        label_content = json.load(jf)
-
-    _filter_lanes_by_size(label_content, min_height=min_lane_height)
-    _filter_few_markers(label_content, min_markers=2)
-    _fix_lane_names(label_content)
-
-    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
-
-    for lane in content['lanes']:
-        for marker in lane['markers']:
-            for pixel_key in marker['pixel_start'].keys():
-                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
-            for pixel_key in marker['pixel_end'].keys():
-                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
-            for pixel_key in marker['world_start'].keys():
-                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
-            for pixel_key in marker['world_end'].keys():
-                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
-    return content
-
-
-def ir(some_value):
-    """ Rounds and casts to int
-    Useful for pixel values that cannot be floats
-    Parameters
-    ----------
-    some_value : float
-                 numeric value
-    Returns
-    --------
-    Rounded integer
-    Raises
-    ------
-    ValueError for non scalar types
-    """
-    return int(round(some_value))
-
-
-# End code under the previous license
+import os
+import json
+import pickle as pkl
+
+import numpy as np
+from progressbar import progressbar
+
+TRAIN_LABELS_DIR = 'labels/train'
+TEST_LABELS_DIR = 'labels/valid'
+SPLIT_DIRECTORIES = {'train': 'labels/train', 'val': 'labels/valid'}
+
+
+class LLAMAS(object):
+    def __init__(self, split='train', max_lanes=None, root=None):
+        self.split = split
+        self.root = root
+        if split not in SPLIT_DIRECTORIES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.labels_dir = os.path.join(self.root, SPLIT_DIRECTORIES[split])
+
+        self.img_w, self.img_h = 1276, 717
+        self.offset = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        # Placeholders
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def get_img_path(self, json_path):
+        # /foo/bar/test/folder/image_label.ext --> test/folder/image_label.ext
+        base_name = '/'.join(json_path.split('/')[-3:])
+        image_path = os.path.join('color_images', base_name.replace('.json', '_color_rect.png'))
+        return image_path
+
+    def get_json_paths(self):
+        json_paths = []
+        for root, dirs, files in os.walk(self.labels_dir):
+            for file in files:
+                if file.endswith(".json"):
+                    json_paths.append(os.path.join(root, file))
+        return json_paths
+
+    def load_annotations(self):
+        # Waiting for the dataset to load is tedious, let's cache it
+        os.makedirs('cache', exist_ok=True)
+        cache_path = 'cache/llamas_{}.pkl'.format(self.split)
+        if os.path.exists(cache_path):
+            with open(cache_path, 'rb') as cache_file:
+                self.annotations = pkl.load(cache_file)
+                self.max_lanes = max(len(anno['lanes']) for anno in self.annotations)
+                self.max_points = max(len(lane) for anno in self.annotations for lane in anno['lanes'])
+                return
+
+        self.annotations = []
+        self.max_points = 0
+        self.max_lanes = 0
+        print("Searching annotation files...")
+        json_paths = self.get_json_paths()
+        print('{} annotations found.'.format(len(json_paths)))
+
+        for json_path in progressbar(json_paths):
+            lanes = get_horizontal_values_for_four_lanes(json_path)
+            lanes = [[(x, y) for x, y in zip(lane, range(self.img_h)) if x >= 0] for lane in lanes]
+            lanes = [lane for lane in lanes if len(lane) > 0]
+            relative_path = self.get_img_path(json_path)
+            img_path = os.path.join(self.root, relative_path)
+            self.max_points = max(self.max_points, max(len(lane for lane in lanes)))
+            self.max_lanes = max(self.max_lanes, len(lanes))
+            self.annotations.append({'path': img_path, 'lanes': lanes, 'aug': False, 'relative_path': relative_path})
+
+        with open(cache_path, 'wb') as cache_file:
+            pkl.dump(self.annotations, cache_file)
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        # Placeholder
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
+
+
+# All following lines were taken from: https://github.com/karstenBehrendt/unsupervised_llamas
+# Its license is copied here
+
+# ##### Begin License ######
+# MIT License
+
+# Copyright (c) 2019 Karsten Behrendt, Robert Bosch LLC
+
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# ##### End License ######
+
+# Start code under the previous license
+
+
+def _extend_lane(lane, projection_matrix):
+    """Extends marker closest to the camera
+
+    Adds an extra marker that reaches the end of the image
+
+    Parameters
+    ----------
+    lane : iterable of markers
+    projection_matrix : 3x3 projection matrix
+    """
+    # Unfortunately, we did not store markers beyond the image plane. That hurts us now
+    # z is the orthongal distance to the car. It's good enough
+
+    # The markers are automatically detected, mapped, and labeled. There exist faulty ones,
+    # e.g., horizontal markers which need to be filtered
+    filtered_markers = filter(
+        lambda x: (x['pixel_start']['y'] != x['pixel_end']['y'] and x['pixel_start']['x'] != x['pixel_end']['x']),
+        lane['markers'])
+    # might be the first marker in the list but not guaranteed
+    closest_marker = min(filtered_markers, key=lambda x: x['world_start']['z'])
+
+    if closest_marker['world_start']['z'] < 0:  # This one likely equals "if False"
+        return lane
+
+    # World marker extension approximation
+    x_gradient = (closest_marker['world_end']['x'] - closest_marker['world_start']['x']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+    y_gradient = (closest_marker['world_end']['y'] - closest_marker['world_start']['y']) /\
+        (closest_marker['world_end']['z'] - closest_marker['world_start']['z'])
+
+    zero_x = closest_marker['world_start']['x'] - (closest_marker['world_start']['z'] - 1) * x_gradient
+    zero_y = closest_marker['world_start']['y'] - (closest_marker['world_start']['z'] - 1) * y_gradient
+
+    # Pixel marker extension approximation
+    pixel_x_gradient = (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x']) /\
+        (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y'])
+    pixel_y_gradient = (closest_marker['pixel_end']['y'] - closest_marker['pixel_start']['y']) /\
+        (closest_marker['pixel_end']['x'] - closest_marker['pixel_start']['x'])
+
+    pixel_zero_x = closest_marker['pixel_start']['x'] + (716 - closest_marker['pixel_start']['y']) * pixel_x_gradient
+    if pixel_zero_x < 0:
+        left_y = closest_marker['pixel_start']['y'] - closest_marker['pixel_start']['x'] * pixel_y_gradient
+        new_pixel_point = (0, left_y)
+    elif pixel_zero_x > 1276:
+        right_y = closest_marker['pixel_start']['y'] + (1276 - closest_marker['pixel_start']['x']) * pixel_y_gradient
+        new_pixel_point = (1276, right_y)
+    else:
+        new_pixel_point = (pixel_zero_x, 716)
+
+    new_marker = {
+        'lane_marker_id': 'FAKE',
+        'world_end': {
+            'x': closest_marker['world_start']['x'],
+            'y': closest_marker['world_start']['y'],
+            'z': closest_marker['world_start']['z']
+        },
+        'world_start': {
+            'x': zero_x,
+            'y': zero_y,
+            'z': 1
+        },
+        'pixel_end': {
+            'x': closest_marker['pixel_start']['x'],
+            'y': closest_marker['pixel_start']['y']
+        },
+        'pixel_start': {
+            'x': ir(new_pixel_point[0]),
+            'y': ir(new_pixel_point[1])
+        }
+    }
+    lane['markers'].insert(0, new_marker)
+
+    return lane
+
+
+class SplineCreator():
+    """
+    For each lane divder
+      - all lines are projected
+      - linearly interpolated to limit oscillations
+      - interpolated by a spline
+      - subsampled to receive individual pixel values
+
+    The spline creation can be optimized!
+      - Better spline parameters
+      - Extend lowest marker to reach bottom of image would also help
+      - Extending last marker may in some cases be interesting too
+    Any help is welcome.
+
+    Call create_all_points and get the points in self.sampled_points
+    It has an x coordinate for each value for each lane
+
+    """
+    def __init__(self, json_path):
+        self.json_path = json_path
+        self.json_content = read_json(json_path)
+        self.lanes = self.json_content['lanes']
+        self.lane_marker_points = {}
+        self.sampled_points = {}  # <--- the interesting part
+        self.debug_image = np.zeros((717, 1276, 3), dtype=np.uint8)
+
+    def _sample_points(self, lane, ypp=5, between_markers=True):
+        """ Markers are given by start and endpoint. This one adds extra points
+        which need to be considered for the interpolation. Otherwise the spline
+        could arbitrarily oscillate between start and end of the individual markers
+
+        Parameters
+        ----------
+        lane: polyline, in theory but there are artifacts which lead to inconsistencies
+              in ordering. There may be parallel lines. The lines may be dashed. It's messy.
+        ypp: y-pixels per point, e.g. 10 leads to a point every ten pixels
+        between_markers : bool, interpolates inbetween dashes
+
+        Notes
+        -----
+        Especially, adding points in the lower parts of the image (high y-values) because
+        the start and end points are too sparse.
+        Removing upper lane markers that have starting and end points mapped into the same pixel.
+        """
+
+        # Collect all x values from all markers along a given line. There may be multiple
+        # intersecting markers, i.e., multiple entries for some y values
+        x_values = [[] for i in range(717)]
+        for marker in lane['markers']:
+            x_values[marker['pixel_start']['y']].append(marker['pixel_start']['x'])
+
+            height = marker['pixel_start']['y'] - marker['pixel_end']['y']
+            if height > 2:
+                slope = (marker['pixel_end']['x'] - marker['pixel_start']['x']) / height
+                step_size = (marker['pixel_start']['y'] - marker['pixel_end']['y']) / float(height)
+                for i in range(height + 1):
+                    x = marker['pixel_start']['x'] + slope * step_size * i
+                    y = marker['pixel_start']['y'] - step_size * i
+                    x_values[ir(y)].append(ir(x))
+
+        # Calculate average x values for each y value
+        for y, xs in enumerate(x_values):
+            if not xs:
+                x_values[y] = -1
+            else:
+                x_values[y] = sum(xs) / float(len(xs))
+
+        # In the following, we will only interpolate between markers if needed
+        if not between_markers:
+            return x_values  # TODO ypp
+
+        # # interpolate between markers
+        current_y = 0
+        while x_values[current_y] == -1:  # skip missing first entries
+            current_y += 1
+
+        # Also possible using numpy.interp when accounting for beginning and end
+        next_set_y = 0
+        try:
+            while current_y < 717:
+                if x_values[current_y] != -1:  # set. Nothing to be done
+                    current_y += 1
+                    continue
+
+                # Finds target x value for interpolation
+                while next_set_y <= current_y or x_values[next_set_y] == -1:
+                    next_set_y += 1
+                    if next_set_y >= 717:
+                        raise StopIteration
+
+                x_values[current_y] = x_values[current_y - 1] + (x_values[next_set_y] - x_values[current_y - 1]) /\
+                    (next_set_y - current_y + 1)
+                current_y += 1
+
+        except StopIteration:
+            pass  # Done with lane
+
+        return x_values
+
+    def _lane_points_fit(self, lane):
+        # TODO name and docstring
+        """ Fits spline in image space for the markers of a single lane (side)
+
+        Parameters
+        ----------
+        lane: dict as specified in label
+
+        Returns
+        -------
+        Pixel level values for curve along the y-axis
+
+        Notes
+        -----
+        This one can be drastically improved. Probably fairly easy as well.
+        """
+        # NOTE all variable names represent image coordinates, interpolation coordinates are swapped!
+        lane = _extend_lane(lane, self.json_content['projection_matrix'])
+        sampled_points = self._sample_points(lane, ypp=1)
+        self.sampled_points[lane['lane_id']] = sampled_points
+
+        return sampled_points
+
+    def create_all_points(self, ):
+        """ Creates splines for given label """
+        for lane in self.lanes:
+            self._lane_points_fit(lane)
+
+
+def get_horizontal_values_for_four_lanes(json_path):
+    """ Gets an x value for every y coordinate for l1, l0, r0, r1
+
+    This allows to easily train a direct curve approximation. For each value along
+    the y-axis, the respective x-values can be compared, e.g. squared distance.
+    Missing values are filled with -1. Missing values are values missing from the spline.
+    There is no extrapolation to the image start/end (yet).
+    But values are interpolated between markers. Space between dashed markers is not missing.
+
+    Parameters
+    ----------
+    json_path: str
+               path to label-file
+
+    Returns
+    -------
+    List of [l1, l0, r0, r1], each of which represents a list of ints the length of
+    the number of vertical pixels of the image
+
+    Notes
+    -----
+    The points are currently based on the splines. The splines are interpolated based on the
+    segmentation values. The spline interpolation has lots of room for improvement, e.g.
+    the lines could be interpolated in 3D, a better approach to spline interpolation could
+    be used, there is barely any error checking, sometimes the splines oscillate too much.
+    This was used for a quick poly-line regression training only.
+    """
+
+    sc = SplineCreator(json_path)
+    sc.create_all_points()
+
+    l1 = sc.sampled_points.get('l1', [-1] * 717)
+    l0 = sc.sampled_points.get('l0', [-1] * 717)
+    r0 = sc.sampled_points.get('r0', [-1] * 717)
+    r1 = sc.sampled_points.get('r1', [-1] * 717)
+
+    lanes = [l1, l0, r0, r1]
+    return lanes
+
+
+def _filter_lanes_by_size(label, min_height=40):
+    """ May need some tuning """
+    filtered_lanes = []
+    for lane in label['lanes']:
+        lane_start = min([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        lane_end = max([int(marker['pixel_start']['y']) for marker in lane['markers']])
+        if (lane_end - lane_start) < min_height:
+            continue
+        filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _filter_few_markers(label, min_markers=2):
+    """Filter lines that consist of only few markers"""
+    filtered_lanes = []
+    for lane in label['lanes']:
+        if len(lane['markers']) >= min_markers:
+            filtered_lanes.append(lane)
+    label['lanes'] = filtered_lanes
+
+
+def _fix_lane_names(label):
+    """ Given keys ['l3', 'l2', 'l0', 'r0', 'r2'] returns ['l2', 'l1', 'l0', 'r0', 'r1']"""
+
+    # Create mapping
+    l_counter = 0
+    r_counter = 0
+    mapping = {}
+    lane_ids = [lane['lane_id'] for lane in label['lanes']]
+    for key in sorted(lane_ids):
+        if key[0] == 'l':
+            mapping[key] = 'l' + str(l_counter)
+            l_counter += 1
+        if key[0] == 'r':
+            mapping[key] = 'r' + str(r_counter)
+            r_counter += 1
+    for lane in label['lanes']:
+        lane['lane_id'] = mapping[lane['lane_id']]
+
+
+def read_json(json_path, min_lane_height=20):
+    """ Reads and cleans label file information by path"""
+    with open(json_path, 'r') as jf:
+        label_content = json.load(jf)
+
+    _filter_lanes_by_size(label_content, min_height=min_lane_height)
+    _filter_few_markers(label_content, min_markers=2)
+    _fix_lane_names(label_content)
+
+    content = {'projection_matrix': label_content['projection_matrix'], 'lanes': label_content['lanes']}
+
+    for lane in content['lanes']:
+        for marker in lane['markers']:
+            for pixel_key in marker['pixel_start'].keys():
+                marker['pixel_start'][pixel_key] = int(marker['pixel_start'][pixel_key])
+            for pixel_key in marker['pixel_end'].keys():
+                marker['pixel_end'][pixel_key] = int(marker['pixel_end'][pixel_key])
+            for pixel_key in marker['world_start'].keys():
+                marker['world_start'][pixel_key] = float(marker['world_start'][pixel_key])
+            for pixel_key in marker['world_end'].keys():
+                marker['world_end'][pixel_key] = float(marker['world_end'][pixel_key])
+    return content
+
+
+def ir(some_value):
+    """ Rounds and casts to int
+    Useful for pixel values that cannot be floats
+    Parameters
+    ----------
+    some_value : float
+                 numeric value
+    Returns
+    --------
+    Rounded integer
+    Raises
+    ------
+    ValueError for non scalar types
+    """
+    return int(round(some_value))
+
+
+# End code under the previous license
diff --git a/lib/datasets/nolabel_dataset.py b/lib/datasets/nolabel_dataset.py
index c8af627..1b3705b 100644
--- a/lib/datasets/nolabel_dataset.py
+++ b/lib/datasets/nolabel_dataset.py
@@ -1,44 +1,44 @@
-import glob
-
-import numpy as np
-
-
-class NoLabelDataset(object):
-    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
-        self.root = root
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = img_w, img_h
-        self.img_ext = img_ext
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        # On NoLabelDataset, always force it
-        self.max_lanes = max_lanes
-        self.max_points = 1
-
-    def get_img_heigth(self, path):
-        return self.img_h
-
-    def get_img_width(self, path):
-        return self.img_w
-
-    def get_metrics(self, lanes, idx):
-        return [1] * len(lanes), [1] * len(lanes), None
-
-    def load_annotations(self):
-        self.annotations = []
-        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
-        print('Looking for image files with the pattern', pattern)
-        for file in glob.glob(pattern, recursive=True):
-            self.annotations.append({'lanes': [], 'path': file})
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        return "", None
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import glob
+
+import numpy as np
+
+
+class NoLabelDataset(object):
+    def __init__(self, split='train', img_h=720, img_w=1280, max_lanes=None, root=None, img_ext='.jpg'):
+        self.root = root
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = img_w, img_h
+        self.img_ext = img_ext
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        # On NoLabelDataset, always force it
+        self.max_lanes = max_lanes
+        self.max_points = 1
+
+    def get_img_heigth(self, path):
+        return self.img_h
+
+    def get_img_width(self, path):
+        return self.img_w
+
+    def get_metrics(self, lanes, idx):
+        return [1] * len(lanes), [1] * len(lanes), None
+
+    def load_annotations(self):
+        self.annotations = []
+        pattern = '{}/**/*{}'.format(self.root, self.img_ext)
+        print('Looking for image files with the pattern', pattern)
+        for file in glob.glob(pattern, recursive=True):
+            self.annotations.append({'lanes': [], 'path': file})
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        return "", None
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..55690dc 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -1,137 +1,137 @@
-import os
-import json
-import random
-
-import numpy as np
-from tabulate import tabulate
-
-from utils.lane import LaneEval
-from utils.metric import eval_json
-
-SPLIT_FILES = {
-    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
-    'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
-    'test': ['test_label.json'],
-}
-
-
-class TuSimple(object):
-    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
-        self.split = split
-        self.root = root
-        self.metric = metric
-
-        if split not in SPLIT_FILES.keys():
-            raise Exception('Split `{}` does not exist.'.format(split))
-
-        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
-
-        if root is None:
-            raise Exception('Please specify the root directory')
-
-        self.img_w, self.img_h = 1280, 720
-        self.max_points = 0
-        self.load_annotations()
-
-        # Force max_lanes, used when evaluating testing with models trained on other datasets
-        if max_lanes is not None:
-            self.max_lanes = max_lanes
-
-    def get_img_heigth(self, path):
-        return 720
-
-    def get_img_width(self, path):
-        return 1280
-
-    def get_metrics(self, lanes, idx):
-        label = self.annotations[idx]
-        org_anno = label['old_anno']
-        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
-        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
-
-        return matches, accs, dist
-
-    def pred2lanes(self, path, pred, y_samples):
-        ys = np.array(y_samples) / self.img_h
-        lanes = []
-        for lane in pred:
-            if lane[0] == 0:
-                continue
-            lane_pred = np.polyval(lane[3:], ys) * self.img_w
-            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
-            lanes.append(list(lane_pred))
-
-        return lanes
-
-    def load_annotations(self):
-        self.annotations = []
-        max_lanes = 0
-        for anno_file in self.anno_files:
-            with open(anno_file, 'r') as anno_obj:
-                lines = anno_obj.readlines()
-            for line in lines:
-                data = json.loads(line)
-                y_samples = data['h_samples']
-                gt_lanes = data['lanes']
-                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
-                lanes = [lane for lane in lanes if len(lane) > 0]
-                max_lanes = max(max_lanes, len(lanes))
-                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
-                self.annotations.append({
-                    'path': os.path.join(self.root, data['raw_file']),
-                    'org_path': data['raw_file'],
-                    'org_lanes': gt_lanes,
-                    'lanes': lanes,
-                    'aug': False,
-                    'y_samples': y_samples
-                })
-
-        if self.split == 'train':
-            random.shuffle(self.annotations)
-        print('total annos', len(self.annotations))
-        self.max_lanes = max_lanes
-
-    def transform_annotations(self, transform):
-        self.annotations = list(map(transform, self.annotations))
-
-    def pred2tusimpleformat(self, idx, pred, runtime):
-        runtime *= 1000.  # s to ms
-        img_name = self.annotations[idx]['old_anno']['org_path']
-        h_samples = self.annotations[idx]['old_anno']['y_samples']
-        lanes = self.pred2lanes(img_name, pred, h_samples)
-        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
-        return json.dumps(output)
-
-    def save_tusimple_predictions(self, predictions, runtimes, filename):
-        lines = []
-        for idx in range(len(predictions)):
-            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
-            lines.append(line)
-        with open(filename, 'w') as output_file:
-            output_file.write('\n'.join(lines))
-
-    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
-        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
-        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
-        if self.metric == 'default':
-            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
-        elif self.metric == 'ours':
-            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
-        table = {}
-        for metric in result:
-            table[metric['name']] = [metric['value']]
-        table = tabulate(table, headers='keys')
-
-        if not only_metrics:
-            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
-            with open(os.path.join(exp_dir, filename), 'w') as out_file:
-                json.dump(result, out_file)
-
-        return table, result
-
-    def __getitem__(self, idx):
-        return self.annotations[idx]
-
-    def __len__(self):
-        return len(self.annotations)
+import os
+import json
+import random
+
+import numpy as np
+from tabulate import tabulate
+
+from utils.lane import LaneEval
+from utils.metric import eval_json
+
+SPLIT_FILES = {
+    'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
+    'train': ['label_data_0313.json', 'label_data_0601.json'],
+    'val': ['test_label.json'],
+    'test': ['test_label.json'],
+}
+
+
+class TuSimple(object):
+    def __init__(self, split='train', max_lanes=None, root=None, metric='default'):
+        self.split = split
+        self.root = root
+        self.metric = metric
+
+        if split not in SPLIT_FILES.keys():
+            raise Exception('Split `{}` does not exist.'.format(split))
+
+        self.anno_files = [os.path.join(self.root, path) for path in SPLIT_FILES[split]]
+
+        if root is None:
+            raise Exception('Please specify the root directory')
+
+        self.img_w, self.img_h = 1280, 720
+        self.max_points = 0
+        self.load_annotations()
+
+        # Force max_lanes, used when evaluating testing with models trained on other datasets
+        if max_lanes is not None:
+            self.max_lanes = max_lanes
+
+    def get_img_heigth(self, path):
+        return 720
+
+    def get_img_width(self, path):
+        return 1280
+
+    def get_metrics(self, lanes, idx):
+        label = self.annotations[idx]
+        org_anno = label['old_anno']
+        pred = self.pred2lanes(org_anno['path'], lanes, org_anno['y_samples'])
+        _, _, _, matches, accs, dist = LaneEval.bench(pred, org_anno['org_lanes'], org_anno['y_samples'], 0, True)
+
+        return matches, accs, dist
+
+    def pred2lanes(self, path, pred, y_samples):
+        ys = np.array(y_samples) / self.img_h
+        lanes = []
+        for lane in pred:
+            if lane[0] == 0:
+                continue
+            lane_pred = np.polyval(lane[3:], ys) * self.img_w
+            lane_pred[(ys < lane[1]) | (ys > lane[2])] = -2
+            lanes.append(list(lane_pred))
+
+        return lanes
+
+    def load_annotations(self):
+        self.annotations = []
+        max_lanes = 0
+        for anno_file in self.anno_files:
+            with open(anno_file, 'r') as anno_obj:
+                lines = anno_obj.readlines()
+            for line in lines:
+                data = json.loads(line)
+                y_samples = data['h_samples']
+                gt_lanes = data['lanes']
+                lanes = [[(x, y) for (x, y) in zip(lane, y_samples) if x >= 0] for lane in gt_lanes]
+                lanes = [lane for lane in lanes if len(lane) > 0]
+                max_lanes = max(max_lanes, len(lanes))
+                self.max_points = max(self.max_points, max([len(l) for l in gt_lanes]))
+                self.annotations.append({
+                    'path': os.path.join(self.root, data['raw_file']),
+                    'org_path': data['raw_file'],
+                    'org_lanes': gt_lanes,
+                    'lanes': lanes,
+                    'aug': False,
+                    'y_samples': y_samples
+                })
+
+        if self.split == 'train':
+            random.shuffle(self.annotations)
+        print('total annos', len(self.annotations))
+        self.max_lanes = max_lanes
+
+    def transform_annotations(self, transform):
+        self.annotations = list(map(transform, self.annotations))
+
+    def pred2tusimpleformat(self, idx, pred, runtime):
+        runtime *= 1000.  # s to ms
+        img_name = self.annotations[idx]['old_anno']['org_path']
+        h_samples = self.annotations[idx]['old_anno']['y_samples']
+        lanes = self.pred2lanes(img_name, pred, h_samples)
+        output = {'raw_file': img_name, 'lanes': lanes, 'run_time': runtime}
+        return json.dumps(output)
+
+    def save_tusimple_predictions(self, predictions, runtimes, filename):
+        lines = []
+        for idx in range(len(predictions)):
+            line = self.pred2tusimpleformat(idx, predictions[idx], runtimes[idx])
+            lines.append(line)
+        with open(filename, 'w') as output_file:
+            output_file.write('\n'.join(lines))
+
+    def eval(self, exp_dir, predictions, runtimes, label=None, only_metrics=False):
+        pred_filename = '/tmp/tusimple_predictions_{}.json'.format(label)
+        self.save_tusimple_predictions(predictions, runtimes, pred_filename)
+        if self.metric == 'default':
+            result = json.loads(LaneEval.bench_one_submit(pred_filename, self.anno_files[0]))
+        elif self.metric == 'ours':
+            result = json.loads(eval_json(pred_filename, self.anno_files[0], json_type='tusimple'))
+        table = {}
+        for metric in result:
+            table[metric['name']] = [metric['value']]
+        table = tabulate(table, headers='keys')
+
+        if not only_metrics:
+            filename = 'tusimple_{}_eval_result_{}.json'.format(self.split, label)
+            with open(os.path.join(exp_dir, filename), 'w') as out_file:
+                json.dump(result, out_file)
+
+        return table, result
+
+    def __getitem__(self, idx):
+        return self.annotations[idx]
+
+    def __len__(self):
+        return len(self.annotations)
diff --git a/lib/models.py b/lib/models.py
index 15eb117..ad6e599 100644
--- a/lib/models.py
+++ b/lib/models.py
@@ -1,160 +1,160 @@
-import torch
-import torch.nn as nn
-from torchvision.models import resnet34, resnet50, resnet101
-from efficientnet_pytorch import EfficientNet
-
-
-class OutputLayer(nn.Module):
-    def __init__(self, fc, num_extra):
-        super(OutputLayer, self).__init__()
-        self.regular_outputs_layer = fc
-        self.num_extra = num_extra
-        if num_extra > 0:
-            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
-
-    def forward(self, x):
-        regular_outputs = self.regular_outputs_layer(x)
-        if self.num_extra > 0:
-            extra_outputs = self.extra_outputs_layer(x)
-        else:
-            extra_outputs = None
-
-        return regular_outputs, extra_outputs
-
-
-class PolyRegression(nn.Module):
-    def __init__(self,
-                 num_outputs,
-                 backbone,
-                 pretrained,
-                 curriculum_steps=None,
-                 extra_outputs=0,
-                 share_top_y=True,
-                 pred_category=False):
-        super(PolyRegression, self).__init__()
-        if 'efficientnet' in backbone:
-            if pretrained:
-                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
-            else:
-                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
-            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
-        elif backbone == 'resnet34':
-            self.model = resnet34(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet50':
-            self.model = resnet50(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        elif backbone == 'resnet101':
-            self.model = resnet101(pretrained=pretrained)
-            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
-            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
-        else:
-            raise NotImplementedError()
-
-        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
-        self.share_top_y = share_top_y
-        self.extra_outputs = extra_outputs
-        self.pred_category = pred_category
-        self.sigmoid = nn.Sigmoid()
-
-    def forward(self, x, epoch=None, **kwargs):
-        output, extra_outputs = self.model(x, **kwargs)
-        for i in range(len(self.curriculum_steps)):
-            if epoch is not None and epoch < self.curriculum_steps[i]:
-                output[:, -len(self.curriculum_steps) + i] = 0
-        return output, extra_outputs
-
-    def decode(self, all_outputs, labels, conf_threshold=0.5):
-        outputs, extra_outputs = all_outputs
-        if extra_outputs is not None:
-            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
-            extra_outputs = extra_outputs.argmax(dim=2)
-        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
-        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
-        outputs[outputs[:, :, 0] < conf_threshold] = 0
-
-        if False and self.share_top_y:
-            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
-
-        return outputs, extra_outputs
-
-    def loss(self,
-             outputs,
-             target,
-             conf_weight=1,
-             lower_weight=1,
-             upper_weight=1,
-             cls_weight=1,
-             poly_weight=300,
-             threshold=15 / 720.):
-        pred, extra_outputs = outputs
-        bce = nn.BCELoss()
-        mse = nn.MSELoss()
-        s = nn.Sigmoid()
-        threshold = nn.Threshold(threshold**2, 0.)
-        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
-        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
-        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
-        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
-        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
-
-        if self.share_top_y:
-            # inexistent lanes have -1e-5 as lower
-            # i'm just setting it to a high value here so that the .min below works fine
-            target_lowers[target_lowers < 0] = 1
-            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
-            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
-
-        target_lowers = target_lowers.reshape((-1, 1))
-        pred_lowers = pred_lowers.reshape((-1, 1))
-
-        target_confs = (target_categories > 0).float()
-        valid_lanes_idx = target_confs == 1
-        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
-        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
-        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
-
-        # classification loss
-        if self.pred_category and self.extra_outputs > 0:
-            ce = nn.CrossEntropyLoss()
-            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
-            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
-            pred_categories = pred_categories[target_categories > 0]
-            target_categories = target_categories[target_categories > 0]
-            cls_loss = ce(pred_categories, target_categories - 1)
-        else:
-            cls_loss = 0
-
-        # poly loss calc
-        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
-        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
-        valid_xs = target_xs >= 0
-        pred_polys = pred_polys[valid_lanes_idx_flat]
-        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
-        pred_xs.t_()
-        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
-        pred_xs = (pred_xs.t_() *
-                   weights).t()  # without this, lanes with more points would have more weight on the cost function
-        target_xs = (target_xs.t_() * weights).t()
-        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
-        poly_loss = threshold(
-            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
-
-        # applying weights to partial losses
-        poly_loss = poly_loss * poly_weight
-        lower_loss = lower_loss * lower_weight
-        upper_loss = upper_loss * upper_weight
-        cls_loss = cls_loss * cls_weight
-        conf_loss = bce(pred_confs, target_confs) * conf_weight
-
-        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
-
-        return loss, {
-            'conf': conf_loss,
-            'lower': lower_loss,
-            'upper': upper_loss,
-            'poly': poly_loss,
-            'cls_loss': cls_loss
-        }
+import torch
+import torch.nn as nn
+from torchvision.models import resnet34, resnet50, resnet101
+from efficientnet_pytorch import EfficientNet
+
+
+class OutputLayer(nn.Module):
+    def __init__(self, fc, num_extra):
+        super(OutputLayer, self).__init__()
+        self.regular_outputs_layer = fc
+        self.num_extra = num_extra
+        if num_extra > 0:
+            self.extra_outputs_layer = nn.Linear(fc.in_features, num_extra)
+
+    def forward(self, x):
+        regular_outputs = self.regular_outputs_layer(x)
+        if self.num_extra > 0:
+            extra_outputs = self.extra_outputs_layer(x)
+        else:
+            extra_outputs = None
+
+        return regular_outputs, extra_outputs
+
+
+class PolyRegression(nn.Module):
+    def __init__(self,
+                 num_outputs,
+                 backbone,
+                 pretrained,
+                 curriculum_steps=None,
+                 extra_outputs=0,
+                 share_top_y=True,
+                 pred_category=False):
+        super(PolyRegression, self).__init__()
+        if 'efficientnet' in backbone:
+            if pretrained:
+                self.model = EfficientNet.from_pretrained(backbone, num_classes=num_outputs)
+            else:
+                self.model = EfficientNet.from_name(backbone, override_params={'num_classes': num_outputs})
+            self.model._fc = OutputLayer(self.model._fc, extra_outputs)
+        elif backbone == 'resnet34':
+            self.model = resnet34(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet50':
+            self.model = resnet50(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        elif backbone == 'resnet101':
+            self.model = resnet101(pretrained=pretrained)
+            self.model.fc = nn.Linear(self.model.fc.in_features, num_outputs)
+            self.model.fc = OutputLayer(self.model.fc, extra_outputs)
+        else:
+            raise NotImplementedError()
+
+        self.curriculum_steps = [0, 0, 0, 0] if curriculum_steps is None else curriculum_steps
+        self.share_top_y = share_top_y
+        self.extra_outputs = extra_outputs
+        self.pred_category = pred_category
+        self.sigmoid = nn.Sigmoid()
+
+    def forward(self, x, epoch=None, **kwargs):
+        output, extra_outputs = self.model(x, **kwargs)
+        for i in range(len(self.curriculum_steps)):
+            if epoch is not None and epoch < self.curriculum_steps[i]:
+                output[:, -len(self.curriculum_steps) + i] = 0
+        return output, extra_outputs
+
+    def decode(self, all_outputs, labels, conf_threshold=0.5):
+        outputs, extra_outputs = all_outputs
+        if extra_outputs is not None:
+            extra_outputs = extra_outputs.reshape(labels.shape[0], 5, -1)
+            extra_outputs = extra_outputs.argmax(dim=2)
+        outputs = outputs.reshape(len(outputs), -1, 7)  # score + upper + lower + 4 coeffs = 7
+        outputs[:, :, 0] = self.sigmoid(outputs[:, :, 0])
+        outputs[outputs[:, :, 0] < conf_threshold] = 0
+
+        if False and self.share_top_y:
+            outputs[:, :, 0] = outputs[:, 0, 0].expand(outputs.shape[0], outputs.shape[1])
+
+        return outputs, extra_outputs
+
+    def loss(self,
+             outputs,
+             target,
+             conf_weight=1,
+             lower_weight=1,
+             upper_weight=1,
+             cls_weight=1,
+             poly_weight=300,
+             threshold=15 / 720.):
+        pred, extra_outputs = outputs
+        bce = nn.BCELoss()
+        mse = nn.MSELoss()
+        s = nn.Sigmoid()
+        threshold = nn.Threshold(threshold**2, 0.)
+        pred = pred.reshape(-1, target.shape[1], 1 + 2 + 4)
+        target_categories, pred_confs = target[:, :, 0].reshape((-1, 1)), s(pred[:, :, 0]).reshape((-1, 1))
+        target_uppers, pred_uppers = target[:, :, 2].reshape((-1, 1)), pred[:, :, 2].reshape((-1, 1))
+        target_points, pred_polys = target[:, :, 3:].reshape((-1, target.shape[2] - 3)), pred[:, :, 3:].reshape(-1, 4)
+        target_lowers, pred_lowers = target[:, :, 1], pred[:, :, 1]
+
+        if self.share_top_y:
+            # inexistent lanes have -1e-5 as lower
+            # i'm just setting it to a high value here so that the .min below works fine
+            target_lowers[target_lowers < 0] = 1
+            target_lowers[...] = target_lowers.min(dim=1, keepdim=True)[0]
+            pred_lowers[...] = pred_lowers[:, 0].reshape(-1, 1).expand(pred.shape[0], pred.shape[1])
+
+        target_lowers = target_lowers.reshape((-1, 1))
+        pred_lowers = pred_lowers.reshape((-1, 1))
+
+        target_confs = (target_categories > 0).float()
+        valid_lanes_idx = target_confs == 1
+        valid_lanes_idx_flat = valid_lanes_idx.reshape(-1)
+        lower_loss = mse(target_lowers[valid_lanes_idx], pred_lowers[valid_lanes_idx])
+        upper_loss = mse(target_uppers[valid_lanes_idx], pred_uppers[valid_lanes_idx])
+
+        # classification loss
+        if self.pred_category and self.extra_outputs > 0:
+            ce = nn.CrossEntropyLoss()
+            pred_categories = extra_outputs.reshape(target.shape[0] * target.shape[1], -1)
+            target_categories = target_categories.reshape(pred_categories.shape[:-1]).long()
+            pred_categories = pred_categories[target_categories > 0]
+            target_categories = target_categories[target_categories > 0]
+            cls_loss = ce(pred_categories, target_categories - 1)
+        else:
+            cls_loss = 0
+
+        # poly loss calc
+        target_xs = target_points[valid_lanes_idx_flat, :target_points.shape[1] // 2]
+        ys = target_points[valid_lanes_idx_flat, target_points.shape[1] // 2:].t()
+        valid_xs = target_xs >= 0
+        pred_polys = pred_polys[valid_lanes_idx_flat]
+        pred_xs = pred_polys[:, 0] * ys**3 + pred_polys[:, 1] * ys**2 + pred_polys[:, 2] * ys + pred_polys[:, 3]
+        pred_xs.t_()
+        weights = (torch.sum(valid_xs, dtype=torch.float32) / torch.sum(valid_xs, dim=1, dtype=torch.float32))**0.5
+        pred_xs = (pred_xs.t_() *
+                   weights).t()  # without this, lanes with more points would have more weight on the cost function
+        target_xs = (target_xs.t_() * weights).t()
+        poly_loss = mse(pred_xs[valid_xs], target_xs[valid_xs]) / valid_lanes_idx.sum()
+        poly_loss = threshold(
+            (pred_xs[valid_xs] - target_xs[valid_xs])**2).sum() / (valid_lanes_idx.sum() * valid_xs.sum())
+
+        # applying weights to partial losses
+        poly_loss = poly_loss * poly_weight
+        lower_loss = lower_loss * lower_weight
+        upper_loss = upper_loss * upper_weight
+        cls_loss = cls_loss * cls_weight
+        conf_loss = bce(pred_confs, target_confs) * conf_weight
+
+        loss = conf_loss + lower_loss + upper_loss + poly_loss + cls_loss
+
+        return loss, {
+            'conf': conf_loss,
+            'lower': lower_loss,
+            'upper': upper_loss,
+            'poly': poly_loss,
+            'cls_loss': cls_loss
+        }
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..3ba5b3a 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,16 +1,15 @@
-lxml==4.6.2
-torchvision==0.5.0
-xmljson==0.2.0
-scipy==1.4.1
-tabulate==0.8.6
-numpy==1.18.1
-ujson==1.35
-matplotlib==3.1.3
-imgaug==0.4.0
-tqdm==4.43.0
-opencv_python==4.2.0.32
-efficientnet_pytorch==0.6.3
-torch==1.4.0
-progressbar33==2.4
-PyYAML==5.3.1
-scikit-learn==0.21.3
+lxml==4.6.2
+torchvision==0.5.0
+xmljson==0.2.0
+scipy==1.4.1
+tabulate==0.8.6
+numpy==1.18.1
+ujson==1.35
+matplotlib==3.1.3
+imgaug==0.4.0
+tqdm==4.43.0
+opencv_python==4.2.0.32
+efficientnet_pytorch==0.6.3
+progressbar33==2.4
+PyYAML==5.3.1
+scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..fc03ee3 100644
--- a/test.py
+++ b/test.py
@@ -1,166 +1,167 @@
-import os
-import sys
-import random
-import logging
-import argparse
-import subprocess
-from time import time
-
-import cv2
-import numpy as np
-import torch
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
-    if verbose:
-        logging.info("Starting testing.")
-
-    # Test the model
-    if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
-
-    model.eval()
-    criterion_parameters = cfg.get_loss_parameters()
-    test_parameters = cfg.get_test_parameters()
-    criterion = model.loss
-    loss = 0
-    total_iters = 0
-    test_t0 = time()
-    loss_dict = {}
-    with torch.no_grad():
-        for idx, (images, labels, img_idxs) in enumerate(test_loader):
-            if max_batches is not None and idx >= max_batches:
-                break
-            if idx % 1 == 0 and verbose:
-                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
-            images = images.to(device)
-            labels = labels.to(device)
-
-            t0 = time()
-            outputs = model(images)
-            t = time() - t0
-            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            loss += loss_i.item()
-            total_iters += 1
-            for key in loss_dict_i:
-                if key not in loss_dict:
-                    loss_dict[key] = 0
-                loss_dict[key] += loss_dict_i[key]
-
-            outputs = model.decode(outputs, labels, **test_parameters)
-
-            if evaluator is not None:
-                lane_outputs, _ = outputs
-                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
-            if view:
-                outputs, extra_outputs = outputs
-                preds = test_loader.dataset.draw_annotation(
-                    idx,
-                    pred=outputs[0].cpu().numpy(),
-                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
-                cv2.imshow('pred', preds)
-                cv2.waitKey(0)
-
-    if verbose:
-        logging.info("Testing time: {:.4f}".format(time() - test_t0))
-    out_line = []
-    for key in loss_dict:
-        loss_dict[key] /= total_iters
-        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
-    if verbose:
-        logging.info(', '.join(out_line))
-
-    return evaluator, loss / total_iters
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Lane regression")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
-    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
-    parser.add_argument("--view", action="store_true", help="Show predictions")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    # Set up logging
-    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
-
-    # Model
-    model = cfg.get_model().to(device)
-    test_epoch = args.epoch
-
-    # Get data set
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size if args.view is False else 1,
-                                              shuffle=False,
-                                              num_workers=8)
-    # Eval results
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import logging
+import argparse
+import subprocess
+from time import time
+
+import cv2
+import numpy as np
+import torch
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=None, verbose=True):
+    if verbose:
+        logging.info("Starting testing.")
+
+    # Test the model
+    if epoch > 0:
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
+
+    model.eval()
+    criterion_parameters = cfg.get_loss_parameters()
+    test_parameters = cfg.get_test_parameters()
+    criterion = model.loss
+    loss = 0
+    total_iters = 0
+    test_t0 = time()
+    loss_dict = {}
+    with torch.no_grad():
+        for idx, (images, labels, img_idxs) in enumerate(test_loader):
+            if max_batches is not None and idx >= max_batches:
+                break
+            if idx % 1 == 0 and verbose:
+                logging.info("Testing iteration: {}/{}".format(idx + 1, len(test_loader)))
+            images = images.to(device)
+            labels = labels.to(device)
+
+            t0 = time()
+            outputs = model(images)
+            t = time() - t0
+            loss_i, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            loss += loss_i.item()
+            total_iters += 1
+            for key in loss_dict_i:
+                if key not in loss_dict:
+                    loss_dict[key] = 0
+                loss_dict[key] += loss_dict_i[key]
+
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            if evaluator is not None:
+                lane_outputs, _ = outputs
+                evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
+            if view:
+                outputs, extra_outputs = outputs
+                print(outputs.shape)
+                preds = test_loader.dataset.draw_annotation(
+                    idx,
+                    pred=outputs[0].cpu().numpy(),
+                    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+                cv2.imshow('pred', preds)
+                cv2.waitKey(0)
+
+    if verbose:
+        logging.info("Testing time: {:.4f}".format(time() - test_t0))
+    out_line = []
+    for key in loss_dict:
+        loss_dict[key] /= total_iters
+        out_line.append('{}: {:.4f}'.format(key, loss_dict[key]))
+    if verbose:
+        logging.info(', '.join(out_line))
+
+    return evaluator, loss / total_iters
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--epoch", type=int, default=None, help="Epoch to test the model on")
+    parser.add_argument("--batch_size", type=int, help="Number of images per batch")
+    parser.add_argument("--view", action="store_true", help="Show predictions")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    # Set up logging
+    exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"] if args.batch_size is None else args.batch_size
+
+    # Model
+    model = cfg.get_model().to(device)
+    test_epoch = args.epoch
+
+    # Get data set
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size if args.view is False else 1,
+                                              shuffle=False,
+                                              num_workers=8)
+    # Eval results
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/train.py b/train.py
index 3753aed..d066d7e 100644
--- a/train.py
+++ b/train.py
@@ -1,271 +1,271 @@
-import os
-import sys
-import random
-import shutil
-import logging
-import argparse
-import subprocess
-from time import time
-
-import numpy as np
-import torch
-
-from test import test
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-
-def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
-    # Get initial train state
-    optimizer = cfg.get_optimizer(model.parameters())
-    scheduler = cfg.get_lr_scheduler(optimizer)
-    starting_epoch = 1
-
-    if train_state is not None:
-        model.load_state_dict(train_state['model'])
-        optimizer.load_state_dict(train_state['optimizer'])
-        scheduler.load_state_dict(train_state['lr_scheduler'])
-        starting_epoch = train_state['epoch'] + 1
-        scheduler.step(starting_epoch)
-
-    # Train the model
-    criterion_parameters = cfg.get_loss_parameters()
-    criterion = model.loss
-    total_step = len(train_loader)
-    ITER_LOG_INTERVAL = cfg['iter_log_interval']
-    ITER_TIME_WINDOW = cfg['iter_time_window']
-    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
-    t0 = time()
-    total_iter = 0
-    iter_times = []
-    logging.info("Starting training.")
-    for epoch in range(starting_epoch, num_epochs + 1):
-        epoch_t0 = time()
-        logging.info("Beginning epoch {}".format(epoch))
-        accum_loss = 0
-        for i, (images, labels, img_idxs) in enumerate(train_loader):
-            total_iter += 1
-            iter_t0 = time()
-            images = images.to(device)
-            labels = labels.to(device)
-
-            # Forward pass
-            outputs = model(images, epoch=epoch)
-            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
-            accum_loss += loss.item()
-
-            # Backward and optimize
-            optimizer.zero_grad()
-            loss.backward()
-            optimizer.step()
-
-            iter_times.append(time() - iter_t0)
-            if len(iter_times) > 100:
-                iter_times = iter_times[-ITER_TIME_WINDOW:]
-            if (i + 1) % ITER_LOG_INTERVAL == 0:
-                loss_str = ', '.join(
-                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
-                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
-                    epoch,
-                    num_epochs,
-                    i + 1,
-                    total_step,
-                    accum_loss / (i + 1),
-                    loss_str,
-                    np.mean(iter_times),
-                    optimizer.param_groups[0]["lr"],
-                ))
-        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
-        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
-            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
-            save_train_state(model_path, model, optimizer, scheduler, epoch)
-        if val_loader is not None:
-            evaluator = Evaluator(val_loader.dataset, exp_root)
-            evaluator, val_loss = test(
-                model,
-                val_loader,
-                evaluator,
-                None,
-                cfg,
-                view=False,
-                epoch=-1,
-                verbose=False,
-            )
-            _, results = evaluator.eval(label=None, only_metrics=True)
-            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
-            model.train()
-        scheduler.step()
-    logging.info("Training time: {:.4f}".format(time() - t0))
-
-    return model
-
-
-def save_train_state(path, model, optimizer, lr_scheduler, epoch):
-    train_state = {
-        'model': model.state_dict(),
-        'optimizer': optimizer.state_dict(),
-        'lr_scheduler': lr_scheduler.state_dict(),
-        'epoch': epoch
-    }
-
-    torch.save(train_state, path)
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
-    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
-    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
-    parser.add_argument("--resume", action="store_true", help="Resume training")
-    parser.add_argument("--validate", action="store_true", help="Validate model during training")
-    parser.add_argument("--deterministic",
-                        action="store_true",
-                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
-
-    return parser.parse_args()
-
-
-def get_code_state():
-    state = "Git hash: {}".format(
-        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
-    state += '\n*************\nGit diff:\n*************\n'
-    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
-
-    return state
-
-
-def setup_exp_dir(exps_dir, exp_name, cfg_path):
-    dirs = ["models"]
-    exp_root = os.path.join(exps_dir, exp_name)
-
-    for dirname in dirs:
-        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
-
-    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
-    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
-        file.write(get_code_state())
-
-    return exp_root
-
-
-def get_exp_train_state(exp_root):
-    models_dir = os.path.join(exp_root, "models")
-    models = os.listdir(models_dir)
-    last_epoch, last_modelname = sorted(
-        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
-        key=lambda x: x[0],
-    )[-1]
-    train_state = torch.load(os.path.join(models_dir, last_modelname))
-
-    return train_state
-
-
-def log_on_exception(exc_type, exc_value, exc_traceback):
-    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    cfg = Config(args.cfg)
-
-    # Set up seeds
-    torch.manual_seed(cfg['seed'])
-    np.random.seed(cfg['seed'])
-    random.seed(cfg['seed'])
-
-    if args.deterministic:
-        torch.backends.cudnn.deterministic = True
-        torch.backends.cudnn.benchmark = False
-
-    # Set up experiment
-    if not args.resume:
-        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
-    else:
-        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-
-    sys.excepthook = log_on_exception
-
-    logging.info("Experiment name: {}".format(args.exp_name))
-    logging.info("Config:\n" + str(cfg))
-    logging.info("Args:\n" + str(args))
-
-    # Get data sets
-    train_dataset = cfg.get_dataset("train")
-
-    # Device configuration
-    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
-
-    # Hyper parameters
-    num_epochs = cfg["epochs"]
-    batch_size = cfg["batch_size"]
-
-    # Model
-    model = cfg.get_model().to(device)
-
-    train_state = None
-    if args.resume:
-        train_state = get_exp_train_state(exp_root)
-
-    # Data loader
-    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
-                                               batch_size=batch_size,
-                                               shuffle=True,
-                                               num_workers=8)
-
-    if args.validate:
-        val_dataset = cfg.get_dataset("val")
-        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
-                                                 batch_size=batch_size,
-                                                 shuffle=False,
-                                                 num_workers=8)
-    # Train regressor
-    try:
-        model = train(
-            model,
-            train_loader,
-            exp_root,
-            cfg,
-            val_loader=val_loader if args.validate else None,
-            train_state=train_state,
-        )
-    except KeyboardInterrupt:
-        logging.info("Training session terminated.")
-    test_epoch = -1
-    if cfg['backup'] is not None:
-        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
-
-    # Eval model after training
-    test_dataset = cfg.get_dataset("test")
-
-    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
-                                              batch_size=batch_size,
-                                              shuffle=False,
-                                              num_workers=8)
-
-    evaluator = Evaluator(test_loader.dataset, exp_root)
-
-    logging.basicConfig(
-        format="[%(asctime)s] [%(levelname)s] %(message)s",
-        level=logging.INFO,
-        handlers=[
-            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
-            logging.StreamHandler(),
-        ],
-    )
-    logging.info('Code state:\n {}'.format(get_code_state()))
-    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
-    logging.info("Mean test loss: {:.4f}".format(mean_loss))
-
-    evaluator.exp_name = args.exp_name
-
-    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
-
-    logging.info(eval_str)
+import os
+import sys
+import random
+import shutil
+import logging
+import argparse
+import subprocess
+from time import time
+
+import numpy as np
+import torch
+
+from test import test
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+
+def train(model, train_loader, exp_dir, cfg, val_loader, train_state=None):
+    # Get initial train state
+    optimizer = cfg.get_optimizer(model.parameters())
+    scheduler = cfg.get_lr_scheduler(optimizer)
+    starting_epoch = 1
+
+    if train_state is not None:
+        model.load_state_dict(train_state['model'])
+        optimizer.load_state_dict(train_state['optimizer'])
+        scheduler.load_state_dict(train_state['lr_scheduler'])
+        starting_epoch = train_state['epoch'] + 1
+        scheduler.step(starting_epoch)
+
+    # Train the model
+    criterion_parameters = cfg.get_loss_parameters()
+    criterion = model.loss
+    total_step = len(train_loader)
+    ITER_LOG_INTERVAL = cfg['iter_log_interval']
+    ITER_TIME_WINDOW = cfg['iter_time_window']
+    MODEL_SAVE_INTERVAL = cfg['model_save_interval']
+    t0 = time()
+    total_iter = 0
+    iter_times = []
+    logging.info("Starting training.")
+    for epoch in range(starting_epoch, num_epochs + 1):
+        epoch_t0 = time()
+        logging.info("Beginning epoch {}".format(epoch))
+        accum_loss = 0
+        for i, (images, labels, img_idxs) in enumerate(train_loader):
+            total_iter += 1
+            iter_t0 = time()
+            images = images.to(device)
+            labels = labels.to(device)
+
+            # Forward pass
+            outputs = model(images, epoch=epoch)
+            loss, loss_dict_i = criterion(outputs, labels, **criterion_parameters)
+            accum_loss += loss.item()
+
+            # Backward and optimize
+            optimizer.zero_grad()
+            loss.backward()
+            optimizer.step()
+
+            iter_times.append(time() - iter_t0)
+            if len(iter_times) > 100:
+                iter_times = iter_times[-ITER_TIME_WINDOW:]
+            if (i + 1) % ITER_LOG_INTERVAL == 0:
+                loss_str = ', '.join(
+                    ['{}: {:.4f}'.format(loss_name, loss_dict_i[loss_name]) for loss_name in loss_dict_i])
+                logging.info("Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({}), s/iter: {:.4f}, lr: {:.1e}".format(
+                    epoch,
+                    num_epochs,
+                    i + 1,
+                    total_step,
+                    accum_loss / (i + 1),
+                    loss_str,
+                    np.mean(iter_times),
+                    optimizer.param_groups[0]["lr"],
+                ))
+        logging.info("Epoch time: {:.4f}".format(time() - epoch_t0))
+        if epoch % MODEL_SAVE_INTERVAL == 0 or epoch == num_epochs:
+            model_path = os.path.join(exp_dir, "models", "model_{:03d}.pt".format(epoch))
+            save_train_state(model_path, model, optimizer, scheduler, epoch)
+        if val_loader is not None:
+            evaluator = Evaluator(val_loader.dataset, exp_root)
+            evaluator, val_loss = test(
+                model,
+                val_loader,
+                evaluator,
+                None,
+                cfg,
+                view=False,
+                epoch=-1,
+                verbose=False,
+            )
+            _, results = evaluator.eval(label=None, only_metrics=True)
+            logging.info("Epoch [{}/{}], Val loss: {:.4f}".format(epoch, num_epochs, val_loss))
+            model.train()
+        scheduler.step()
+    logging.info("Training time: {:.4f}".format(time() - t0))
+
+    return model
+
+
+def save_train_state(path, model, optimizer, lr_scheduler, epoch):
+    train_state = {
+        'model': model.state_dict(),
+        'optimizer': optimizer.state_dict(),
+        'lr_scheduler': lr_scheduler.state_dict(),
+        'epoch': epoch
+    }
+
+    torch.save(train_state, path)
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Train PolyLaneNet")
+    parser.add_argument("--exp_name", default="default", help="Experiment name", required=True)
+    parser.add_argument("--cfg", default="config.yaml", help="Config file", required=True)
+    parser.add_argument("--resume", action="store_true", help="Resume training")
+    parser.add_argument("--validate", action="store_true", help="Validate model during training")
+    parser.add_argument("--deterministic",
+                        action="store_true",
+                        help="set cudnn.deterministic = True and cudnn.benchmark = False")
+
+    return parser.parse_args()
+
+
+def get_code_state():
+    state = "Git hash: {}".format(
+        subprocess.run(['git', 'rev-parse', 'HEAD'], stdout=subprocess.PIPE).stdout.decode('utf-8'))
+    state += '\n*************\nGit diff:\n*************\n'
+    state += subprocess.run(['git', 'diff'], stdout=subprocess.PIPE).stdout.decode('utf-8')
+
+    return state
+
+
+def setup_exp_dir(exps_dir, exp_name, cfg_path):
+    dirs = ["models"]
+    exp_root = os.path.join(exps_dir, exp_name)
+
+    for dirname in dirs:
+        os.makedirs(os.path.join(exp_root, dirname), exist_ok=True)
+
+    shutil.copyfile(cfg_path, os.path.join(exp_root, 'config.yaml'))
+    with open(os.path.join(exp_root, 'code_state.txt'), 'w') as file:
+        file.write(get_code_state())
+
+    return exp_root
+
+
+def get_exp_train_state(exp_root):
+    models_dir = os.path.join(exp_root, "models")
+    models = os.listdir(models_dir)
+    last_epoch, last_modelname = sorted(
+        [(int(name.split("_")[1].split(".")[0]), name) for name in models],
+        key=lambda x: x[0],
+    )[-1]
+    train_state = torch.load(os.path.join(models_dir, last_modelname))
+
+    return train_state
+
+
+def log_on_exception(exc_type, exc_value, exc_traceback):
+    logging.error("Uncaught exception", exc_info=(exc_type, exc_value, exc_traceback))
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config(args.cfg)
+
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+    if args.deterministic:
+        torch.backends.cudnn.deterministic = True
+        torch.backends.cudnn.benchmark = False
+
+    # Set up experiment
+    if not args.resume:
+        exp_root = setup_exp_dir(cfg['exps_dir'], args.exp_name, args.cfg)
+    else:
+        exp_root = os.path.join(cfg['exps_dir'], os.path.basename(os.path.normpath(args.exp_name)))
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+
+    sys.excepthook = log_on_exception
+
+    logging.info("Experiment name: {}".format(args.exp_name))
+    logging.info("Config:\n" + str(cfg))
+    logging.info("Args:\n" + str(args))
+
+    # Get data sets
+    train_dataset = cfg.get_dataset("train")
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    # Model
+    model = cfg.get_model().to(device)
+
+    train_state = None
+    if args.resume:
+        train_state = get_exp_train_state(exp_root)
+
+    # Data loader
+    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
+                                               batch_size=batch_size,
+                                               shuffle=True,
+                                               num_workers=8)
+
+    if args.validate:
+        val_dataset = cfg.get_dataset("val")
+        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
+                                                 batch_size=batch_size,
+                                                 shuffle=False,
+                                                 num_workers=8)
+    # Train regressor
+    try:
+        model = train(
+            model,
+            train_loader,
+            exp_root,
+            cfg,
+            val_loader=val_loader if args.validate else None,
+            train_state=train_state,
+        )
+    except KeyboardInterrupt:
+        logging.info("Training session terminated.")
+    test_epoch = -1
+    if cfg['backup'] is not None:
+        subprocess.run(['rclone', 'copy', exp_root, '{}/{}'.format(cfg['backup'], args.exp_name)])
+
+    # Eval model after training
+    test_dataset = cfg.get_dataset("test")
+
+    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
+                                              batch_size=batch_size,
+                                              shuffle=False,
+                                              num_workers=8)
+
+    evaluator = Evaluator(test_loader.dataset, exp_root)
+
+    logging.basicConfig(
+        format="[%(asctime)s] [%(levelname)s] %(message)s",
+        level=logging.INFO,
+        handlers=[
+            logging.FileHandler(os.path.join(exp_root, "test_log.txt")),
+            logging.StreamHandler(),
+        ],
+    )
+    logging.info('Code state:\n {}'.format(get_code_state()))
+    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=False)
+    logging.info("Mean test loss: {:.4f}".format(mean_loss))
+
+    evaluator.exp_name = args.exp_name
+
+    eval_str, _ = evaluator.eval(label='{}_{}'.format(os.path.basename(args.exp_name), test_epoch))
+
+    logging.info(eval_str)
diff --git a/utils/evaluator.py b/utils/evaluator.py
index b4d51a1..9793857 100644
--- a/utils/evaluator.py
+++ b/utils/evaluator.py
@@ -1,33 +1,33 @@
-import sys
-
-import numpy as np
-
-from lib.datasets.lane_dataset import LaneDataset
-
-EXPS_DIR = 'experiments'
-
-
-class Evaluator(object):
-    def __init__(self, dataset, exp_dir, poly_degree=3):
-        self.dataset = dataset
-        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
-        self.predictions = None
-        self.runtimes = np.zeros(len(dataset))
-        self.loss = np.zeros(len(dataset))
-        self.exp_dir = exp_dir
-        self.new_preds = False
-
-    def add_prediction(self, idx, pred, runtime):
-        if self.predictions is None:
-            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
-        self.predictions[idx, :pred.shape[1], :] = pred
-        self.runtimes[idx] = runtime
-        self.new_preds = True
-
-    def eval(self, **kwargs):
-        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
-
-
-if __name__ == "__main__":
-    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
-    evaluator.tusimple_eval()
+import sys
+
+import numpy as np
+
+from lib.datasets.lane_dataset import LaneDataset
+
+EXPS_DIR = 'experiments'
+
+
+class Evaluator(object):
+    def __init__(self, dataset, exp_dir, poly_degree=3):
+        self.dataset = dataset
+        # self.predictions = np.zeros((len(dataset.annotations), dataset.max_lanes, 4 + poly_degree))
+        self.predictions = None
+        self.runtimes = np.zeros(len(dataset))
+        self.loss = np.zeros(len(dataset))
+        self.exp_dir = exp_dir
+        self.new_preds = False
+
+    def add_prediction(self, idx, pred, runtime):
+        if self.predictions is None:
+            self.predictions = np.zeros((len(self.dataset.annotations), pred.shape[1], pred.shape[2]))
+        self.predictions[idx, :pred.shape[1], :] = pred
+        self.runtimes[idx] = runtime
+        self.new_preds = True
+
+    def eval(self, **kwargs):
+        return self.dataset.dataset.eval(self.exp_dir, self.predictions, self.runtimes, **kwargs)
+
+
+if __name__ == "__main__":
+    evaluator = Evaluator(LaneDataset(split='test'), exp_dir=sys.argv[1])
+    evaluator.tusimple_eval()
diff --git a/utils/gen_video.py b/utils/gen_video.py
index b4a3b4d..8dff9a8 100644
--- a/utils/gen_video.py
+++ b/utils/gen_video.py
@@ -1,67 +1,67 @@
-import pickle
-import argparse
-
-import cv2
-from tqdm import tqdm
-
-from lib.config import Config
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
-    parser.add_argument("--pred", help=".pkl file to load predictions from")
-    parser.add_argument("--cfg", default="config.yaml", help="Config file")
-    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
-    parser.add_argument("--out", default="video.avi", help="Output filename")
-    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
-
-    return parser.parse_args()
-
-
-def add_cover_img(video, cover_path, frames=90):
-    cover = cv2.imread(cover_path)
-    for _ in range(frames):
-        video.write(cover)
-
-
-def create_video(filename, width, height, fps=30):
-    fourcc = cv2.VideoWriter_fourcc(*'MP42')
-    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
-
-    return video
-
-
-def main():
-    args = parse_args()
-    cfg = Config(args.cfg)
-    dataset = cfg.get_dataset('test')
-    height, width = cfg['datasets']['test']['parameters']['img_size']
-    print('Using resolution {}x{}'.format(width, height))
-    if not args.view:
-        video = create_video(args.out, width, height)
-    # add_cover_img(video, args.cover)
-    with open(args.pred, "rb") as pred_file:
-        predictions = pickle.load(pred_file)
-
-    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
-        if idx < 2200: continue
-        if idx > 3000: break
-        det_pred, cls_pred = pred
-        assert det_pred.shape[0] == 1  # batch size == 1
-        frame = dataset.draw_annotation(idx,
-                                        pred=det_pred[0].cpu().numpy(),
-                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
-        assert frame.shape[:2] == (height, width)
-        if args.view:
-            cv2.imshow('frame', frame)
-            cv2.waitKey(0)
-        else:
-            video.write(frame)
-
-    if not args.view:
-        video.release()
-        print('Video saved as {}'.format(args.out))
-
-
-if __name__ == '__main__':
-    main()
+import pickle
+import argparse
+
+import cv2
+from tqdm import tqdm
+
+from lib.config import Config
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Tool to generate qualitative results videos")
+    parser.add_argument("--pred", help=".pkl file to load predictions from")
+    parser.add_argument("--cfg", default="config.yaml", help="Config file")
+    parser.add_argument("--cover", default="tusimple_cover.png", help="Cover image file")
+    parser.add_argument("--out", default="video.avi", help="Output filename")
+    parser.add_argument("--view", action="store_true", help="Show predictions instead of creating video")
+
+    return parser.parse_args()
+
+
+def add_cover_img(video, cover_path, frames=90):
+    cover = cv2.imread(cover_path)
+    for _ in range(frames):
+        video.write(cover)
+
+
+def create_video(filename, width, height, fps=30):
+    fourcc = cv2.VideoWriter_fourcc(*'MP42')
+    video = cv2.VideoWriter(filename, fourcc, float(fps), (width, height))
+
+    return video
+
+
+def main():
+    args = parse_args()
+    cfg = Config(args.cfg)
+    dataset = cfg.get_dataset('test')
+    height, width = cfg['datasets']['test']['parameters']['img_size']
+    print('Using resolution {}x{}'.format(width, height))
+    if not args.view:
+        video = create_video(args.out, width, height)
+    # add_cover_img(video, args.cover)
+    with open(args.pred, "rb") as pred_file:
+        predictions = pickle.load(pred_file)
+
+    for idx, pred in tqdm(zip(range(len(dataset)), predictions), total=len(dataset)):
+        if idx < 2200: continue
+        if idx > 3000: break
+        det_pred, cls_pred = pred
+        assert det_pred.shape[0] == 1  # batch size == 1
+        frame = dataset.draw_annotation(idx,
+                                        pred=det_pred[0].cpu().numpy(),
+                                        cls_pred=cls_pred[0].cpu().numpy() if cls_pred is not None else None)
+        assert frame.shape[:2] == (height, width)
+        if args.view:
+            cv2.imshow('frame', frame)
+            cv2.waitKey(0)
+        else:
+            video.write(frame)
+
+    if not args.view:
+        video.release()
+        print('Video saved as {}'.format(args.out))
+
+
+if __name__ == '__main__':
+    main()
diff --git a/utils/lane.py b/utils/lane.py
index 863a92a..6fd2a7d 100644
--- a/utils/lane.py
+++ b/utils/lane.py
@@ -1,133 +1,133 @@
-import numpy as np
-import ujson as json
-from sklearn.linear_model import LinearRegression
-
-
-class LaneEval(object):
-    lr = LinearRegression()
-    pixel_thresh = 20
-    pt_thresh = 0.85
-
-    @staticmethod
-    def get_angle(xs, y_samples):
-        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
-        if len(xs) > 1:
-            LaneEval.lr.fit(ys[:, None], xs)
-            k = LaneEval.lr.coef_[0]
-            theta = np.arctan(k)
-        else:
-            theta = 0
-        return theta
-
-    @staticmethod
-    def line_accuracy(pred, gt, thresh):
-        pred = np.array([p if p >= 0 else -100 for p in pred])
-        gt = np.array([g if g >= 0 else -100 for g in gt])
-        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
-
-    @staticmethod
-    def distances(pred, gt):
-        return np.abs(pred - gt)
-
-    @staticmethod
-    def bench(pred, gt, y_samples, running_time, get_matches=False):
-        if any(len(p) != len(y_samples) for p in pred):
-            raise Exception('Format of lanes error.')
-        if running_time > 20000 or len(gt) + 2 < len(pred):
-            return 0., 0., 1.
-        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
-        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
-        line_accs = []
-        fp, fn = 0., 0.
-        matched = 0.
-        my_matches = [False] * len(pred)
-        my_accs = [0] * len(pred)
-        my_dists = [None] * len(pred)
-        for x_gts, thresh in zip(gt, threshs):
-            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
-            my_accs = np.maximum(my_accs, accs)
-            max_acc = np.max(accs) if len(accs) > 0 else 0.
-            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
-            if len(accs) > 0:
-                my_dists[np.argmax(accs)] = {
-                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
-                    'dists': list(my_dist[np.argmax(accs)])
-                }
-
-            if max_acc < LaneEval.pt_thresh:
-                fn += 1
-            else:
-                my_matches[np.argmax(accs)] = True
-                matched += 1
-            line_accs.append(max_acc)
-        fp = len(pred) - matched
-        if len(gt) > 4 and fn > 0:
-            fn -= 1
-        s = sum(line_accs)
-        if len(gt) > 4:
-            s -= min(line_accs)
-        if get_matches:
-            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
-                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
-        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
-
-    @staticmethod
-    def bench_one_submit(pred_file, gt_file):
-        try:
-            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-        except BaseException as e:
-            raise Exception('Fail to load json file of the prediction.')
-        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-        if len(json_gt) != len(json_pred):
-            raise Exception('We do not get the predictions of all the test tasks')
-        gts = {l['raw_file']: l for l in json_gt}
-        accuracy, fp, fn = 0., 0., 0.
-        run_times = []
-        for pred in json_pred:
-            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
-                raise Exception('raw_file or lanes or run_time not in some predictions.')
-            raw_file = pred['raw_file']
-            pred_lanes = pred['lanes']
-            run_time = pred['run_time']
-            run_times.append(run_time)
-            if raw_file not in gts:
-                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-            gt = gts[raw_file]
-            gt_lanes = gt['lanes']
-            y_samples = gt['h_samples']
-            try:
-                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
-            except BaseException as e:
-                raise Exception('Format of lanes error.')
-            accuracy += a
-            fp += p
-            fn += n
-        num = len(gts)
-        # the first return parameter is the default ranking parameter
-        return json.dumps([{
-            'name': 'Accuracy',
-            'value': accuracy / num,
-            'order': 'desc'
-        }, {
-            'name': 'FP',
-            'value': fp / num,
-            'order': 'asc'
-        }, {
-            'name': 'FN',
-            'value': fn / num,
-            'order': 'asc'
-        }, {
-            'name': 'FPS',
-            'value': 1000. / np.mean(run_times)
-        }])
-
-
-if __name__ == '__main__':
-    import sys
-    try:
-        if len(sys.argv) != 3:
-            raise Exception('Invalid input arguments')
-        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
-    except Exception as e:
-        print(e)
-        # sys.exit(e.message)
+import numpy as np
+import ujson as json
+from sklearn.linear_model import LinearRegression
+
+
+class LaneEval(object):
+    lr = LinearRegression()
+    pixel_thresh = 20
+    pt_thresh = 0.85
+
+    @staticmethod
+    def get_angle(xs, y_samples):
+        xs, ys = xs[xs >= 0], y_samples[xs >= 0]
+        if len(xs) > 1:
+            LaneEval.lr.fit(ys[:, None], xs)
+            k = LaneEval.lr.coef_[0]
+            theta = np.arctan(k)
+        else:
+            theta = 0
+        return theta
+
+    @staticmethod
+    def line_accuracy(pred, gt, thresh):
+        pred = np.array([p if p >= 0 else -100 for p in pred])
+        gt = np.array([g if g >= 0 else -100 for g in gt])
+        return np.sum(np.where(np.abs(pred - gt) < thresh, 1., 0.)) / len(gt)
+
+    @staticmethod
+    def distances(pred, gt):
+        return np.abs(pred - gt)
+
+    @staticmethod
+    def bench(pred, gt, y_samples, running_time, get_matches=False):
+        if any(len(p) != len(y_samples) for p in pred):
+            raise Exception('Format of lanes error.')
+        if running_time > 20000 or len(gt) + 2 < len(pred):
+            return 0., 0., 1.
+        angles = [LaneEval.get_angle(np.array(x_gts), np.array(y_samples)) for x_gts in gt]
+        threshs = [LaneEval.pixel_thresh / np.cos(angle) for angle in angles]
+        line_accs = []
+        fp, fn = 0., 0.
+        matched = 0.
+        my_matches = [False] * len(pred)
+        my_accs = [0] * len(pred)
+        my_dists = [None] * len(pred)
+        for x_gts, thresh in zip(gt, threshs):
+            accs = [LaneEval.line_accuracy(np.array(x_preds), np.array(x_gts), thresh) for x_preds in pred]
+            my_accs = np.maximum(my_accs, accs)
+            max_acc = np.max(accs) if len(accs) > 0 else 0.
+            my_dist = [LaneEval.distances(np.array(x_preds), np.array(x_gts)) for x_preds in pred]
+            if len(accs) > 0:
+                my_dists[np.argmax(accs)] = {
+                    'y_gts': list(np.array(y_samples)[np.array(x_gts) >= 0].astype(int)),
+                    'dists': list(my_dist[np.argmax(accs)])
+                }
+
+            if max_acc < LaneEval.pt_thresh:
+                fn += 1
+            else:
+                my_matches[np.argmax(accs)] = True
+                matched += 1
+            line_accs.append(max_acc)
+        fp = len(pred) - matched
+        if len(gt) > 4 and fn > 0:
+            fn -= 1
+        s = sum(line_accs)
+        if len(gt) > 4:
+            s -= min(line_accs)
+        if get_matches:
+            return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(
+                min(len(gt), 4.), 1.), my_matches, my_accs, my_dists
+        return s / max(min(4.0, len(gt)), 1.), fp / len(pred) if len(pred) > 0 else 0., fn / max(min(len(gt), 4.), 1.)
+
+    @staticmethod
+    def bench_one_submit(pred_file, gt_file):
+        try:
+            json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+        except BaseException as e:
+            raise Exception('Fail to load json file of the prediction.')
+        json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+        if len(json_gt) != len(json_pred):
+            raise Exception('We do not get the predictions of all the test tasks')
+        gts = {l['raw_file']: l for l in json_gt}
+        accuracy, fp, fn = 0., 0., 0.
+        run_times = []
+        for pred in json_pred:
+            if 'raw_file' not in pred or 'lanes' not in pred or 'run_time' not in pred:
+                raise Exception('raw_file or lanes or run_time not in some predictions.')
+            raw_file = pred['raw_file']
+            pred_lanes = pred['lanes']
+            run_time = pred['run_time']
+            run_times.append(run_time)
+            if raw_file not in gts:
+                raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+            gt = gts[raw_file]
+            gt_lanes = gt['lanes']
+            y_samples = gt['h_samples']
+            try:
+                a, p, n = LaneEval.bench(pred_lanes, gt_lanes, y_samples, run_time)
+            except BaseException as e:
+                raise Exception('Format of lanes error.')
+            accuracy += a
+            fp += p
+            fn += n
+        num = len(gts)
+        # the first return parameter is the default ranking parameter
+        return json.dumps([{
+            'name': 'Accuracy',
+            'value': accuracy / num,
+            'order': 'desc'
+        }, {
+            'name': 'FP',
+            'value': fp / num,
+            'order': 'asc'
+        }, {
+            'name': 'FN',
+            'value': fn / num,
+            'order': 'asc'
+        }, {
+            'name': 'FPS',
+            'value': 1000. / np.mean(run_times)
+        }])
+
+
+if __name__ == '__main__':
+    import sys
+    try:
+        if len(sys.argv) != 3:
+            raise Exception('Invalid input arguments')
+        print(LaneEval.bench_one_submit(sys.argv[1], sys.argv[2]))
+    except Exception as e:
+        print(e)
+        # sys.exit(e.message)
diff --git a/utils/metric.py b/utils/metric.py
index f2c066d..9fe866e 100644
--- a/utils/metric.py
+++ b/utils/metric.py
@@ -1,177 +1,177 @@
-import argparse
-from pprint import pprint
-
-import cv2
-import numpy as np
-import ujson as json
-from tqdm import tqdm
-from tabulate import tabulate
-from scipy.spatial import distance
-
-
-def show_preds(pred, gt):
-    img = np.zeros((720, 1280, 3), dtype=np.uint8)
-    print(len(gt), 'gts and', len(pred), 'preds')
-    for lane in gt:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
-    for lane in pred:
-        for p in lane:
-            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
-    cv2.imshow('img', img)
-    cv2.waitKey(0)
-
-
-def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
-    pred = np.vstack([pred_x, pred_y]).T
-    gt = np.vstack([gt_x, gt_y]).T
-
-    # pred = pred[pred[:, 0] > 0][:3, :]
-    # gt = gt[gt[:, 0] > 0][:5, :]
-
-    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
-
-    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
-    dist /= np.max(gt_y) - np.min(gt_y)
-    return dist
-
-
-def area_metric(pred, gt, debug=None):
-    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
-    if len(pred) == 0:
-        return 0., 0., len(gt)
-    line_dists = []
-    fp = 0.
-    matched = 0.
-    gt_matches = [False] * len(gt)
-    pred_matches = [False] * len(pred)
-    pred_dists = [None] * len(pred)
-
-    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
-    for i_gt, gt_points in enumerate(gt):
-        x_gts = [x for x, _ in gt_points]
-        y_gts = [y for _, y in gt_points]
-        for i_pred, pred_points in enumerate(pred):
-            x_preds = [x for x, _ in pred_points]
-            y_preds = [y for _, y in pred_points]
-            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
-
-    best_preds = np.argmin(distances, axis=1)
-    best_gts = np.argmin(distances, axis=0)
-    fp = 0.
-    fn = 0.
-    dist = 0.
-    is_fp = []
-    is_fn = []
-    for i_pred, best_gt in enumerate(best_gts):
-        if best_preds[best_gt] == i_pred:
-            dist += distances[best_gt, i_pred]
-            is_fp.append(False)
-        else:
-            fp += 1
-            is_fp.append(True)
-    for i_gt, best_pred in enumerate(best_preds):
-        if best_gts[best_pred] != i_gt:
-            fn += 1
-            is_fn.append(True)
-        else:
-            is_fn.append(False)
-    if debug:
-        print('is fp')
-        print(is_fp)
-        print('is fn')
-        print(is_fn)
-        print('distances')
-        dists = np.min(distances, axis=0)
-        dists[np.array(is_fp)] = 0
-        print(dists)
-        show_preds(pred, gt)
-
-    return dist, fp, fn
-
-
-def convert_tusimple_format(json_gt):
-    output = []
-    for data in json_gt:
-        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
-                 if any(x > 0 for x in lane)]
-        output.append({
-            'raw_file': data['raw_file'],
-            'run_time': data['run_time'] if 'run_time' in data else None,
-            'lanes': lanes
-        })
-    return output
-
-
-def eval_json(pred_file, gt_file, json_type=None, debug=False):
-    try:
-        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
-    except BaseException as e:
-        raise Exception('Fail to load json file of the prediction.')
-    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
-    if len(json_gt) != len(json_pred):
-        raise Exception('We do not get the predictions of all the test tasks')
-
-    if json_type == 'tusimple':
-        for gt, pred in zip(json_gt, json_pred):
-            pred['h_samples'] = gt['h_samples']
-        json_gt = convert_tusimple_format(json_gt)
-        json_pred = convert_tusimple_format(json_pred)
-    gts = {l['raw_file']: l for l in json_gt}
-
-    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
-    for pred in tqdm(json_pred):
-        if 'raw_file' not in pred or 'lanes' not in pred:
-            raise Exception('raw_file or lanes not in some predictions.')
-        raw_file = pred['raw_file']
-        pred_lanes = pred['lanes']
-        run_time += pred['run_time'] if 'run_time' in pred else 1.
-
-        if raw_file not in gts:
-            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
-        gt = gts[raw_file]
-        gt_lanes = gt['lanes']
-
-        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
-
-        total_distance += distance
-        total_fp += fp
-        total_fn += fn
-
-    num = len(gts)
-    return json.dumps([{
-        'name': 'Distance',
-        'value': total_distance / num,
-        'order': 'desc'
-    }, {
-        'name': 'FP',
-        'value': total_fp,
-        'order': 'asc'
-    }, {
-        'name': 'FN',
-        'value': total_fn,
-        'order': 'asc'
-    }, {
-        'name': 'FPS',
-        'value': 1000. * num / run_time
-    }])
-
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(description="Compute the metrics")
-    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
-    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
-    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
-    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
-    argv = vars(parser.parse_args())
-
-    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
-
-    # pretty-print
-    table = {}
-    for metric in result:
-        if metric['name'] not in table.keys():
-            table[metric['name']] = []
-        table[metric['name']].append(metric['value'])
-    print(tabulate(table, headers='keys'))
+import argparse
+from pprint import pprint
+
+import cv2
+import numpy as np
+import ujson as json
+from tqdm import tqdm
+from tabulate import tabulate
+from scipy.spatial import distance
+
+
+def show_preds(pred, gt):
+    img = np.zeros((720, 1280, 3), dtype=np.uint8)
+    print(len(gt), 'gts and', len(pred), 'preds')
+    for lane in gt:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 5, thickness=-1, color=(255, 0, 255))
+    for lane in pred:
+        for p in lane:
+            cv2.circle(img, tuple(map(int, p)), 4, thickness=-1, color=(0, 255, 0))
+    cv2.imshow('img', img)
+    cv2.waitKey(0)
+
+
+def area_distance(pred_x, pred_y, gt_x, gt_y, placeholder=np.nan):
+    pred = np.vstack([pred_x, pred_y]).T
+    gt = np.vstack([gt_x, gt_y]).T
+
+    # pred = pred[pred[:, 0] > 0][:3, :]
+    # gt = gt[gt[:, 0] > 0][:5, :]
+
+    dist_matrix = distance.cdist(pred, gt, metric='euclidean')
+
+    dist = 0.5 * (np.min(dist_matrix, axis=0).sum() + np.min(dist_matrix, axis=1).sum())
+    dist /= np.max(gt_y) - np.min(gt_y)
+    return dist
+
+
+def area_metric(pred, gt, debug=None):
+    pred = sorted(pred, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    gt = sorted(gt, key=lambda ps: abs(ps[0][0] - 720/2.))[:2]
+    if len(pred) == 0:
+        return 0., 0., len(gt)
+    line_dists = []
+    fp = 0.
+    matched = 0.
+    gt_matches = [False] * len(gt)
+    pred_matches = [False] * len(pred)
+    pred_dists = [None] * len(pred)
+
+    distances = np.ones((len(gt), len(pred)), dtype=np.float32)
+    for i_gt, gt_points in enumerate(gt):
+        x_gts = [x for x, _ in gt_points]
+        y_gts = [y for _, y in gt_points]
+        for i_pred, pred_points in enumerate(pred):
+            x_preds = [x for x, _ in pred_points]
+            y_preds = [y for _, y in pred_points]
+            distances[i_gt, i_pred] = area_distance(x_preds, y_preds, x_gts, y_gts)
+
+    best_preds = np.argmin(distances, axis=1)
+    best_gts = np.argmin(distances, axis=0)
+    fp = 0.
+    fn = 0.
+    dist = 0.
+    is_fp = []
+    is_fn = []
+    for i_pred, best_gt in enumerate(best_gts):
+        if best_preds[best_gt] == i_pred:
+            dist += distances[best_gt, i_pred]
+            is_fp.append(False)
+        else:
+            fp += 1
+            is_fp.append(True)
+    for i_gt, best_pred in enumerate(best_preds):
+        if best_gts[best_pred] != i_gt:
+            fn += 1
+            is_fn.append(True)
+        else:
+            is_fn.append(False)
+    if debug:
+        print('is fp')
+        print(is_fp)
+        print('is fn')
+        print(is_fn)
+        print('distances')
+        dists = np.min(distances, axis=0)
+        dists[np.array(is_fp)] = 0
+        print(dists)
+        show_preds(pred, gt)
+
+    return dist, fp, fn
+
+
+def convert_tusimple_format(json_gt):
+    output = []
+    for data in json_gt:
+        lanes = [[(x, y) for (x, y) in zip(lane, data['h_samples']) if x >= 0] for lane in data['lanes']
+                 if any(x > 0 for x in lane)]
+        output.append({
+            'raw_file': data['raw_file'],
+            'run_time': data['run_time'] if 'run_time' in data else None,
+            'lanes': lanes
+        })
+    return output
+
+
+def eval_json(pred_file, gt_file, json_type=None, debug=False):
+    try:
+        json_pred = [json.loads(line) for line in open(pred_file).readlines()]
+    except BaseException as e:
+        raise Exception('Fail to load json file of the prediction.')
+    json_gt = [json.loads(line) for line in open(gt_file).readlines()]
+    if len(json_gt) != len(json_pred):
+        raise Exception('We do not get the predictions of all the test tasks')
+
+    if json_type == 'tusimple':
+        for gt, pred in zip(json_gt, json_pred):
+            pred['h_samples'] = gt['h_samples']
+        json_gt = convert_tusimple_format(json_gt)
+        json_pred = convert_tusimple_format(json_pred)
+    gts = {l['raw_file']: l for l in json_gt}
+
+    total_distance, total_fp, total_fn, run_time = 0., 0., 0., 0.
+    for pred in tqdm(json_pred):
+        if 'raw_file' not in pred or 'lanes' not in pred:
+            raise Exception('raw_file or lanes not in some predictions.')
+        raw_file = pred['raw_file']
+        pred_lanes = pred['lanes']
+        run_time += pred['run_time'] if 'run_time' in pred else 1.
+
+        if raw_file not in gts:
+            raise Exception('Some raw_file from your predictions do not exist in the test tasks.')
+        gt = gts[raw_file]
+        gt_lanes = gt['lanes']
+
+        distance, fp, fn = area_metric(pred_lanes, gt_lanes, debug=debug)
+
+        total_distance += distance
+        total_fp += fp
+        total_fn += fn
+
+    num = len(gts)
+    return json.dumps([{
+        'name': 'Distance',
+        'value': total_distance / num,
+        'order': 'desc'
+    }, {
+        'name': 'FP',
+        'value': total_fp,
+        'order': 'asc'
+    }, {
+        'name': 'FN',
+        'value': total_fn,
+        'order': 'asc'
+    }, {
+        'name': 'FPS',
+        'value': 1000. * num / run_time
+    }])
+
+
+if __name__ == '__main__':
+    parser = argparse.ArgumentParser(description="Compute the metrics")
+    parser.add_argument('--preds', required=True, type=str, help=".json with the predictions")
+    parser.add_argument('--gt', required=True, type=str, help=".json with the GT")
+    parser.add_argument('--gt-type', type=str, help='pass `tusimple` if using the TuSimple file format')
+    parser.add_argument('--debug', action='store_true', help='show metrics and preds/gts')
+    argv = vars(parser.parse_args())
+
+    result = json.loads(eval_json(argv['preds'], argv['gt'], argv['gt_type'], argv['debug']))
+
+    # pretty-print
+    table = {}
+    for metric in result:
+        if metric['name'] not in table.keys():
+            table[metric['name']] = []
+        table[metric['name']].append(metric['value'])
+    print(tabulate(table, headers='keys'))
diff --git a/utils/plot_log.py b/utils/plot_log.py
index ee18cf1..aaba69a 100644
--- a/utils/plot_log.py
+++ b/utils/plot_log.py
@@ -1,161 +1,161 @@
-import os
-import re
-import argparse
-import datetime
-
-import numpy as np
-import matplotlib.dates as mdates
-import matplotlib.colors as colors
-import matplotlib.pyplot as plt
-
-ITER_PATTERN = re.compile(
-    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
-)
-LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
-EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
-EXPS_DIR = '../data_lane-regression/experiments'
-
-# TODO: refactor this file
-
-
-def smooth_curve(xs, factor):
-    smoothed = [None] * len(xs)
-    smoothed[0] = xs[0]
-    for i in range(1, len(xs)):
-        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
-
-    return smoothed
-
-
-def plot_loss(data,
-              fig,
-              ax,
-              label,
-              plot_lr=True,
-              smoothing=0,
-              xaxis='time',
-              only_epoch_end=False,
-              plot_val=False,
-              plot_loss_comps=False):
-    iter_data = data['iter_update']
-    epoch_data = data['epoch_update']
-    now = datetime.datetime.today()
-    if xaxis == 'epoch':
-        if only_epoch_end:
-            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
-        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
-    elif xaxis == 'time':
-        d0 = iter_data[0]['date']
-        x = [now + (d['date'] - d0) for d in iter_data]
-    elif xaxis == 'iter':
-        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
-    loss = [d['loss'] for d in iter_data]
-    if plot_loss_comps:
-        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
-    if plot_val:
-        val_loss = [d['val_loss'] for d in epoch_data]
-        if xaxis == 'epoch':
-            val_loss_x = [d['epoch'] for d in epoch_data]
-        else:
-            val_loss_d0 = epoch_data[0]['date']
-            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
-    loss_smooth = smooth_curve(loss, factor=smoothing)
-    if plot_lr:
-        lr = [d['lr'] for d in iter_data]
-        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
-                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
-        if len(lr_decays) < 10:
-            for epoch, old, new in lr_decays:
-                ax.axvline(x=epoch, linestyle='--')
-        ax.plot(x, lr, label='LR: {}'.format(label))
-    ax.set_yscale('log')
-    ax.set_title('Loss')
-    ax.set_xlabel('Epoch')
-    ax.set_ylabel('Loss')
-    loss_line = ax.plot(x, loss_smooth)[0]
-    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
-    loss_line_color[-1] = 0.5
-    if plot_loss_comps:
-        for loss_comp in loss_comps:
-            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
-            line_color = np.array(colors.to_rgba(line.get_color()))
-            line_color[-1] = 0.5
-            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
-    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
-    if plot_val:
-        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
-    if xaxis == 'time':
-        fig.autofmt_xdate()
-        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
-
-
-def parse_line(line):
-    iter_match = re.match(ITER_PATTERN, line)
-    epoch_match = re.match(EPOCH_PATTERN, line)
-    data = {}
-    if iter_match is not None:
-        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
-        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
-            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
-                loss), float(speed), float(lr)
-        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
-        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
-        data['iter_update'] = {
-            'date': date,
-            'epoch': epoch,
-            'total_epochs': total_epochs,
-            'iter_nb': iter_nb,
-            'total_iters': total_iters,
-            'loss': loss,
-            'speed': date,
-            'loss_comps': loss_comps,
-            'lr': lr,
-        }
-    if epoch_match is not None:
-        date, epoch, _, val_loss = epoch_match.groups()
-        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
-        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
-
-    return data
-
-
-def parse_log(log_path):
-    with open(log_path, 'r') as log_file:
-        lines = [line.rstrip() for line in log_file.readlines()]
-    data = {'iter_update': [], 'epoch_update': []}
-    for line in lines:
-        line_data = parse_line(line)
-        for key in line_data:
-            data[key].append(line_data[key])
-    return data
-
-
-def get_logfilepath(exp_name):
-    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
-
-
-def parse_args():
-    parser = argparse.ArgumentParser(description='Visualization')
-    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
-    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
-    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
-
-    return parser.parse_args()
-
-
-if __name__ == "__main__":
-    args = parse_args()
-    fig, ax = plt.subplots(nrows=1, ncols=1)
-    for exp_name in args.exp_name:
-        log_filepath = get_logfilepath(exp_name)
-        data = parse_log(log_filepath)
-        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
-
-    # Show the major grid lines with dark grey lines
-    plt.grid(b=True, which='major', color='#666666', linestyle='-')
-
-    # Show the minor grid lines with very faint and almost transparent grey lines
-    plt.minorticks_on()
-    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
-    plt.legend()
-    plt.show()
+import os
+import re
+import argparse
+import datetime
+
+import numpy as np
+import matplotlib.dates as mdates
+import matplotlib.colors as colors
+import matplotlib.pyplot as plt
+
+ITER_PATTERN = re.compile(
+    '^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Step\ \[(\d*)/(\d*).*Loss: (\d*\.?\d*)\ \((.*)\).*s/iter:\ -?(\d*\.?\d*).*lr:\ ([^\ ]*)$'  # noqa: E501
+)
+LOSS_COMP_PATTERN = re.compile('(\w+):\ (\d*\.?\d*)')  # noqa: w605
+EPOCH_PATTERN = re.compile('^\[([^\]]*)\]\ .*Epoch \[(\d*)/(\d*).*Val\ loss: (\d*\.?\d*)$')  # noqa: w605
+EXPS_DIR = '../data_lane-regression/experiments'
+
+# TODO: refactor this file
+
+
+def smooth_curve(xs, factor):
+    smoothed = [None] * len(xs)
+    smoothed[0] = xs[0]
+    for i in range(1, len(xs)):
+        smoothed[i] = xs[i] * (1 - factor) + smoothed[i - 1] * factor
+
+    return smoothed
+
+
+def plot_loss(data,
+              fig,
+              ax,
+              label,
+              plot_lr=True,
+              smoothing=0,
+              xaxis='time',
+              only_epoch_end=False,
+              plot_val=False,
+              plot_loss_comps=False):
+    iter_data = data['iter_update']
+    epoch_data = data['epoch_update']
+    now = datetime.datetime.today()
+    if xaxis == 'epoch':
+        if only_epoch_end:
+            iter_data = [d for d in iter_data if d['iter_nb'] == d['total_iters']]
+        x = [d['epoch'] + d['iter_nb'] * 1.0 / d['total_iters'] for d in iter_data]
+    elif xaxis == 'time':
+        d0 = iter_data[0]['date']
+        x = [now + (d['date'] - d0) for d in iter_data]
+    elif xaxis == 'iter':
+        x = [(d['epoch'] - 1) * d['total_iters'] + d['iter_nb'] for d in iter_data]
+    loss = [d['loss'] for d in iter_data]
+    if plot_loss_comps:
+        loss_comps = {comp: [d['loss_comps'][comp] for d in iter_data] for comp in iter_data[0]['loss_comps']}
+    if plot_val:
+        val_loss = [d['val_loss'] for d in epoch_data]
+        if xaxis == 'epoch':
+            val_loss_x = [d['epoch'] for d in epoch_data]
+        else:
+            val_loss_d0 = epoch_data[0]['date']
+            val_loss_x = [now + (d['date'] - val_loss_d0) for d in epoch_data]
+    loss_smooth = smooth_curve(loss, factor=smoothing)
+    if plot_lr:
+        lr = [d['lr'] for d in iter_data]
+        lr_decays = [(iter_data[i + 1]['epoch'], iter_data[i]['lr'], iter_data[i + 1]['lr'])
+                     for i in range(len(iter_data) - 1) if iter_data[i + 1]['lr'] != iter_data[i]['lr']]
+        if len(lr_decays) < 10:
+            for epoch, old, new in lr_decays:
+                ax.axvline(x=epoch, linestyle='--')
+        ax.plot(x, lr, label='LR: {}'.format(label))
+    ax.set_yscale('log')
+    ax.set_title('Loss')
+    ax.set_xlabel('Epoch')
+    ax.set_ylabel('Loss')
+    loss_line = ax.plot(x, loss_smooth)[0]
+    loss_line_color = np.array(colors.to_rgba(loss_line.get_color()))
+    loss_line_color[-1] = 0.5
+    if plot_loss_comps:
+        for loss_comp in loss_comps:
+            line = ax.plot(x, smooth_curve(loss_comps[loss_comp], smoothing))[0]
+            line_color = np.array(colors.to_rgba(line.get_color()))
+            line_color[-1] = 0.5
+            ax.plot(x, loss_comps[loss_comp], label='{}: {}'.format(loss_comp, label), color=line_color)
+    ax.plot(x, loss, label='Train Loss: {}'.format(label), color=loss_line_color)
+    if plot_val:
+        ax.plot(val_loss_x, val_loss, label='Val Loss: {}'.format(label))
+    if xaxis == 'time':
+        fig.autofmt_xdate()
+        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M"'))
+
+
+def parse_line(line):
+    iter_match = re.match(ITER_PATTERN, line)
+    epoch_match = re.match(EPOCH_PATTERN, line)
+    data = {}
+    if iter_match is not None:
+        date, epoch, total_epochs, iter_nb, total_iters, loss, loss_comps, speed, lr = iter_match.groups()
+        date, epoch, total_epochs, iter_nb, total_iters, loss, speed, lr = datetime.datetime.strptime(
+            date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), int(total_epochs), int(iter_nb), int(total_iters), float(
+                loss), float(speed), float(lr)
+        loss_comps = re.findall(LOSS_COMP_PATTERN, loss_comps)
+        loss_comps = {d[0]: float(d[1]) for d in loss_comps}
+        data['iter_update'] = {
+            'date': date,
+            'epoch': epoch,
+            'total_epochs': total_epochs,
+            'iter_nb': iter_nb,
+            'total_iters': total_iters,
+            'loss': loss,
+            'speed': date,
+            'loss_comps': loss_comps,
+            'lr': lr,
+        }
+    if epoch_match is not None:
+        date, epoch, _, val_loss = epoch_match.groups()
+        date, epoch, val_loss = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S,%f'), int(epoch), float(val_loss)
+        data['epoch_update'] = {'date': date, 'epoch': epoch, 'val_loss': val_loss}
+
+    return data
+
+
+def parse_log(log_path):
+    with open(log_path, 'r') as log_file:
+        lines = [line.rstrip() for line in log_file.readlines()]
+    data = {'iter_update': [], 'epoch_update': []}
+    for line in lines:
+        line_data = parse_line(line)
+        for key in line_data:
+            data[key].append(line_data[key])
+    return data
+
+
+def get_logfilepath(exp_name):
+    return os.path.join(EXPS_DIR, exp_name, 'log.txt')
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(description='Visualization')
+    parser.add_argument('exp_name', nargs='*', default=None, help='Experiment names')
+    parser.add_argument('--smoothing', type=float, default=0.99, help='Experiment name')
+    parser.add_argument('--xaxis', default='time', help='X axis (`time`or `epoch`)')
+
+    return parser.parse_args()
+
+
+if __name__ == "__main__":
+    args = parse_args()
+    fig, ax = plt.subplots(nrows=1, ncols=1)
+    for exp_name in args.exp_name:
+        log_filepath = get_logfilepath(exp_name)
+        data = parse_log(log_filepath)
+        plot_loss(data, fig, ax, exp_name, smoothing=args.smoothing, xaxis=args.xaxis)
+
+    # Show the major grid lines with dark grey lines
+    plt.grid(b=True, which='major', color='#666666', linestyle='-')
+
+    # Show the minor grid lines with very faint and almost transparent grey lines
+    plt.minorticks_on()
+    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)
+    plt.legend()
+    plt.show()
diff --git a/utils/upperbound.py b/utils/upperbound.py
index 78af9b3..1fbce9e 100644
--- a/utils/upperbound.py
+++ b/utils/upperbound.py
@@ -1,44 +1,44 @@
-import sys
-import warnings
-
-import numpy as np
-from progressbar import progressbar
-
-from lib.config import Config
-from utils.evaluator import Evaluator
-
-warnings.simplefilter('ignore', np.RankWarning)
-
-
-def polyfit_upperbound(dataset, degree):
-    evaluator = Evaluator(dataset, '/tmp', degree)
-    print('Predicting with upperbound...')
-    for i, anno in enumerate(progressbar(dataset.annotations)):
-        label = anno['label']
-        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
-        pred[:, :3] = label[:, :3]
-        for j, lane in enumerate(label):
-            if lane[0] == 0:
-                continue
-            xy = lane[3:]
-            x = xy[:(len(xy) // 2)]
-            y = xy[(len(xy) // 2):]
-            ind = x > 0
-            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
-        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
-    _, result = evaluator.eval(label='upperbound', only_metrics=True)
-
-    return result
-
-
-if __name__ == "__main__":
-    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
-    dataset = cfg.get_dataset('test')
-    for n in range(1, 5 + 1):
-        result = polyfit_upperbound(dataset, n)
-        print('Degree {} upperbound:'.format(n))
-        for metric in result:
-            if metric['name'] == 'Accuracy':
-                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
-            else:
-                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))
+import sys
+import warnings
+
+import numpy as np
+from progressbar import progressbar
+
+from lib.config import Config
+from utils.evaluator import Evaluator
+
+warnings.simplefilter('ignore', np.RankWarning)
+
+
+def polyfit_upperbound(dataset, degree):
+    evaluator = Evaluator(dataset, '/tmp', degree)
+    print('Predicting with upperbound...')
+    for i, anno in enumerate(progressbar(dataset.annotations)):
+        label = anno['label']
+        pred = np.zeros((label.shape[0], 1 + 2 + degree + 1))
+        pred[:, :3] = label[:, :3]
+        for j, lane in enumerate(label):
+            if lane[0] == 0:
+                continue
+            xy = lane[3:]
+            x = xy[:(len(xy) // 2)]
+            y = xy[(len(xy) // 2):]
+            ind = x > 0
+            pred[j, -(degree + 1):] = np.polyfit(y[ind], x[ind], degree)
+        evaluator.add_prediction([i], pred, 0.0005)  # 0.0005 = dummy runtime
+    _, result = evaluator.eval(label='upperbound', only_metrics=True)
+
+    return result
+
+
+if __name__ == "__main__":
+    cfg = Config(sys.argv[1] if len(sys.argv) > 1 else 'config.yaml')
+    dataset = cfg.get_dataset('test')
+    for n in range(1, 5 + 1):
+        result = polyfit_upperbound(dataset, n)
+        print('Degree {} upperbound:'.format(n))
+        for metric in result:
+            if metric['name'] == 'Accuracy':
+                print('\t{}: {:.2f}'.format(metric['name'], metric['value'] * 100))
+            else:
+                print('\t{}: {:.3f}'.format(metric['name'], metric['value']))

[2021-08-08 22:25:45,227] [INFO] Starting testing.
[2021-08-08 22:25:47,100] [INFO] Testing iteration: 1/2782
[2021-08-08 22:26:37,360] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-08 22:26:37,361] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-08 22:26:37,362] [INFO] Args:
Namespace(batch_size=1, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-08 22:26:38,208] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..c72e6b5 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),

[2021-08-08 22:26:38,209] [INFO] Starting testing.
[2021-08-08 22:26:55,170] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 160, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 34, in test
    for idx, (images, labels, img_idxs) in enumerate(test_loader):
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\utils\data\dataloader.py", line 279, in __iter__
    return _MultiProcessingDataLoaderIter(self)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\utils\data\dataloader.py", line 719, in __init__
    w.start()
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\multiprocessing\process.py", line 105, in start
    self._popen = self._Popen(self)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\multiprocessing\popen_spawn_win32.py", line 65, in __init__
    reduction.dump(process_obj, to_child)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
BrokenPipeError: [Errno 32] Broken pipe
[2021-08-09 11:11:54,508] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-09 11:11:54,522] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: val
      max_lanes: 5
      img_size: [360, 640]
      root: "data_lane-regression/datasets/tusimple"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test

[2021-08-09 11:11:54,534] [INFO] Args:
Namespace(batch_size=1, cfg='experiments/tusimple_efficientnetb1/config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-09 11:11:55,563] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..c72e6b5 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),

[2021-08-09 11:11:55,564] [INFO] Starting testing.
[2021-08-09 11:12:13,269] [INFO] Testing iteration: 1/2782
[2021-08-09 11:12:19,360] [INFO] Testing iteration: 2/2782
[2021-08-09 11:12:21,264] [INFO] Testing iteration: 3/2782
[2021-08-09 11:12:26,184] [INFO] Testing iteration: 4/2782
[2021-08-09 11:12:28,350] [INFO] Testing iteration: 5/2782
[2021-08-09 11:12:30,285] [INFO] Testing iteration: 6/2782
[2021-08-09 11:12:32,981] [INFO] Testing iteration: 7/2782
[2021-08-09 11:12:35,264] [INFO] Testing iteration: 8/2782
[2021-08-09 11:12:37,992] [INFO] Testing iteration: 9/2782
[2021-08-09 11:12:40,268] [INFO] Testing iteration: 10/2782
[2021-08-09 11:12:43,523] [INFO] Testing iteration: 11/2782
[2021-08-09 11:12:46,870] [INFO] Testing iteration: 12/2782
[2021-08-09 11:12:49,228] [INFO] Testing iteration: 13/2782
[2021-08-09 11:12:52,852] [INFO] Testing iteration: 14/2782
[2021-08-09 11:12:55,093] [INFO] Testing iteration: 15/2782
[2021-08-09 11:15:52,580] [INFO] Testing iteration: 16/2782
[2021-08-09 11:15:54,617] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 160, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 43, in test
    outputs = model(images)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\nn\modules\module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "E:\New folder\umic\Polynomial Regression\PolyLaneNet\lib\models.py", line 63, in forward
    output, extra_outputs = self.model(x, **kwargs)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\nn\modules\module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\efficientnet_pytorch\model.py", line 193, in forward
    x = self.extract_features(inputs)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\efficientnet_pytorch\model.py", line 182, in extract_features
    x = block(x, drop_connect_rate=drop_connect_rate)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\nn\modules\module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\efficientnet_pytorch\model.py", line 78, in forward
    x = self._swish(self._bn1(self._depthwise_conv(x)))
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\nn\modules\module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\efficientnet_pytorch\utils.py", line 144, in forward
    x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)
KeyboardInterrupt
[2021-08-10 15:27:18,633] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:27:18,655] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 360 # The height of your test images (they shoud all have the same size)
      img_w: 640 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "data_lane-regression/datasets/tusimple" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpeg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:27:18,670] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:27:19,561] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/predict.py b/predict.py
index e69de29..96a042c 100644
--- a/predict.py
+++ b/predict.py
@@ -0,0 +1,169 @@
+import cv2
+import os
+
+import random
+
+import argparse
+
+from lib.config import Config
+
+import numpy as np
+import torch
+
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--img_path", default="default", help="image path", required=True)
+    return parser.parse_args()
+
+class Prediction_class(Dataset):
+    def __init__(self,
+                 img_path,
+                 normalize=True,
+                 img_size=(720, 1080)):
+
+        self.img_h, self.img_w = img_size
+        self.normalize = normalize
+        self.to_tensor = ToTensor()
+        self.img_path = img_path
+
+    def __getitem__(self, idx):
+
+        #img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[0])
+        img = cv2.imread(self.img_path)
+        # print("*"*50)
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, idx)
+
+    def __len__(self):
+        #return len(os.listdir(self.img_dir))
+        return 1
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+
+        img, _ = self.__getitem__(idx)
+        # Tensor to opencv image
+        img = img.permute(1, 2, 0).numpy()
+        # Unnormalize
+
+        img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+        img = (img * 255).astype(np.uint8)
+
+        img_h, img_w, _ = img.shape
+
+        print(pred)
+        # pred = pred.reshape(5,7)
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        # matches, accs, _ = self.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+
+            # print(lane.shape)
+            color = PRED_HIT_COLOR
+
+            pred_conf = lane[0]
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(pred_conf),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config("experiments/tusimple_efficientnetb1/config.yaml")
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    model = cfg.get_model().to(device)
+
+    #img_dir = 'data_lane-regression\datasets\prediction'
+    img_path = args.img_path
+    predict_set = Prediction_class(img_path, normalize=True, img_size=(720, 1080))
+
+    test_loader = torch.utils.data.DataLoader(dataset=predict_set,
+                                                  batch_size=1,
+                                                  shuffle=False)
+    model.load_state_dict(torch.load('experiments/tusimple_efficientnetb1/models/model_2695.pt',
+                                     map_location=torch.device('cpu'))['model'])
+
+    test_parameters = cfg.get_test_parameters()
+
+    with torch.no_grad():
+        for idx, (images, img_idxs) in enumerate(test_loader):
+            images = images.to(device)
+
+            outputs = model(images)
+
+            labels = np.zeros((1, 1), dtype=int)
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            output, extra_outputs = outputs
+            # print(output.shape)
+            # print(images.shape)
+            preds = test_loader.dataset.draw_annotation(idx, pred=output[0].cpu().numpy(),
+                                                        cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+
+
+
+    cv2.imshow('pred', preds)
+    cv2.waitKey(0)
+    cv2.destroyAllWindows()
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..c72e6b5 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),

[2021-08-10 15:27:19,561] [INFO] Starting testing.
[2021-08-10 15:27:24,774] [INFO] Testing time: 4.4267
[2021-08-10 15:27:24,774] [INFO] 
[2021-08-10 15:27:24,774] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 160, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 77, in test
    return evaluator, loss / total_iters
ZeroDivisionError: division by zero
[2021-08-10 15:27:47,347] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:27:47,347] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 360 # The height of your test images (they shoud all have the same size)
      img_w: 640 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "data_lane-regression/datasets/prediction" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpeg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:27:47,347] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:27:47,632] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/predict.py b/predict.py
index e69de29..96a042c 100644
--- a/predict.py
+++ b/predict.py
@@ -0,0 +1,169 @@
+import cv2
+import os
+
+import random
+
+import argparse
+
+from lib.config import Config
+
+import numpy as np
+import torch
+
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--img_path", default="default", help="image path", required=True)
+    return parser.parse_args()
+
+class Prediction_class(Dataset):
+    def __init__(self,
+                 img_path,
+                 normalize=True,
+                 img_size=(720, 1080)):
+
+        self.img_h, self.img_w = img_size
+        self.normalize = normalize
+        self.to_tensor = ToTensor()
+        self.img_path = img_path
+
+    def __getitem__(self, idx):
+
+        #img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[0])
+        img = cv2.imread(self.img_path)
+        # print("*"*50)
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, idx)
+
+    def __len__(self):
+        #return len(os.listdir(self.img_dir))
+        return 1
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+
+        img, _ = self.__getitem__(idx)
+        # Tensor to opencv image
+        img = img.permute(1, 2, 0).numpy()
+        # Unnormalize
+
+        img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+        img = (img * 255).astype(np.uint8)
+
+        img_h, img_w, _ = img.shape
+
+        print(pred)
+        # pred = pred.reshape(5,7)
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        # matches, accs, _ = self.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+
+            # print(lane.shape)
+            color = PRED_HIT_COLOR
+
+            pred_conf = lane[0]
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(pred_conf),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config("experiments/tusimple_efficientnetb1/config.yaml")
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    model = cfg.get_model().to(device)
+
+    #img_dir = 'data_lane-regression\datasets\prediction'
+    img_path = args.img_path
+    predict_set = Prediction_class(img_path, normalize=True, img_size=(720, 1080))
+
+    test_loader = torch.utils.data.DataLoader(dataset=predict_set,
+                                                  batch_size=1,
+                                                  shuffle=False)
+    model.load_state_dict(torch.load('experiments/tusimple_efficientnetb1/models/model_2695.pt',
+                                     map_location=torch.device('cpu'))['model'])
+
+    test_parameters = cfg.get_test_parameters()
+
+    with torch.no_grad():
+        for idx, (images, img_idxs) in enumerate(test_loader):
+            images = images.to(device)
+
+            outputs = model(images)
+
+            labels = np.zeros((1, 1), dtype=int)
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            output, extra_outputs = outputs
+            # print(output.shape)
+            # print(images.shape)
+            preds = test_loader.dataset.draw_annotation(idx, pred=output[0].cpu().numpy(),
+                                                        cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+
+
+
+    cv2.imshow('pred', preds)
+    cv2.waitKey(0)
+    cv2.destroyAllWindows()
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..c72e6b5 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),

[2021-08-10 15:27:47,632] [INFO] Starting testing.
[2021-08-10 15:27:52,285] [INFO] Testing time: 3.9825
[2021-08-10 15:27:52,285] [INFO] 
[2021-08-10 15:27:52,285] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 160, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 77, in test
    return evaluator, loss / total_iters
ZeroDivisionError: division by zero
[2021-08-10 15:28:59,450] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:28:59,450] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 360 # The height of your test images (they shoud all have the same size)
      img_w: 640 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "data_lane-regression/datasets/prediction" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpeg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:28:59,450] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:28:59,679] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/predict.py b/predict.py
index e69de29..96a042c 100644
--- a/predict.py
+++ b/predict.py
@@ -0,0 +1,169 @@
+import cv2
+import os
+
+import random
+
+import argparse
+
+from lib.config import Config
+
+import numpy as np
+import torch
+
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--img_path", default="default", help="image path", required=True)
+    return parser.parse_args()
+
+class Prediction_class(Dataset):
+    def __init__(self,
+                 img_path,
+                 normalize=True,
+                 img_size=(720, 1080)):
+
+        self.img_h, self.img_w = img_size
+        self.normalize = normalize
+        self.to_tensor = ToTensor()
+        self.img_path = img_path
+
+    def __getitem__(self, idx):
+
+        #img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[0])
+        img = cv2.imread(self.img_path)
+        # print("*"*50)
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, idx)
+
+    def __len__(self):
+        #return len(os.listdir(self.img_dir))
+        return 1
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+
+        img, _ = self.__getitem__(idx)
+        # Tensor to opencv image
+        img = img.permute(1, 2, 0).numpy()
+        # Unnormalize
+
+        img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+        img = (img * 255).astype(np.uint8)
+
+        img_h, img_w, _ = img.shape
+
+        print(pred)
+        # pred = pred.reshape(5,7)
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        # matches, accs, _ = self.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+
+            # print(lane.shape)
+            color = PRED_HIT_COLOR
+
+            pred_conf = lane[0]
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(pred_conf),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config("experiments/tusimple_efficientnetb1/config.yaml")
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    model = cfg.get_model().to(device)
+
+    #img_dir = 'data_lane-regression\datasets\prediction'
+    img_path = args.img_path
+    predict_set = Prediction_class(img_path, normalize=True, img_size=(720, 1080))
+
+    test_loader = torch.utils.data.DataLoader(dataset=predict_set,
+                                                  batch_size=1,
+                                                  shuffle=False)
+    model.load_state_dict(torch.load('experiments/tusimple_efficientnetb1/models/model_2695.pt',
+                                     map_location=torch.device('cpu'))['model'])
+
+    test_parameters = cfg.get_test_parameters()
+
+    with torch.no_grad():
+        for idx, (images, img_idxs) in enumerate(test_loader):
+            images = images.to(device)
+
+            outputs = model(images)
+
+            labels = np.zeros((1, 1), dtype=int)
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            output, extra_outputs = outputs
+            # print(output.shape)
+            # print(images.shape)
+            preds = test_loader.dataset.draw_annotation(idx, pred=output[0].cpu().numpy(),
+                                                        cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+
+
+
+    cv2.imshow('pred', preds)
+    cv2.waitKey(0)
+    cv2.destroyAllWindows()
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..27f815f 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),
@@ -73,8 +74,8 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
     if verbose:
         logging.info(', '.join(out_line))
 
-    return evaluator, loss / total_iters
-
+    #return evaluator, loss / total_iters
+    return evaluator, loss
 
 def parse_args():
     parser = argparse.ArgumentParser(description="Lane regression")

[2021-08-10 15:28:59,691] [INFO] Starting testing.
[2021-08-10 15:29:03,770] [INFO] Testing time: 3.9279
[2021-08-10 15:29:03,770] [INFO] 
[2021-08-10 15:29:03,770] [INFO] Mean test loss: 0.0000
[2021-08-10 15:29:03,770] [INFO] 
[2021-08-10 15:29:48,770] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:29:48,770] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 360 # The height of your test images (they shoud all have the same size)
      img_w: 640 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "data_lane-regression/datasets/prediction" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:29:48,770] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:29:48,986] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/predict.py b/predict.py
index e69de29..96a042c 100644
--- a/predict.py
+++ b/predict.py
@@ -0,0 +1,169 @@
+import cv2
+import os
+
+import random
+
+import argparse
+
+from lib.config import Config
+
+import numpy as np
+import torch
+
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--img_path", default="default", help="image path", required=True)
+    return parser.parse_args()
+
+class Prediction_class(Dataset):
+    def __init__(self,
+                 img_path,
+                 normalize=True,
+                 img_size=(720, 1080)):
+
+        self.img_h, self.img_w = img_size
+        self.normalize = normalize
+        self.to_tensor = ToTensor()
+        self.img_path = img_path
+
+    def __getitem__(self, idx):
+
+        #img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[0])
+        img = cv2.imread(self.img_path)
+        # print("*"*50)
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, idx)
+
+    def __len__(self):
+        #return len(os.listdir(self.img_dir))
+        return 1
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+
+        img, _ = self.__getitem__(idx)
+        # Tensor to opencv image
+        img = img.permute(1, 2, 0).numpy()
+        # Unnormalize
+
+        img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+        img = (img * 255).astype(np.uint8)
+
+        img_h, img_w, _ = img.shape
+
+        print(pred)
+        # pred = pred.reshape(5,7)
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        # matches, accs, _ = self.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+
+            # print(lane.shape)
+            color = PRED_HIT_COLOR
+
+            pred_conf = lane[0]
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(pred_conf),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config("experiments/tusimple_efficientnetb1/config.yaml")
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    model = cfg.get_model().to(device)
+
+    #img_dir = 'data_lane-regression\datasets\prediction'
+    img_path = args.img_path
+    predict_set = Prediction_class(img_path, normalize=True, img_size=(720, 1080))
+
+    test_loader = torch.utils.data.DataLoader(dataset=predict_set,
+                                                  batch_size=1,
+                                                  shuffle=False)
+    model.load_state_dict(torch.load('experiments/tusimple_efficientnetb1/models/model_2695.pt',
+                                     map_location=torch.device('cpu'))['model'])
+
+    test_parameters = cfg.get_test_parameters()
+
+    with torch.no_grad():
+        for idx, (images, img_idxs) in enumerate(test_loader):
+            images = images.to(device)
+
+            outputs = model(images)
+
+            labels = np.zeros((1, 1), dtype=int)
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            output, extra_outputs = outputs
+            # print(output.shape)
+            # print(images.shape)
+            preds = test_loader.dataset.draw_annotation(idx, pred=output[0].cpu().numpy(),
+                                                        cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+
+
+
+    cv2.imshow('pred', preds)
+    cv2.waitKey(0)
+    cv2.destroyAllWindows()
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..27f815f 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),
@@ -73,8 +74,8 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
     if verbose:
         logging.info(', '.join(out_line))
 
-    return evaluator, loss / total_iters
-
+    #return evaluator, loss / total_iters
+    return evaluator, loss
 
 def parse_args():
     parser = argparse.ArgumentParser(description="Lane regression")

[2021-08-10 15:29:48,988] [INFO] Starting testing.
[2021-08-10 15:29:52,518] [INFO] Testing iteration: 1/1
[2021-08-10 15:30:33,997] [INFO] Testing time: 44.8598
[2021-08-10 15:30:33,999] [INFO] conf: 11.0770, lower: nan, upper: nan, poly: nan, cls_loss: 0.0000
[2021-08-10 15:30:33,999] [INFO] Mean test loss: nan
[2021-08-10 15:30:33,999] [INFO] 
[2021-08-10 15:31:01,109] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:31:01,109] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 720 # The height of your test images (they shoud all have the same size)
      img_w: 1280 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "data_lane-regression/datasets/prediction" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:31:01,109] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:31:01,303] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/predict.py b/predict.py
index e69de29..96a042c 100644
--- a/predict.py
+++ b/predict.py
@@ -0,0 +1,169 @@
+import cv2
+import os
+
+import random
+
+import argparse
+
+from lib.config import Config
+
+import numpy as np
+import torch
+
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--img_path", default="default", help="image path", required=True)
+    return parser.parse_args()
+
+class Prediction_class(Dataset):
+    def __init__(self,
+                 img_path,
+                 normalize=True,
+                 img_size=(720, 1080)):
+
+        self.img_h, self.img_w = img_size
+        self.normalize = normalize
+        self.to_tensor = ToTensor()
+        self.img_path = img_path
+
+    def __getitem__(self, idx):
+
+        #img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[0])
+        img = cv2.imread(self.img_path)
+        # print("*"*50)
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, idx)
+
+    def __len__(self):
+        #return len(os.listdir(self.img_dir))
+        return 1
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+
+        img, _ = self.__getitem__(idx)
+        # Tensor to opencv image
+        img = img.permute(1, 2, 0).numpy()
+        # Unnormalize
+
+        img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+        img = (img * 255).astype(np.uint8)
+
+        img_h, img_w, _ = img.shape
+
+        print(pred)
+        # pred = pred.reshape(5,7)
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        # matches, accs, _ = self.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+
+            # print(lane.shape)
+            color = PRED_HIT_COLOR
+
+            pred_conf = lane[0]
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(pred_conf),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config("experiments/tusimple_efficientnetb1/config.yaml")
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    model = cfg.get_model().to(device)
+
+    #img_dir = 'data_lane-regression\datasets\prediction'
+    img_path = args.img_path
+    predict_set = Prediction_class(img_path, normalize=True, img_size=(720, 1080))
+
+    test_loader = torch.utils.data.DataLoader(dataset=predict_set,
+                                                  batch_size=1,
+                                                  shuffle=False)
+    model.load_state_dict(torch.load('experiments/tusimple_efficientnetb1/models/model_2695.pt',
+                                     map_location=torch.device('cpu'))['model'])
+
+    test_parameters = cfg.get_test_parameters()
+
+    with torch.no_grad():
+        for idx, (images, img_idxs) in enumerate(test_loader):
+            images = images.to(device)
+
+            outputs = model(images)
+
+            labels = np.zeros((1, 1), dtype=int)
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            output, extra_outputs = outputs
+            # print(output.shape)
+            # print(images.shape)
+            preds = test_loader.dataset.draw_annotation(idx, pred=output[0].cpu().numpy(),
+                                                        cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+
+
+
+    cv2.imshow('pred', preds)
+    cv2.waitKey(0)
+    cv2.destroyAllWindows()
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..27f815f 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),
@@ -73,8 +74,8 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
     if verbose:
         logging.info(', '.join(out_line))
 
-    return evaluator, loss / total_iters
-
+    #return evaluator, loss / total_iters
+    return evaluator, loss
 
 def parse_args():
     parser = argparse.ArgumentParser(description="Lane regression")

[2021-08-10 15:31:01,303] [INFO] Starting testing.
[2021-08-10 15:31:04,506] [INFO] Testing iteration: 1/1
[2021-08-10 15:31:24,080] [INFO] Testing time: 22.6301
[2021-08-10 15:31:24,080] [INFO] conf: 11.0770, lower: nan, upper: nan, poly: nan, cls_loss: 0.0000
[2021-08-10 15:31:24,080] [INFO] Mean test loss: nan
[2021-08-10 15:31:24,080] [INFO] 
[2021-08-10 15:32:03,322] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:32:03,322] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 720 # The height of your test images (they shoud all have the same size)
      img_w: 1280 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "data_lane-regression/datasets/prediction" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:32:03,322] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:32:03,522] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/predict.py b/predict.py
index e69de29..96a042c 100644
--- a/predict.py
+++ b/predict.py
@@ -0,0 +1,169 @@
+import cv2
+import os
+
+import random
+
+import argparse
+
+from lib.config import Config
+
+import numpy as np
+import torch
+
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--img_path", default="default", help="image path", required=True)
+    return parser.parse_args()
+
+class Prediction_class(Dataset):
+    def __init__(self,
+                 img_path,
+                 normalize=True,
+                 img_size=(720, 1080)):
+
+        self.img_h, self.img_w = img_size
+        self.normalize = normalize
+        self.to_tensor = ToTensor()
+        self.img_path = img_path
+
+    def __getitem__(self, idx):
+
+        #img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[0])
+        img = cv2.imread(self.img_path)
+        # print("*"*50)
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, idx)
+
+    def __len__(self):
+        #return len(os.listdir(self.img_dir))
+        return 1
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+
+        img, _ = self.__getitem__(idx)
+        # Tensor to opencv image
+        img = img.permute(1, 2, 0).numpy()
+        # Unnormalize
+
+        img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+        img = (img * 255).astype(np.uint8)
+
+        img_h, img_w, _ = img.shape
+
+        print(pred)
+        # pred = pred.reshape(5,7)
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        # matches, accs, _ = self.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+
+            # print(lane.shape)
+            color = PRED_HIT_COLOR
+
+            pred_conf = lane[0]
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(pred_conf),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config("experiments/tusimple_efficientnetb1/config.yaml")
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    model = cfg.get_model().to(device)
+
+    #img_dir = 'data_lane-regression\datasets\prediction'
+    img_path = args.img_path
+    predict_set = Prediction_class(img_path, normalize=True, img_size=(720, 1080))
+
+    test_loader = torch.utils.data.DataLoader(dataset=predict_set,
+                                                  batch_size=1,
+                                                  shuffle=False)
+    model.load_state_dict(torch.load('experiments/tusimple_efficientnetb1/models/model_2695.pt',
+                                     map_location=torch.device('cpu'))['model'])
+
+    test_parameters = cfg.get_test_parameters()
+
+    with torch.no_grad():
+        for idx, (images, img_idxs) in enumerate(test_loader):
+            images = images.to(device)
+
+            outputs = model(images)
+
+            labels = np.zeros((1, 1), dtype=int)
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            output, extra_outputs = outputs
+            # print(output.shape)
+            # print(images.shape)
+            preds = test_loader.dataset.draw_annotation(idx, pred=output[0].cpu().numpy(),
+                                                        cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+
+
+
+    cv2.imshow('pred', preds)
+    cv2.waitKey(0)
+    cv2.destroyAllWindows()
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..27f815f 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),
@@ -73,8 +74,8 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
     if verbose:
         logging.info(', '.join(out_line))
 
-    return evaluator, loss / total_iters
-
+    #return evaluator, loss / total_iters
+    return evaluator, loss
 
 def parse_args():
     parser = argparse.ArgumentParser(description="Lane regression")

[2021-08-10 15:32:03,522] [INFO] Starting testing.
[2021-08-10 15:32:06,672] [INFO] Testing iteration: 1/2
[2021-08-10 15:32:14,810] [INFO] Testing iteration: 2/2
[2021-08-10 15:32:20,364] [INFO] Testing time: 16.7050
[2021-08-10 15:32:20,372] [INFO] conf: 11.6821, lower: nan, upper: nan, poly: nan, cls_loss: 0.0000
[2021-08-10 15:32:20,374] [INFO] Mean test loss: nan
[2021-08-10 15:32:20,374] [INFO] 
[2021-08-10 15:32:34,799] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:32:34,806] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 720 # The height of your test images (they shoud all have the same size)
      img_w: 1280 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "data_lane-regression/datasets/prediction" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:32:34,806] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:32:35,037] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/predict.py b/predict.py
index e69de29..96a042c 100644
--- a/predict.py
+++ b/predict.py
@@ -0,0 +1,169 @@
+import cv2
+import os
+
+import random
+
+import argparse
+
+from lib.config import Config
+
+import numpy as np
+import torch
+
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--img_path", default="default", help="image path", required=True)
+    return parser.parse_args()
+
+class Prediction_class(Dataset):
+    def __init__(self,
+                 img_path,
+                 normalize=True,
+                 img_size=(720, 1080)):
+
+        self.img_h, self.img_w = img_size
+        self.normalize = normalize
+        self.to_tensor = ToTensor()
+        self.img_path = img_path
+
+    def __getitem__(self, idx):
+
+        #img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[0])
+        img = cv2.imread(self.img_path)
+        # print("*"*50)
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, idx)
+
+    def __len__(self):
+        #return len(os.listdir(self.img_dir))
+        return 1
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+
+        img, _ = self.__getitem__(idx)
+        # Tensor to opencv image
+        img = img.permute(1, 2, 0).numpy()
+        # Unnormalize
+
+        img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+        img = (img * 255).astype(np.uint8)
+
+        img_h, img_w, _ = img.shape
+
+        print(pred)
+        # pred = pred.reshape(5,7)
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        # matches, accs, _ = self.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+
+            # print(lane.shape)
+            color = PRED_HIT_COLOR
+
+            pred_conf = lane[0]
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(pred_conf),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config("experiments/tusimple_efficientnetb1/config.yaml")
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    model = cfg.get_model().to(device)
+
+    #img_dir = 'data_lane-regression\datasets\prediction'
+    img_path = args.img_path
+    predict_set = Prediction_class(img_path, normalize=True, img_size=(720, 1080))
+
+    test_loader = torch.utils.data.DataLoader(dataset=predict_set,
+                                                  batch_size=1,
+                                                  shuffle=False)
+    model.load_state_dict(torch.load('experiments/tusimple_efficientnetb1/models/model_2695.pt',
+                                     map_location=torch.device('cpu'))['model'])
+
+    test_parameters = cfg.get_test_parameters()
+
+    with torch.no_grad():
+        for idx, (images, img_idxs) in enumerate(test_loader):
+            images = images.to(device)
+
+            outputs = model(images)
+
+            labels = np.zeros((1, 1), dtype=int)
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            output, extra_outputs = outputs
+            # print(output.shape)
+            # print(images.shape)
+            preds = test_loader.dataset.draw_annotation(idx, pred=output[0].cpu().numpy(),
+                                                        cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+
+
+
+    cv2.imshow('pred', preds)
+    cv2.waitKey(0)
+    cv2.destroyAllWindows()
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..27f815f 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),
@@ -73,8 +74,8 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
     if verbose:
         logging.info(', '.join(out_line))
 
-    return evaluator, loss / total_iters
-
+    #return evaluator, loss / total_iters
+    return evaluator, loss
 
 def parse_args():
     parser = argparse.ArgumentParser(description="Lane regression")

[2021-08-10 15:32:35,037] [INFO] Starting testing.
[2021-08-10 15:32:39,748] [INFO] Testing iteration: 1/1
[2021-08-10 15:33:10,153] [INFO] Testing time: 34.9682
[2021-08-10 15:33:10,153] [INFO] conf: 12.2872, lower: nan, upper: nan, poly: nan, cls_loss: 0.0000
[2021-08-10 15:33:10,153] [INFO] Mean test loss: nan
[2021-08-10 15:33:10,153] [INFO] 
[2021-08-10 15:35:25,088] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:35:25,088] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 720 # The height of your test images (they shoud all have the same size)
      img_w: 1280 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "data_lane-regression/datasets/prediction" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:35:25,088] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:35:25,289] [INFO] Code state:
 Git hash: 6155ce2e7d3841c46a0035a25acc9d2e304d9856

*************
Git diff:
*************
diff --git a/README.md b/README.md
index b4af404..5ab66b5 100644
--- a/README.md
+++ b/README.md
@@ -23,6 +23,7 @@ The code requires Python 3, and has been tested on Python 3.5.2, but should work
 Install dependencies:
 ```
 pip install -r requirements.txt
+(install pytorch 1.4 and torchvision from https://pytorch.org/get-started/previous-versions/)
 ```
 
 <a name="usage"/>
diff --git a/lib/datasets/lane_dataset.py b/lib/datasets/lane_dataset.py
index 1ce9e82..508b205 100644
--- a/lib/datasets/lane_dataset.py
+++ b/lib/datasets/lane_dataset.py
@@ -134,6 +134,7 @@ class LaneDataset(Dataset):
         if pred is None:
             return img
 
+
         # Draw predictions
         pred = pred[pred[:, 0] != 0]  # filter invalid lanes
         matches, accs, _ = self.dataset.get_metrics(pred, idx)
diff --git a/lib/datasets/tusimple.py b/lib/datasets/tusimple.py
index 513e86e..0ac4306 100644
--- a/lib/datasets/tusimple.py
+++ b/lib/datasets/tusimple.py
@@ -11,7 +11,7 @@ from utils.metric import eval_json
 SPLIT_FILES = {
     'train+val': ['label_data_0313.json', 'label_data_0601.json', 'label_data_0531.json'],
     'train': ['label_data_0313.json', 'label_data_0601.json'],
-    'val': ['label_data_0531.json'],
+    'val': ['test_label.json'],
     'test': ['test_label.json'],
 }
 
diff --git a/predict.py b/predict.py
index e69de29..96a042c 100644
--- a/predict.py
+++ b/predict.py
@@ -0,0 +1,169 @@
+import cv2
+import os
+
+import random
+
+import argparse
+
+from lib.config import Config
+
+import numpy as np
+import torch
+
+from torchvision.transforms import ToTensor
+from torch.utils.data.dataset import Dataset
+
+
+GT_COLOR = (255, 0, 0)
+PRED_HIT_COLOR = (0, 255, 0)
+PRED_MISS_COLOR = (0, 0, 255)
+IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
+IMAGENET_STD = np.array([0.229, 0.224, 0.225])
+
+def parse_args():
+    parser = argparse.ArgumentParser(description="Lane regression")
+    parser.add_argument("--img_path", default="default", help="image path", required=True)
+    return parser.parse_args()
+
+class Prediction_class(Dataset):
+    def __init__(self,
+                 img_path,
+                 normalize=True,
+                 img_size=(720, 1080)):
+
+        self.img_h, self.img_w = img_size
+        self.normalize = normalize
+        self.to_tensor = ToTensor()
+        self.img_path = img_path
+
+    def __getitem__(self, idx):
+
+        #img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[0])
+        img = cv2.imread(self.img_path)
+        # print("*"*50)
+        img = img / 255.
+        if self.normalize:
+            img = (img - IMAGENET_MEAN) / IMAGENET_STD
+        img = self.to_tensor(img.astype(np.float32))
+        return (img, idx)
+
+    def __len__(self):
+        #return len(os.listdir(self.img_dir))
+        return 1
+    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):
+
+        img, _ = self.__getitem__(idx)
+        # Tensor to opencv image
+        img = img.permute(1, 2, 0).numpy()
+        # Unnormalize
+
+        img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)
+        img = (img * 255).astype(np.uint8)
+
+        img_h, img_w, _ = img.shape
+
+        print(pred)
+        # pred = pred.reshape(5,7)
+        # Draw predictions
+        pred = pred[pred[:, 0] != 0]  # filter invalid lanes
+        # matches, accs, _ = self.get_metrics(pred, idx)
+        overlay = img.copy()
+        for i, lane in enumerate(pred):
+
+            # print(lane.shape)
+            color = PRED_HIT_COLOR
+
+            pred_conf = lane[0]
+            lane = lane[1:]  # remove conf
+            lower, upper = lane[0], lane[1]
+            lane = lane[2:]  # remove upper, lower positions
+
+            # generate points from the polynomial
+            ys = np.linspace(lower, upper, num=100)
+            points = np.zeros((len(ys), 2), dtype=np.int32)
+            points[:, 1] = (ys * img_h).astype(int)
+            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)
+            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]
+
+            # draw lane with a polyline on the overlay
+            for current_point, next_point in zip(points[:-1], points[1:]):
+                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)
+
+            # draw class icon
+            if cls_pred is not None and len(points) > 0:
+                class_icon = self.dataset.get_class_icon(cls_pred[i])
+                class_icon = cv2.resize(class_icon, (32, 32))
+                mid = tuple(points[len(points) // 2] - 60)
+                x, y = mid
+
+                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon
+
+            # draw lane ID
+            if len(points) > 0:
+                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)
+
+            # draw lane accuracy
+            if len(points) > 0:
+                cv2.putText(img,
+                            '{:.2f}'.format(pred_conf),
+                            tuple(points[len(points) // 2] - 30),
+                            fontFace=cv2.FONT_HERSHEY_COMPLEX,
+                            fontScale=.75,
+                            color=color)
+        # Add lanes overlay
+        w = 0.6
+        img = ((1. - w) * img + w * overlay).astype(np.uint8)
+
+        return img
+
+if __name__ == "__main__":
+    args = parse_args()
+    cfg = Config("experiments/tusimple_efficientnetb1/config.yaml")
+    # Set up seeds
+    torch.manual_seed(cfg['seed'])
+    np.random.seed(cfg['seed'])
+    random.seed(cfg['seed'])
+
+
+
+    # Device configuration
+    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+
+    # Hyper parameters
+    num_epochs = cfg["epochs"]
+    batch_size = cfg["batch_size"]
+
+    model = cfg.get_model().to(device)
+
+    #img_dir = 'data_lane-regression\datasets\prediction'
+    img_path = args.img_path
+    predict_set = Prediction_class(img_path, normalize=True, img_size=(720, 1080))
+
+    test_loader = torch.utils.data.DataLoader(dataset=predict_set,
+                                                  batch_size=1,
+                                                  shuffle=False)
+    model.load_state_dict(torch.load('experiments/tusimple_efficientnetb1/models/model_2695.pt',
+                                     map_location=torch.device('cpu'))['model'])
+
+    test_parameters = cfg.get_test_parameters()
+
+    with torch.no_grad():
+        for idx, (images, img_idxs) in enumerate(test_loader):
+            images = images.to(device)
+
+            outputs = model(images)
+
+            labels = np.zeros((1, 1), dtype=int)
+            outputs = model.decode(outputs, labels, **test_parameters)
+
+            output, extra_outputs = outputs
+            # print(output.shape)
+            # print(images.shape)
+            preds = test_loader.dataset.draw_annotation(idx, pred=output[0].cpu().numpy(),
+                                                        cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)
+
+
+
+    cv2.imshow('pred', preds)
+    cv2.waitKey(0)
+    cv2.destroyAllWindows()
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 5a328c1..bacb3f0 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -10,7 +10,6 @@ imgaug==0.4.0
 tqdm==4.43.0
 opencv_python==4.2.0.32
 efficientnet_pytorch==0.6.3
-torch==1.4.0
 progressbar33==2.4
 PyYAML==5.3.1
 scikit-learn==0.21.3
diff --git a/requirements2.txt b/requirements2.txt
index e69de29..7657e14 100644
--- a/requirements2.txt
+++ b/requirements2.txt
@@ -0,0 +1 @@
+torch==1.4.0
\ No newline at end of file
diff --git a/test.py b/test.py
index 4641d01..c72e6b5 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()
@@ -57,6 +57,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
                 evaluator.add_prediction(img_idxs, lane_outputs.cpu().numpy(), t / images.shape[0])
             if view:
                 outputs, extra_outputs = outputs
+                print(outputs.shape)
                 preds = test_loader.dataset.draw_annotation(
                     idx,
                     pred=outputs[0].cpu().numpy(),

[2021-08-10 15:35:25,304] [INFO] Starting testing.
[2021-08-10 15:35:29,342] [INFO] Testing iteration: 1/1
[2021-08-10 15:35:41,798] [INFO] Testing time: 16.3280
[2021-08-10 15:35:41,798] [INFO] conf: 12.2872, lower: nan, upper: nan, poly: nan, cls_loss: 0.0000
[2021-08-10 15:35:41,798] [INFO] Mean test loss: nan
[2021-08-10 15:35:41,798] [INFO] 
[2021-08-10 15:48:35,297] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:48:35,297] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 720 # The height of your test images (they shoud all have the same size)
      img_w: 1280 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "dataset/prediction" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:48:35,297] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:48:35,513] [INFO] Code state:
 Git hash: ec58d1d5207e78233e25dd501a58ce535a82cd1e

*************
Git diff:
*************

[2021-08-10 15:48:35,513] [INFO] Starting testing.
[2021-08-10 15:48:35,513] [ERROR] Uncaught exception
Traceback (most recent call last):
  File "test.py", line 159, in <module>
    _, mean_loss = test(model, test_loader, evaluator, exp_root, cfg, epoch=test_epoch, view=args.view)
  File "test.py", line 23, in test
    model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\serialization.py", line 529, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\serialization.py", line 702, in _legacy_load
    result = unpickler.load()
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\serialization.py", line 665, in persistent_load
    deserialized_objects[root_key] = restore_location(obj, location)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\serialization.py", line 156, in default_restore_location
    result = fn(storage, location)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\serialization.py", line 132, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "D:\User\miniconda3\envs\PolyLaneNet\lib\site-packages\torch\serialization.py", line 116, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2021-08-10 15:49:35,417] [INFO] Experiment name: tusimple_efficientnetb1
[2021-08-10 15:49:35,417] [INFO] Config:
# Training settings
seed: 0
exps_dir: 'experiments'
iter_log_interval: 1
iter_time_window: 100
model_save_interval: 1
backup:
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 poly coeffs)
    pretrained: true
    backbone: 'efficientnet-b1'
    pred_category: false
    curriculum_steps: [0, 0, 0, 0]
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 16
epochs: 2695
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations:
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "data_lane-regression/datasets/tusimple"

  test: &test
    type: LaneDataset
    parameters:
      dataset: nolabel_dataset
      normalize: true
      augmentations: []
      img_h: 720 # The height of your test images (they shoud all have the same size)
      img_w: 1280 # The width of your test images
      img_size: [720, 1280]
      max_lanes: 5 # Same number used in the pretrained model. If you use a model pretrained on TuSimple (most likely case), you'll use 5 here
      root: "dataset/prediction" # Path to the directory containing your test images. The loader will look recursively for image files in this directory
      img_ext: ".jpg"
      split: val


  # val = test
  val:
    <<: *test

[2021-08-10 15:49:35,418] [INFO] Args:
Namespace(batch_size=1, cfg='experiments\\tusimple_efficientnetb1\\config.yaml', epoch=2695, exp_name='tusimple_efficientnetb1', view=True)
[2021-08-10 15:49:35,633] [INFO] Code state:
 Git hash: ec58d1d5207e78233e25dd501a58ce535a82cd1e

*************
Git diff:
*************
diff --git a/test.py b/test.py
index 4641d01..2f03159 100644
--- a/test.py
+++ b/test.py
@@ -20,7 +20,7 @@ def test(model, test_loader, evaluator, exp_root, cfg, view, epoch, max_batches=
 
     # Test the model
     if epoch > 0:
-        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)))['model'])
+        model.load_state_dict(torch.load(os.path.join(exp_root, "models", "model_{:03d}.pt".format(epoch)), map_location=torch.device('cpu'))['model'])
 
     model.eval()
     criterion_parameters = cfg.get_loss_parameters()

[2021-08-10 15:49:35,633] [INFO] Starting testing.
[2021-08-10 15:49:39,498] [INFO] Testing iteration: 1/1
[2021-08-10 15:49:55,193] [INFO] Testing time: 19.3964
[2021-08-10 15:49:55,193] [INFO] conf: 12.2872, lower: nan, upper: nan, poly: nan, cls_loss: 0.0000
[2021-08-10 15:49:55,195] [INFO] Mean test loss: nan
[2021-08-10 15:49:55,195] [INFO] 
