{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061980f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import subprocess\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from lib.config import Config\n",
    "from utils.evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76aacd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(\"experiments/tusimple_efficientnetb1/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d66cdabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up seeds\n",
    "torch.manual_seed(cfg['seed'])\n",
    "np.random.seed(cfg['seed'])\n",
    "random.seed(cfg['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8676e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = cfg[\"epochs\"]\n",
    "batch_size = cfg[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f4bc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "model = cfg.get_model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ceb6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('experiments/tusimple_efficientnetb1/models/model_2695.pt', map_location=torch.device('cpu'))['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e3cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffad943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ab36d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmenters import Resize\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from imgaug.augmentables.lines import LineString, LineStringsOnImage\n",
    "\n",
    "\n",
    "GT_COLOR = (255, 0, 0)\n",
    "PRED_HIT_COLOR = (0, 255, 0)\n",
    "PRED_MISS_COLOR = (0, 0, 255)\n",
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "class Prediction_class(Dataset):\n",
    "    def __init__(self,\n",
    "                 img_dir,\n",
    "                 normalize=True,\n",
    "                 img_size=(720, 1080)):\n",
    "\n",
    "        self.img_h, self.img_w = img_size\n",
    "        self.normalize = normalize\n",
    "        self.to_tensor = ToTensor()\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, os.listdir(self.img_dir)[0])\n",
    "        img = cv2.imread(img_path)\n",
    "        #print(\"*\"*50)\n",
    "        img = img / 255.\n",
    "        if self.normalize:\n",
    "            img = (img - IMAGENET_MEAN) / IMAGENET_STD\n",
    "        img = self.to_tensor(img.astype(np.float32))\n",
    "        return (img, idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.img_dir))\n",
    "    \n",
    "    \n",
    "    def draw_annotation(self, idx, pred=None, img=None, cls_pred=None):\n",
    "        \n",
    "        img, _ = self.__getitem__(idx)\n",
    "        # Tensor to opencv image\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        # Unnormalize\n",
    "\n",
    "        img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        img_h, img_w, _ = img.shape\n",
    "\n",
    "        print(pred)\n",
    "        #pred = pred.reshape(5,7)\n",
    "        # Draw predictions\n",
    "        pred = pred[pred[:, 0] != 0]  # filter invalid lanes\n",
    "        #matches, accs, _ = self.get_metrics(pred, idx)\n",
    "        overlay = img.copy()\n",
    "        for i, lane in enumerate(pred):\n",
    "            \n",
    "            #print(lane.shape)\n",
    "            color = PRED_HIT_COLOR\n",
    "            \n",
    "            pred_conf = lane[0]\n",
    "            lane = lane[1:]  # remove conf\n",
    "            lower, upper = lane[0], lane[1]\n",
    "            lane = lane[2:]  # remove upper, lower positions\n",
    "\n",
    "            # generate points from the polynomial\n",
    "            ys = np.linspace(lower, upper, num=100)\n",
    "            points = np.zeros((len(ys), 2), dtype=np.int32)\n",
    "            points[:, 1] = (ys * img_h).astype(int)\n",
    "            points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)\n",
    "            points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]\n",
    "\n",
    "            # draw lane with a polyline on the overlay\n",
    "            for current_point, next_point in zip(points[:-1], points[1:]):\n",
    "                overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)\n",
    "\n",
    "            # draw class icon\n",
    "            if cls_pred is not None and len(points) > 0:\n",
    "                class_icon = self.dataset.get_class_icon(cls_pred[i])\n",
    "                class_icon = cv2.resize(class_icon, (32, 32))\n",
    "                mid = tuple(points[len(points) // 2] - 60)\n",
    "                x, y = mid\n",
    "\n",
    "                img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon\n",
    "\n",
    "            # draw lane ID\n",
    "            if len(points) > 0:\n",
    "                cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)\n",
    "\n",
    "            # draw lane accuracy\n",
    "            if len(points) > 0:\n",
    "                cv2.putText(img,\n",
    "                            '{:.2f}'.format(pred_conf),\n",
    "                            tuple(points[len(points) // 2] - 30),\n",
    "                            fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "                            fontScale=.75,\n",
    "                            color=color)\n",
    "        # Add lanes overlay\n",
    "        w = 0.6\n",
    "        img = ((1. - w) * img + w * overlay).astype(np.uint8)\n",
    "\n",
    "        return img\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a42df3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(img_dir, os.listdir(img_dir)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "33220076",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'data_lane-regression\\datasets\\prediction'\n",
    "predict_set = Prediction_class(img_dir, normalize=True, img_size=(720, 1080))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f1933025",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=predict_set,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8b31e37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "15b3da0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.33478528  0.6908689   0.11480151  0.17138144 -0.89206874\n",
      "   0.6756637 ]\n",
      " [ 1.         -0.00616999  0.8119759  -0.25480416  0.28873855 -0.44717577\n",
      "   0.58625025]\n",
      " [ 0.5000369   0.00214301  0.9661293  -0.01230763  0.35438856 -0.12804604\n",
      "   0.63476104]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test_parameters = cfg.get_test_parameters()\n",
    "with torch.no_grad():\n",
    "    for idx, (images, img_idxs) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        \n",
    "        labels = np.zeros((1,1), dtype = int)\n",
    "        outputs = model.decode(outputs, labels, **test_parameters)\n",
    "        \n",
    "        output, extra_outputs = outputs\n",
    "        #print(output.shape)\n",
    "        #print(images.shape)\n",
    "        preds = test_loader.dataset.draw_annotation(idx, pred=output[0].cpu().numpy(), cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)\n",
    "        #preds = test_loader.dataset.draw_annotation(\n",
    "        #    idx,\n",
    "        #    pred=outputs[0].cpu().numpy(),\n",
    "        #    cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)\n",
    "        #cv2.imshow('pred', preds)\n",
    "        #cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "64a06a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('pred', preds)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d5214666",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 35 is out of bounds for axis 0 with size 35",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-673b3af9ddd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 35 is out of bounds for axis 0 with size 35"
     ]
    }
   ],
   "source": [
    "p = np.zeros((35,), dtype='float')\n",
    "print(p[35])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "84963a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lane in enumerate(p):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e07b41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-391bdc2bec3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m preds = draw_annotation(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     cls_pred=extra_outputs[0].cpu().numpy() if extra_outputs is not None else None)\n\u001b[0;32m      5\u001b[0m \"\"\"cv2.imshow('pred', preds)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"cv2.imshow('pred', preds)\n",
    "cv2.waitKey(0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3ee0834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_annotation(idx, img, pred, cls_pred):\n",
    "\n",
    "    # Tensor to opencv image\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    # Unnormalize\n",
    "\n",
    "    img = img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "    img_h, img_w, _ = img.shape\n",
    "\n",
    "    print(pred.shape)\n",
    "    pred = pred.reshape(pred.shape[0],1)\n",
    "    # Draw predictions\n",
    "    pred = pred[pred[:, 0] != 0]  # filter invalid lanes\n",
    "    #matches, accs, _ = self.dataset.get_metrics(pred, idx)\n",
    "    overlay = img.copy()\n",
    "    for i, lane in enumerate(pred):\n",
    "        if matches[i]:\n",
    "            color = PRED_HIT_COLOR\n",
    "        else:\n",
    "            color = PRED_MISS_COLOR\n",
    "        lane = lane[1:]  # remove conf\n",
    "        lower, upper = lane[0], lane[1]\n",
    "        lane = lane[2:]  # remove upper, lower positions\n",
    "\n",
    "        # generate points from the polynomial\n",
    "        ys = np.linspace(lower, upper, num=100)\n",
    "        points = np.zeros((len(ys), 2), dtype=np.int32)\n",
    "        points[:, 1] = (ys * img_h).astype(int)\n",
    "        points[:, 0] = (np.polyval(lane, ys) * img_w).astype(int)\n",
    "        points = points[(points[:, 0] > 0) & (points[:, 0] < img_w)]\n",
    "\n",
    "        # draw lane with a polyline on the overlay\n",
    "        for current_point, next_point in zip(points[:-1], points[1:]):\n",
    "            overlay = cv2.line(overlay, tuple(current_point), tuple(next_point), color=color, thickness=2)\n",
    "\n",
    "        # draw class icon\n",
    "        if cls_pred is not None and len(points) > 0:\n",
    "            class_icon = self.dataset.get_class_icon(cls_pred[i])\n",
    "            class_icon = cv2.resize(class_icon, (32, 32))\n",
    "            mid = tuple(points[len(points) // 2] - 60)\n",
    "            x, y = mid\n",
    "\n",
    "            img[y:y + class_icon.shape[0], x:x + class_icon.shape[1]] = class_icon\n",
    "\n",
    "        # draw lane ID\n",
    "        if len(points) > 0:\n",
    "            cv2.putText(img, str(i), tuple(points[0]), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1, color=color)\n",
    "\n",
    "        # draw lane accuracy\n",
    "        if len(points) > 0:\n",
    "            cv2.putText(img,\n",
    "                        '{:.2f}'.format(accs[i] * 100),\n",
    "                        tuple(points[len(points) // 2] - 30),\n",
    "                        fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        fontScale=.75,\n",
    "                        color=color)\n",
    "    # Add lanes overlay\n",
    "    w = 0.6\n",
    "    img = ((1. - w) * img + w * overlay).astype(np.uint8)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8308e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b198c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
